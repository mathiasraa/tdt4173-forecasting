{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import IPython\n",
    "import IPython.display\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "# import tensorflow as tf\n",
    "\n",
    "# mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "# mpl.rcParams['axes.grid'] = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan:\n",
    " - Load sets\n",
    " - Clean:\n",
    "    - remove duplicate entries from sets\n",
    "    - Drop the unimportant coloumns that we found\n",
    "    - Make querters into hours\n",
    "    - remove values from train_targets that are nan in both x and y sets\n",
    "    - make time features\n",
    "    - drop datetime coloumns\n",
    " - Set prep:\n",
    "    - 75/25 fordeling. 75% av OBSERVED er trening, resterende 25% er validation, 75% av ESTIMATED er trening, resterende 25% er validation\n",
    "- Concat the different locations into 1 set, where location is a feature as well\n",
    "   - 1 hot encoding\n",
    "- Make a time series model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A\n",
    "y_a = pd.read_parquet('../data/A/train_targets.parquet')\n",
    "X_test_estimated_a = pd.read_parquet('../data/A/X_test_estimated.parquet')\n",
    "X_train_estimated_a = pd.read_parquet('../data/A/X_train_estimated.parquet')\n",
    "X_train_observed_a = pd.read_parquet('../data/A/X_train_observed.parquet')\n",
    "\n",
    "# B\n",
    "y_b = pd.read_parquet('../data/B/train_targets.parquet')\n",
    "X_test_estimated_b = pd.read_parquet('../data/B/X_test_estimated.parquet')\n",
    "X_train_estimated_b = pd.read_parquet('../data/B/X_train_estimated.parquet')\n",
    "X_train_observed_b = pd.read_parquet('../data/B/X_train_observed.parquet')\n",
    "\n",
    "# C\n",
    "y_c = pd.read_parquet('../data/C/train_targets.parquet')\n",
    "X_test_estimated_c = pd.read_parquet('../data/C/X_test_estimated.parquet')\n",
    "X_train_estimated_c = pd.read_parquet('../data/C/X_train_estimated.parquet')\n",
    "X_train_observed_c = pd.read_parquet('../data/C/X_train_observed.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing duplicate entries from the sets if any exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that removes the duplicates if it finds duplicates in the specified coloumn\n",
    "def remove_duplicates_in_coloumn(df, col):\n",
    "    duplicate_mask = df[col].duplicated(keep=\"first\")\n",
    "    if duplicate_mask.any():\n",
    "        df = df[~duplicate_mask]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A\n",
    "y_a = remove_duplicates_in_coloumn(y_a, \"time\")\n",
    "X_test_estimated_a = remove_duplicates_in_coloumn(X_test_estimated_a, \"date_forecast\")\n",
    "X_train_estimated_a = remove_duplicates_in_coloumn(X_train_estimated_a, \"date_forecast\")\n",
    "X_train_observed_a = remove_duplicates_in_coloumn(X_train_observed_a, \"date_forecast\")\n",
    "\n",
    "#B\n",
    "y_b = remove_duplicates_in_coloumn(y_b, \"time\")\n",
    "X_test_estimated_b = remove_duplicates_in_coloumn(X_test_estimated_b, \"date_forecast\")\n",
    "X_train_estimated_b = remove_duplicates_in_coloumn(X_train_estimated_b, \"date_forecast\")\n",
    "X_train_observed_b = remove_duplicates_in_coloumn(X_train_observed_b, \"date_forecast\")\n",
    "\n",
    "#C\n",
    "y_c = remove_duplicates_in_coloumn(y_c, \"time\")\n",
    "X_test_estimated_c = remove_duplicates_in_coloumn(X_test_estimated_c, \"date_forecast\")\n",
    "X_train_estimated_c = remove_duplicates_in_coloumn(X_train_estimated_c, \"date_forecast\")\n",
    "X_train_observed_c = remove_duplicates_in_coloumn(X_train_observed_c, \"date_forecast\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of all estimated and observed sets\n",
    "\n",
    "list_of_all_estimated_and_observed_sets = [X_test_estimated_a, X_train_estimated_a, X_train_observed_a,\n",
    "                                           X_test_estimated_b, X_train_estimated_b, X_train_observed_b,\n",
    "                                           X_test_estimated_c, X_train_estimated_c, X_train_observed_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping some coloumns for the bants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "for set in list_of_all_estimated_and_observed_sets:\n",
    "    # set.drop(\"snow_density:kgm3\", axis=1, inplace=True)\n",
    "    # these 2 had a lot of NaN values\n",
    "    set.drop(\"ceiling_height_agl:m\", axis=1, inplace=True) \n",
    "    set.drop(\"cloud_base_agl:m\", axis=1,inplace=True) # could potentially not drop this, but set all nan values to 0\n",
    "    # set.drop(\"snow_density:kgm3\", axis=1, inplace=True)\n",
    "    set.drop(\"elevation:m\", axis=1, inplace=True) \n",
    "    set.drop(\"precip_5min:mm\", axis=1, inplace=True)\n",
    "    set.drop(\"precip_type_5min:idx\", axis=1, inplace=True)\n",
    "    set.drop(\"pressure_50m:hPa\", axis=1, inplace=True)\n",
    "    set.drop(\"snow_drift:idx\", axis=1, inplace=True)\n",
    "    set.drop(\"wind_speed_u_10m:ms\", axis=1, inplace=True)\n",
    "    set.drop(\"wind_speed_v_10m:ms\", axis=1, inplace=True)\n",
    "    set.drop(\"wind_speed_w_1000hPa:ms\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting degree features to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_from_degree_to_ciruclar(df, feature):\n",
    "    df[feature+'_sin'] = np.sin(np.radians(df[feature]))\n",
    "    df[feature+'_cos'] = np.cos(np.radians(df[feature]))\n",
    "    df = df.drop(feature, axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2880, 36)\n",
      "(2880, 37)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_estimated_a.shape)\n",
    "\n",
    "X_train_estimated_a = convert_from_degree_to_ciruclar(X_train_estimated_a, \"sun_azimuth:d\")\n",
    "X_train_observed_a = convert_from_degree_to_ciruclar(X_train_observed_a, \"sun_azimuth:d\")\n",
    "X_test_estimated_a = convert_from_degree_to_ciruclar(X_test_estimated_a, \"sun_azimuth:d\")\n",
    "X_train_estimated_b = convert_from_degree_to_ciruclar(X_train_estimated_b, \"sun_azimuth:d\")\n",
    "X_train_observed_b = convert_from_degree_to_ciruclar(X_train_observed_b, \"sun_azimuth:d\")\n",
    "X_test_estimated_b = convert_from_degree_to_ciruclar(X_test_estimated_b, \"sun_azimuth:d\")\n",
    "X_train_estimated_c = convert_from_degree_to_ciruclar(X_train_estimated_c, \"sun_azimuth:d\")\n",
    "X_train_observed_c = convert_from_degree_to_ciruclar(X_train_observed_c, \"sun_azimuth:d\")\n",
    "X_test_estimated_c = convert_from_degree_to_ciruclar(X_test_estimated_c, \"sun_azimuth:d\")\n",
    "\n",
    "print(X_test_estimated_a.shape)\n",
    "\n",
    "# X_train_observed_a.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing date_calc from all estimated sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_estimated_a.drop(\"date_calc\", axis=1, inplace=True)\n",
    "X_train_estimated_a.drop(\"date_calc\", axis=1, inplace=True)\n",
    "X_test_estimated_b.drop(\"date_calc\", axis=1, inplace=True)\n",
    "X_train_estimated_b.drop(\"date_calc\", axis=1, inplace=True)\n",
    "X_test_estimated_c.drop(\"date_calc\", axis=1, inplace=True)\n",
    "X_train_estimated_c.drop(\"date_calc\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting every 4 quarters into an whole hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "## It might be better not to resample actually, but just use the actual hours that correspond perfectly\n",
    "\n",
    "def convert_df_into_hourly(df):\n",
    "    df.set_index(\"date_forecast\", inplace=True)\n",
    "    df = df.resample('1H').sum()\n",
    "    df.reset_index(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2880, 36)\n",
      "(1536, 36)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_forecast</th>\n",
       "      <th>absolute_humidity_2m:gm3</th>\n",
       "      <th>air_density_2m:kgm3</th>\n",
       "      <th>clear_sky_energy_1h:J</th>\n",
       "      <th>clear_sky_rad:W</th>\n",
       "      <th>dew_or_rime:idx</th>\n",
       "      <th>dew_point_2m:K</th>\n",
       "      <th>diffuse_rad:W</th>\n",
       "      <th>diffuse_rad_1h:J</th>\n",
       "      <th>direct_rad:W</th>\n",
       "      <th>...</th>\n",
       "      <th>snow_melt_10min:mm</th>\n",
       "      <th>snow_water:kgm2</th>\n",
       "      <th>sun_elevation:d</th>\n",
       "      <th>super_cooled_liquid_water:kgm2</th>\n",
       "      <th>t_1000hPa:K</th>\n",
       "      <th>total_cloud_cover:p</th>\n",
       "      <th>visibility:m</th>\n",
       "      <th>wind_speed_10m:ms</th>\n",
       "      <th>sun_azimuth:d_sin</th>\n",
       "      <th>sun_azimuth:d_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-10-28 22:00:00</td>\n",
       "      <td>33.400002</td>\n",
       "      <td>4.932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1125.099976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>-156.261002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1138.700073</td>\n",
       "      <td>400.0</td>\n",
       "      <td>82850.101562</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>-0.840212</td>\n",
       "      <td>3.893597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-10-28 23:00:00</td>\n",
       "      <td>32.400002</td>\n",
       "      <td>4.936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1123.400024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>-157.529007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1137.300049</td>\n",
       "      <td>400.0</td>\n",
       "      <td>22496.699219</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>0.468029</td>\n",
       "      <td>3.955367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-10-29 00:00:00</td>\n",
       "      <td>32.599998</td>\n",
       "      <td>4.919</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1123.699951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>-152.162003</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1135.500000</td>\n",
       "      <td>400.0</td>\n",
       "      <td>12961.700195</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.635808</td>\n",
       "      <td>3.632862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-10-29 01:00:00</td>\n",
       "      <td>32.799999</td>\n",
       "      <td>4.914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1124.199951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-137.561996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1137.400024</td>\n",
       "      <td>400.0</td>\n",
       "      <td>12974.000000</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>2.658692</td>\n",
       "      <td>2.970362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-10-29 02:00:00</td>\n",
       "      <td>33.500000</td>\n",
       "      <td>4.908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1125.399902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-117.074997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1138.099976</td>\n",
       "      <td>400.0</td>\n",
       "      <td>10113.799805</td>\n",
       "      <td>8.799999</td>\n",
       "      <td>3.382308</td>\n",
       "      <td>2.114047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date_forecast  absolute_humidity_2m:gm3  air_density_2m:kgm3  \\\n",
       "0 2022-10-28 22:00:00                 33.400002                4.932   \n",
       "1 2022-10-28 23:00:00                 32.400002                4.936   \n",
       "2 2022-10-29 00:00:00                 32.599998                4.919   \n",
       "3 2022-10-29 01:00:00                 32.799999                4.914   \n",
       "4 2022-10-29 02:00:00                 33.500000                4.908   \n",
       "\n",
       "   clear_sky_energy_1h:J  clear_sky_rad:W  dew_or_rime:idx  dew_point_2m:K  \\\n",
       "0                    0.0              0.0              4.0     1125.099976   \n",
       "1                    0.0              0.0              4.0     1123.400024   \n",
       "2                    0.0              0.0              4.0     1123.699951   \n",
       "3                    0.0              0.0              4.0     1124.199951   \n",
       "4                    0.0              0.0              4.0     1125.399902   \n",
       "\n",
       "   diffuse_rad:W  diffuse_rad_1h:J  direct_rad:W  ...  snow_melt_10min:mm  \\\n",
       "0            0.0               0.0           0.0  ...                 0.0   \n",
       "1            0.0               0.0           0.0  ...                 0.0   \n",
       "2            0.0               0.0           0.0  ...                 0.0   \n",
       "3            0.0               0.0           0.0  ...                 0.0   \n",
       "4            0.0               0.0           0.0  ...                 0.0   \n",
       "\n",
       "   snow_water:kgm2  sun_elevation:d  super_cooled_liquid_water:kgm2  \\\n",
       "0              1.9      -156.261002                             0.0   \n",
       "1              2.8      -157.529007                             0.0   \n",
       "2              4.7      -152.162003                             0.8   \n",
       "3              3.5      -137.561996                             1.0   \n",
       "4              4.0      -117.074997                             1.0   \n",
       "\n",
       "   t_1000hPa:K  total_cloud_cover:p  visibility:m  wind_speed_10m:ms  \\\n",
       "0  1138.700073                400.0  82850.101562           2.800000   \n",
       "1  1137.300049                400.0  22496.699219           3.100000   \n",
       "2  1135.500000                400.0  12961.700195           6.000000   \n",
       "3  1137.400024                400.0  12974.000000           6.300000   \n",
       "4  1138.099976                400.0  10113.799805           8.799999   \n",
       "\n",
       "   sun_azimuth:d_sin  sun_azimuth:d_cos  \n",
       "0          -0.840212           3.893597  \n",
       "1           0.468029           3.955367  \n",
       "2           1.635808           3.632862  \n",
       "3           2.658692           2.970362  \n",
       "4           3.382308           2.114047  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(X_test_estimated_a.shape)\n",
    "\n",
    "X_train_estimated_a = convert_df_into_hourly(X_train_estimated_a)\n",
    "X_train_observed_a = convert_df_into_hourly(X_train_observed_a)\n",
    "X_test_estimated_a = convert_df_into_hourly(X_test_estimated_a)\n",
    "X_train_estimated_b = convert_df_into_hourly(X_train_estimated_b)\n",
    "X_train_observed_b = convert_df_into_hourly(X_train_observed_b)\n",
    "X_test_estimated_b = convert_df_into_hourly(X_test_estimated_b)\n",
    "X_train_estimated_c = convert_df_into_hourly(X_train_estimated_c)\n",
    "X_train_observed_c = convert_df_into_hourly(X_train_observed_c)\n",
    "X_test_estimated_c = convert_df_into_hourly(X_test_estimated_c)\n",
    "\n",
    "print(X_test_estimated_a.shape)\n",
    "\n",
    "X_train_estimated_a.head()\n",
    "## We should probably do it for the test_sets here as well\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing all NaN from y_targets\n",
    " - Removing all NaN from y_targets and their corresponding dates in the X_train sets, both observed and estimated\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that returns train_targets, observed and estimated sets left after filtering away NaN\n",
    "def drop_nan_rows_in_target_and_train(y_df, observed_train_df, estimated_train_df):\n",
    "    y_df = y_df.dropna(subset=['pv_measurement'])\n",
    "    valid_dates = y_df['time']\n",
    "    observed_train_df = observed_train_df[observed_train_df['date_forecast'].isin(valid_dates)]\n",
    "    estimated_train_df = estimated_train_df[estimated_train_df['date_forecast'].isin(valid_dates)]\n",
    "    return (y_df, observed_train_df, estimated_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>pv_measurement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5913</th>\n",
       "      <td>2019-09-04 08:00:00</td>\n",
       "      <td>137.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5914</th>\n",
       "      <td>2019-09-04 09:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5915</th>\n",
       "      <td>2019-09-04 10:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5916</th>\n",
       "      <td>2019-09-04 11:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5917</th>\n",
       "      <td>2019-09-04 12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    time  pv_measurement\n",
       "5913 2019-09-04 08:00:00           137.2\n",
       "5914 2019-09-04 09:00:00             0.0\n",
       "5915 2019-09-04 10:00:00             0.0\n",
       "5916 2019-09-04 11:00:00             0.0\n",
       "5917 2019-09-04 12:00:00             0.0"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#doing the NaN filtering\n",
    "y_a, X_train_observed_a, X_train_estimated_a = drop_nan_rows_in_target_and_train(y_a, X_train_observed_a, X_train_estimated_a)\n",
    "y_b, X_train_observed_b, X_train_estimated_b = drop_nan_rows_in_target_and_train(y_b, X_train_observed_b, X_train_estimated_b)\n",
    "y_c, X_train_observed_c, X_train_estimated_c = drop_nan_rows_in_target_and_train(y_c, X_train_observed_c, X_train_estimated_c)\n",
    "\n",
    "y_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_forecast</th>\n",
       "      <th>absolute_humidity_2m:gm3</th>\n",
       "      <th>air_density_2m:kgm3</th>\n",
       "      <th>clear_sky_energy_1h:J</th>\n",
       "      <th>clear_sky_rad:W</th>\n",
       "      <th>dew_or_rime:idx</th>\n",
       "      <th>dew_point_2m:K</th>\n",
       "      <th>diffuse_rad:W</th>\n",
       "      <th>diffuse_rad_1h:J</th>\n",
       "      <th>direct_rad:W</th>\n",
       "      <th>...</th>\n",
       "      <th>snow_melt_10min:mm</th>\n",
       "      <th>snow_water:kgm2</th>\n",
       "      <th>sun_elevation:d</th>\n",
       "      <th>super_cooled_liquid_water:kgm2</th>\n",
       "      <th>t_1000hPa:K</th>\n",
       "      <th>total_cloud_cover:p</th>\n",
       "      <th>visibility:m</th>\n",
       "      <th>wind_speed_10m:ms</th>\n",
       "      <th>sun_azimuth:d_sin</th>\n",
       "      <th>sun_azimuth:d_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5912</th>\n",
       "      <td>2019-09-04 08:00:00</td>\n",
       "      <td>26.5</td>\n",
       "      <td>4.883</td>\n",
       "      <td>5283377.5</td>\n",
       "      <td>1684.900024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1112.800049</td>\n",
       "      <td>271.899994</td>\n",
       "      <td>9.320397e+05</td>\n",
       "      <td>1352.599976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.019997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1134.900024</td>\n",
       "      <td>124.799995</td>\n",
       "      <td>198197.796875</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.039486</td>\n",
       "      <td>-2.582547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5913</th>\n",
       "      <td>2019-09-04 09:00:00</td>\n",
       "      <td>25.1</td>\n",
       "      <td>4.857</td>\n",
       "      <td>6726922.0</td>\n",
       "      <td>2032.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1109.699951</td>\n",
       "      <td>306.500000</td>\n",
       "      <td>1.041404e+06</td>\n",
       "      <td>1624.199951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.817001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1139.199951</td>\n",
       "      <td>345.000000</td>\n",
       "      <td>209239.906250</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.200736</td>\n",
       "      <td>-3.324243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5914</th>\n",
       "      <td>2019-09-04 10:00:00</td>\n",
       "      <td>23.6</td>\n",
       "      <td>4.833</td>\n",
       "      <td>7747199.5</td>\n",
       "      <td>2247.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1106.600098</td>\n",
       "      <td>450.299988</td>\n",
       "      <td>1.362371e+06</td>\n",
       "      <td>1598.800049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.110001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1143.599976</td>\n",
       "      <td>380.599976</td>\n",
       "      <td>215915.203125</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.117962</td>\n",
       "      <td>-3.825162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5915</th>\n",
       "      <td>2019-09-04 11:00:00</td>\n",
       "      <td>23.5</td>\n",
       "      <td>4.814</td>\n",
       "      <td>8254105.0</td>\n",
       "      <td>2312.100098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1106.599976</td>\n",
       "      <td>780.599976</td>\n",
       "      <td>2.215590e+06</td>\n",
       "      <td>1090.799927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.548004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1147.699951</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>218043.703125</td>\n",
       "      <td>7.8</td>\n",
       "      <td>-0.108947</td>\n",
       "      <td>-3.983159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5916</th>\n",
       "      <td>2019-09-04 12:00:00</td>\n",
       "      <td>24.6</td>\n",
       "      <td>4.807</td>\n",
       "      <td>8205280.0</td>\n",
       "      <td>2220.699951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1109.000000</td>\n",
       "      <td>973.500000</td>\n",
       "      <td>3.157120e+06</td>\n",
       "      <td>449.399994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>130.675995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1150.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>217138.593750</td>\n",
       "      <td>6.1</td>\n",
       "      <td>-1.321110</td>\n",
       "      <td>-3.760065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date_forecast  absolute_humidity_2m:gm3  air_density_2m:kgm3  \\\n",
       "5912 2019-09-04 08:00:00                      26.5                4.883   \n",
       "5913 2019-09-04 09:00:00                      25.1                4.857   \n",
       "5914 2019-09-04 10:00:00                      23.6                4.833   \n",
       "5915 2019-09-04 11:00:00                      23.5                4.814   \n",
       "5916 2019-09-04 12:00:00                      24.6                4.807   \n",
       "\n",
       "      clear_sky_energy_1h:J  clear_sky_rad:W  dew_or_rime:idx  dew_point_2m:K  \\\n",
       "5912              5283377.5      1684.900024              0.0     1112.800049   \n",
       "5913              6726922.0      2032.500000              0.0     1109.699951   \n",
       "5914              7747199.5      2247.500000              0.0     1106.600098   \n",
       "5915              8254105.0      2312.100098              0.0     1106.599976   \n",
       "5916              8205280.0      2220.699951              0.0     1109.000000   \n",
       "\n",
       "      diffuse_rad:W  diffuse_rad_1h:J  direct_rad:W  ...  snow_melt_10min:mm  \\\n",
       "5912     271.899994      9.320397e+05   1352.599976  ...                 0.0   \n",
       "5913     306.500000      1.041404e+06   1624.199951  ...                 0.0   \n",
       "5914     450.299988      1.362371e+06   1598.800049  ...                 0.0   \n",
       "5915     780.599976      2.215590e+06   1090.799927  ...                 0.0   \n",
       "5916     973.500000      3.157120e+06    449.399994  ...                 0.0   \n",
       "\n",
       "      snow_water:kgm2  sun_elevation:d  super_cooled_liquid_water:kgm2  \\\n",
       "5912              0.0       103.019997                             0.0   \n",
       "5913              0.0       120.817001                             0.0   \n",
       "5914              0.0       132.110001                             0.0   \n",
       "5915              0.0       135.548004                             0.0   \n",
       "5916              0.2       130.675995                             0.0   \n",
       "\n",
       "      t_1000hPa:K  total_cloud_cover:p   visibility:m  wind_speed_10m:ms  \\\n",
       "5912  1134.900024           124.799995  198197.796875                5.0   \n",
       "5913  1139.199951           345.000000  209239.906250                6.0   \n",
       "5914  1143.599976           380.599976  215915.203125                8.0   \n",
       "5915  1147.699951           400.000000  218043.703125                7.8   \n",
       "5916  1150.000000           400.000000  217138.593750                6.1   \n",
       "\n",
       "      sun_azimuth:d_sin  sun_azimuth:d_cos  \n",
       "5912           3.039486          -2.582547  \n",
       "5913           2.200736          -3.324243  \n",
       "5914           1.117962          -3.825162  \n",
       "5915          -0.108947          -3.983159  \n",
       "5916          -1.321110          -3.760065  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_observed_c.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that creates timefeatures based on the specified coloumn\n",
    "def create_time_features_based_on_coloun(df, col):   \n",
    "    df['hour'] = df[col].dt.hour\n",
    "    df['dayofmonth'] = df[col].dt.day\n",
    "    df['dayofweek'] = df[col].dt.dayofweek\n",
    "    df['quarter'] = df[col].dt.quarter\n",
    "    df['month'] = df[col].dt.month\n",
    "    df['year'] = df[col].dt.year\n",
    "    df['dayofyear'] = df[col].dt.dayofyear\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding time features\n",
    "\n",
    "#A\n",
    "X_train_estimated_a = create_time_features_based_on_coloun(X_train_estimated_a, \"date_forecast\")\n",
    "X_train_observed_a = create_time_features_based_on_coloun(X_train_observed_a, \"date_forecast\")\n",
    "X_test_estimated_a = create_time_features_based_on_coloun(X_test_estimated_a, \"date_forecast\")\n",
    "\n",
    "#B\n",
    "X_train_estimated_b = create_time_features_based_on_coloun(X_train_estimated_b, \"date_forecast\")\n",
    "X_train_observed_b = create_time_features_based_on_coloun(X_train_observed_b, \"date_forecast\")\n",
    "X_test_estimated_b = create_time_features_based_on_coloun(X_test_estimated_b, \"date_forecast\")\n",
    "\n",
    "#C\n",
    "X_train_estimated_c = create_time_features_based_on_coloun(X_train_estimated_c, \"date_forecast\")\n",
    "X_train_observed_c = create_time_features_based_on_coloun(X_train_observed_c, \"date_forecast\")\n",
    "X_test_estimated_c = create_time_features_based_on_coloun(X_test_estimated_c, \"date_forecast\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just showing the shapes to se if i havent f'ed up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "(4418, 43)\n",
      "(29667, 43)\n",
      "34085\n",
      "(34085, 2)\n",
      "B\n",
      "(3625, 43)\n",
      "(29218, 43)\n",
      "32843\n",
      "(32844, 2)\n",
      "C\n",
      "(2954, 43)\n",
      "(23141, 43)\n",
      "26095\n",
      "(26095, 2)\n"
     ]
    }
   ],
   "source": [
    "# printing shapes\n",
    "print(\"A\")\n",
    "print(X_train_estimated_a.shape)\n",
    "print(X_train_observed_a.shape)\n",
    "print(X_train_estimated_a.shape[0]+X_train_observed_a.shape[0])\n",
    "print(y_a.shape)\n",
    "\n",
    "print(\"B\")\n",
    "print(X_train_estimated_b.shape)\n",
    "print(X_train_observed_b.shape)\n",
    "print(X_train_estimated_b.shape[0]+X_train_observed_b.shape[0])  ## this one seems to be of by 1??????\n",
    "print(y_b.shape)\n",
    "\n",
    "print(\"C\")\n",
    "print(X_train_estimated_c.shape)\n",
    "print(X_train_observed_c.shape)\n",
    "print(X_train_estimated_c.shape[0]+X_train_observed_c.shape[0])\n",
    "print(y_c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for B there is actually on row more in the target set for some reason, finding that row and deleting it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 time  pv_measurement\n",
      "0 2018-12-31 23:00:00             0.0\n"
     ]
    }
   ],
   "source": [
    "## Finding the row in y_b that does not have a match\n",
    "\n",
    "# renaming\n",
    "date_times_estimated = X_train_estimated_b['date_forecast']\n",
    "date_times_observed = X_train_observed_b['date_forecast']\n",
    "result_df = y_b[~y_b['time'].isin(date_times_estimated) & ~y_b['time'].isin(date_times_observed)]\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okey so let's remove that row and verify that everything is correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n",
      "(3625, 43)\n",
      "(29218, 43)\n",
      "32843\n",
      "(32843, 2)\n"
     ]
    }
   ],
   "source": [
    "# removing row\n",
    "y_b = y_b[~y_b['time'].isin(result_df['time'])]\n",
    "\n",
    "# checking that the numbers add up again\n",
    "print(\"B\")\n",
    "print(X_train_estimated_b.shape)\n",
    "print(X_train_observed_b.shape)\n",
    "print(X_train_estimated_b.shape[0]+X_train_observed_b.shape[0])\n",
    "print(y_b.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing repeated indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dividing the sets into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_forecast</th>\n",
       "      <th>absolute_humidity_2m:gm3</th>\n",
       "      <th>air_density_2m:kgm3</th>\n",
       "      <th>clear_sky_energy_1h:J</th>\n",
       "      <th>clear_sky_rad:W</th>\n",
       "      <th>dew_or_rime:idx</th>\n",
       "      <th>dew_point_2m:K</th>\n",
       "      <th>diffuse_rad:W</th>\n",
       "      <th>diffuse_rad_1h:J</th>\n",
       "      <th>direct_rad:W</th>\n",
       "      <th>...</th>\n",
       "      <th>wind_speed_10m:ms</th>\n",
       "      <th>sun_azimuth:d_sin</th>\n",
       "      <th>sun_azimuth:d_cos</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofmonth</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>quarter</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>dayofyear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-02 22:00:00</td>\n",
       "      <td>30.799999</td>\n",
       "      <td>4.913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1121.199951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.4</td>\n",
       "      <td>-0.827235</td>\n",
       "      <td>3.904145</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-06-02 23:00:00</td>\n",
       "      <td>30.799999</td>\n",
       "      <td>4.894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1121.199951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.4</td>\n",
       "      <td>0.137934</td>\n",
       "      <td>3.988335</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-06-03 00:00:00</td>\n",
       "      <td>31.500000</td>\n",
       "      <td>4.879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1122.599976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1.028531</td>\n",
       "      <td>3.856086</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-03 01:00:00</td>\n",
       "      <td>33.700001</td>\n",
       "      <td>4.872</td>\n",
       "      <td>834.599976</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1126.699951</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>2107.100098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.9</td>\n",
       "      <td>1.912442</td>\n",
       "      <td>3.503262</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-06-03 02:00:00</td>\n",
       "      <td>35.799999</td>\n",
       "      <td>4.872</td>\n",
       "      <td>129872.601562</td>\n",
       "      <td>92.400002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1130.000000</td>\n",
       "      <td>47.900002</td>\n",
       "      <td>88275.796875</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>10.2</td>\n",
       "      <td>2.670854</td>\n",
       "      <td>2.966543</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date_forecast  absolute_humidity_2m:gm3  air_density_2m:kgm3  \\\n",
       "0 2019-06-02 22:00:00                 30.799999                4.913   \n",
       "1 2019-06-02 23:00:00                 30.799999                4.894   \n",
       "2 2019-06-03 00:00:00                 31.500000                4.879   \n",
       "3 2019-06-03 01:00:00                 33.700001                4.872   \n",
       "4 2019-06-03 02:00:00                 35.799999                4.872   \n",
       "\n",
       "   clear_sky_energy_1h:J  clear_sky_rad:W  dew_or_rime:idx  dew_point_2m:K  \\\n",
       "0               0.000000         0.000000              0.0     1121.199951   \n",
       "1               0.000000         0.000000              0.0     1121.199951   \n",
       "2               0.000000         0.000000              0.0     1122.599976   \n",
       "3             834.599976         3.000000              0.0     1126.699951   \n",
       "4          129872.601562        92.400002              0.0     1130.000000   \n",
       "\n",
       "   diffuse_rad:W  diffuse_rad_1h:J  direct_rad:W  ...  wind_speed_10m:ms  \\\n",
       "0       0.000000          0.000000           0.0  ...               14.4   \n",
       "1       0.000000          0.000000           0.0  ...               13.4   \n",
       "2       0.000000          0.000000           0.0  ...               12.2   \n",
       "3       1.200000       2107.100098           0.0  ...               10.9   \n",
       "4      47.900002      88275.796875           0.6  ...               10.2   \n",
       "\n",
       "   sun_azimuth:d_sin  sun_azimuth:d_cos  hour  dayofmonth  dayofweek  quarter  \\\n",
       "0          -0.827235           3.904145    22           2          6        2   \n",
       "1           0.137934           3.988335    23           2          6        2   \n",
       "2           1.028531           3.856086     0           3          0        2   \n",
       "3           1.912442           3.503262     1           3          0        2   \n",
       "4           2.670854           2.966543     2           3          0        2   \n",
       "\n",
       "   month  year  dayofyear  \n",
       "0      6  2019        153  \n",
       "1      6  2019        153  \n",
       "2      6  2019        154  \n",
       "3      6  2019        154  \n",
       "4      6  2019        154  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first renaming the date_forecast columns to time  (DOES NOT WORK)\n",
    "for df in list_of_all_estimated_and_observed_sets:               \n",
    "    df.rename(columns={'date_forecast': 'time'}, inplace=True)\n",
    "\n",
    "#maybe we can drop it here already actually\n",
    "X_train_observed_a.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data = first 75% of observed + first 75% of estimated\n",
    "Validation data = last 25% of observed + last 25% of estimated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34085, 43) (34085, 2)\n",
      "(32843, 43) (32843, 2)\n",
      "(26095, 43) (26095, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Making training and validation data for A\n",
    "percent_observed_train_a = 1\n",
    "percent_estimated_train_a = 1\n",
    "\n",
    "split_index_obs_a = int(len(X_train_observed_a)*percent_observed_train_a)\n",
    "X_train_observed_a_first_75 = X_train_observed_a[:split_index_obs_a]\n",
    "X_train_observed_a_last_25 = X_train_observed_a[split_index_obs_a:]\n",
    "\n",
    "split_index_est_a = int(len(X_train_estimated_a)*percent_estimated_train_a)\n",
    "X_train_estimated_a_first_75 = X_train_estimated_a[:split_index_est_a]\n",
    "X_train_estimated_a_last_25 = X_train_estimated_a[split_index_est_a:]\n",
    "\n",
    "X_train_a = pd.concat([X_train_observed_a_first_75, X_train_estimated_a_first_75])\n",
    "y_train_a = y_a[y_a[\"time\"].isin(X_train_a['date_forecast'])]\n",
    "print(X_train_a.shape, y_train_a.shape)\n",
    "\n",
    "X_validate_a = pd.concat([X_train_observed_a_last_25, X_train_estimated_a_last_25])\n",
    "y_validate_a = y_a[y_a[\"time\"].isin(X_validate_a['date_forecast'])]\n",
    "\n",
    "\n",
    "# making training and validation for B\n",
    "percent_observed_train_b = 1\n",
    "percent_estimated_train_b = 1\n",
    "\n",
    "split_index_obs_b = int(len(X_train_observed_b)*percent_observed_train_b)\n",
    "X_train_observed_b_first_75 = X_train_observed_b[:split_index_obs_b]\n",
    "X_train_observed_b_last_25 = X_train_observed_b[split_index_obs_b:]\n",
    "\n",
    "\n",
    "split_index_est_b = int(len(X_train_estimated_b)*percent_estimated_train_b)\n",
    "X_train_estimated_b_first_75 = X_train_estimated_b[:split_index_est_b]\n",
    "X_train_estimated_b_last_25 = X_train_estimated_b[split_index_est_b:]\n",
    "\n",
    "X_train_b = pd.concat([X_train_observed_b_first_75, X_train_estimated_b_first_75])\n",
    "y_train_b = y_b[y_b[\"time\"].isin(X_train_b['date_forecast'])]\n",
    "print(X_train_b.shape, y_train_b.shape)\n",
    "\n",
    "X_validate_b = pd.concat([X_train_observed_b_last_25, X_train_estimated_b_last_25])\n",
    "y_validate_b = y_b[y_b[\"time\"].isin(X_validate_b['date_forecast'])]\n",
    "\n",
    "# making training and validation for C\n",
    "percent_observed_train_c = 1\n",
    "percent_estimated_train_c = 1\n",
    "\n",
    "split_index_obs_c = int(len(X_train_observed_c)*percent_observed_train_c)\n",
    "X_train_observed_c_first_75 = X_train_observed_c[:split_index_obs_c]\n",
    "X_train_observed_c_last_25 = X_train_observed_c[split_index_obs_c:]\n",
    "\n",
    "split_index_est_c = int(len(X_train_estimated_c)*percent_estimated_train_c)\n",
    "X_train_estimated_c_first_75 = X_train_estimated_c[:split_index_est_c]\n",
    "X_train_estimated_c_last_25 = X_train_estimated_c[split_index_est_c:]\n",
    "\n",
    "X_train_c = pd.concat([X_train_observed_c_first_75, X_train_estimated_c_first_75])\n",
    "y_train_c = y_c[y_c[\"time\"].isin(X_train_c['date_forecast'])]\n",
    "print(X_train_c.shape, y_train_c.shape)\n",
    "\n",
    "X_validate_c = pd.concat([X_train_observed_c_last_25, X_train_estimated_c_last_25])\n",
    "y_validate_c = y_c[y_c[\"time\"].isin(X_validate_c['date_forecast'])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing repeated indexes here, think this might be the wrong place to do it, should probably to it for the concat BUT hEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_repeated_indexes(df, column_name, repeat_count=12):\n",
    "    \"\"\"\n",
    "    Find and return the indexes of rows with a specified number of repeated values in a given column.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame to search for repeated rows.\n",
    "    - column_name: Name of the column to check for repeated values.\n",
    "    - repeat_count: Number of repeated values required to consider a row as a match.\n",
    "\n",
    "    Returns:\n",
    "    - List of indexes for rows with the specified number of repeated values in the given column.\n",
    "    \"\"\"\n",
    "    df = df.reset_index()\n",
    "    repeated_indexes = []\n",
    "    temp_repeated_indexes = []\n",
    "    current_value = None\n",
    "    count = 0\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        value = row[column_name]\n",
    "\n",
    "        if value == current_value:\n",
    "            count += 1\n",
    "            temp_repeated_indexes.append(index)\n",
    "        else:\n",
    "            current_value = value\n",
    "            if count <= repeat_count:\n",
    "                temp_repeated_indexes = []\n",
    "                count = 1\n",
    "            else:\n",
    "                for i in temp_repeated_indexes:\n",
    "                    if i not in repeated_indexes:\n",
    "                        repeated_indexes.append(i)\n",
    "                temp_repeated_indexes = []\n",
    "                count = 1\n",
    "            \n",
    "\n",
    "    return repeated_indexes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34085, 43) (34085, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34043, 43) (34043, 3)\n"
     ]
    }
   ],
   "source": [
    "#removing repeated indexes\n",
    "\n",
    "#A\n",
    "print(X_train_a.shape, y_train_a.shape)\n",
    "repeated_indices = find_repeated_indexes(y_train_a,\"pv_measurement\", 24)\n",
    "y_train_a = y_train_a.reset_index()\n",
    "y_train_a = y_train_a.drop(repeated_indices)\n",
    "X_train_a = X_train_a[X_train_a[\"date_forecast\"].isin(y_train_a[\"time\"])]\n",
    "print(X_train_a.shape, y_train_a.shape)\n",
    "\n",
    "repeated_indices = find_repeated_indexes(y_validate_a,\"pv_measurement\",22)\n",
    "y_validate_a = y_validate_a.reset_index()\n",
    "y_validate_a = y_validate_a.drop(repeated_indices)\n",
    "X_validate_a = X_validate_a[X_validate_a[\"date_forecast\"].isin(y_validate_a[\"time\"])]\n",
    "\n",
    "y_train_a.reset_index(drop=True, inplace=True)\n",
    "X_train_a.reset_index(drop=True, inplace=True)\n",
    "y_validate_a.reset_index(drop=True, inplace=True)\n",
    "X_validate_a.reset_index(drop=True, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32843, 43) (32843, 2)\n",
      "(25954, 43) (25954, 3)\n"
     ]
    }
   ],
   "source": [
    "#B  -  works reeaaaly well for B\n",
    "print(X_train_b.shape, y_train_b.shape)\n",
    "repeated_indices = find_repeated_indexes(y_train_b,\"pv_measurement\", 24)\n",
    "y_train_b = y_train_b.reset_index()\n",
    "y_train_b = y_train_b.drop(repeated_indices)\n",
    "X_train_b = X_train_b[X_train_b[\"date_forecast\"].isin(y_train_b[\"time\"])]\n",
    "print(X_train_b.shape, y_train_b.shape)\n",
    "\n",
    "repeated_indices = find_repeated_indexes(y_validate_b,\"pv_measurement\",24)\n",
    "y_validate_b = y_validate_b.reset_index()\n",
    "y_validate_b = y_validate_b.drop(repeated_indices)\n",
    "X_validate_b = X_validate_b[X_validate_b[\"date_forecast\"].isin(y_validate_b[\"time\"])]\n",
    "\n",
    "y_train_b.reset_index(drop=True, inplace=True)\n",
    "X_train_b.reset_index(drop=True, inplace=True)\n",
    "y_validate_b.reset_index(drop=True, inplace=True)\n",
    "X_validate_b.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26095, 43) (26095, 2)\n",
      "(21169, 43) (21169, 3)\n"
     ]
    }
   ],
   "source": [
    "#C\n",
    "print(X_train_c.shape, y_train_c.shape)\n",
    "repeated_indices = find_repeated_indexes(y_train_c,\"pv_measurement\", 24)\n",
    "y_train_c = y_train_c.reset_index()\n",
    "y_train_c = y_train_c.drop(repeated_indices)\n",
    "X_train_c = X_train_c[X_train_c[\"date_forecast\"].isin(y_train_c[\"time\"])]\n",
    "print(X_train_c.shape, y_train_c.shape)\n",
    "\n",
    "repeated_indices = find_repeated_indexes(y_validate_c,\"pv_measurement\",24)\n",
    "y_validate_c = y_validate_c.reset_index()\n",
    "y_validate_c = y_validate_c.drop(repeated_indices)\n",
    "X_validate_c = X_validate_c[X_validate_c[\"date_forecast\"].isin(y_validate_c[\"time\"])]\n",
    "\n",
    "y_train_c.reset_index(drop=True, inplace=True)\n",
    "X_train_c.reset_index(drop=True, inplace=True)\n",
    "y_validate_c.reset_index(drop=True, inplace=True)\n",
    "X_validate_c.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing time feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_a.drop(\"date_forecast\", axis=1, inplace=True)\n",
    "y_train_a.drop(\"time\", axis=1, inplace=True)\n",
    "X_validate_a.drop(\"date_forecast\", axis=1, inplace=True)\n",
    "y_validate_a.drop(\"time\", axis=1, inplace=True)\n",
    "\n",
    "X_train_b.drop(\"date_forecast\", axis=1, inplace=True)\n",
    "y_train_b.drop(\"time\", axis=1, inplace=True)\n",
    "X_validate_b.drop(\"date_forecast\", axis=1, inplace=True)\n",
    "y_validate_b.drop(\"time\", axis=1, inplace=True)\n",
    "\n",
    "X_train_c.drop(\"date_forecast\", axis=1, inplace=True)\n",
    "y_train_c.drop(\"time\", axis=1, inplace=True)\n",
    "X_validate_c.drop(\"date_forecast\", axis=1, inplace=True)\n",
    "y_validate_c.drop(\"time\", axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding location features to the sets before merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_a[\"location\"] =  \"A\" \n",
    "y_train_a[\"location\"] = \"A\"\n",
    "X_validate_a[\"location\"] = \"A\"\n",
    "y_validate_a[\"location\"] = \"A\"\n",
    "\n",
    "X_train_b[\"location\"] = \"B\"\n",
    "y_train_b[\"location\"] = \"B\"\n",
    "X_validate_b[\"location\"] = \"B\"\n",
    "y_validate_b[\"location\"] = \"B\"\n",
    "\n",
    "X_train_c[\"location\"] = \"C\"\n",
    "y_train_c[\"location\"] = \"C\"\n",
    "X_validate_c[\"location\"] = \"C\"\n",
    "y_validate_c[\"location\"] = \"C\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging tranining data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81166, 43)\n",
      "(81166, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.concat([X_train_a, X_train_b, X_train_c])\n",
    "y_train = pd.concat([y_train_a, y_train_b, y_train_c])\n",
    "\n",
    "X_validate = pd.concat([X_validate_a, X_validate_b, X_validate_c])\n",
    "y_validate = pd.concat([y_validate_a, y_validate_b, y_validate_c])\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding and dropping location feature   some fuckery here\n",
    "# one_hot = pd.get_dummies(X_train[\"location\"]).astype(int)\n",
    "# X_train = X_train.drop(\"location\", axis=1)\n",
    "# X_train = pd.merge(X_train, one_hot, left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "# one_hot = pd.get_dummies(X_validate[\"location\"]).astype(int)\n",
    "# X_validate = pd.merge(X_validate, one_hot, left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixing test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load valid dates function\n",
    "import os\n",
    "\n",
    "\n",
    "dir_path = os.getcwd()\n",
    "def load_valid_dates():\n",
    "    \n",
    "    test = pd.read_csv(f\"{dir_path}/../data/test.csv\")\n",
    "\n",
    "    return test[\"time\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding location feature\n",
    "\n",
    "X_test_estimated_a[\"location\"] = \"A\"\n",
    "X_test_estimated_b[\"location\"] = \"B\"\n",
    "X_test_estimated_c[\"location\"] = \"C\"\n",
    "\n",
    "# concatting:\n",
    "X_test = pd.concat([X_test_estimated_a, X_test_estimated_b, X_test_estimated_c])\n",
    "# filtering out invalid dates:\n",
    "X_test = X_test[X_test[\"date_forecast\"].isin(load_valid_dates())]\n",
    "# removing forecast coloum\n",
    "X_test = X_test.drop(\"date_forecast\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute_humidity_2m:gm3</th>\n",
       "      <th>air_density_2m:kgm3</th>\n",
       "      <th>clear_sky_energy_1h:J</th>\n",
       "      <th>clear_sky_rad:W</th>\n",
       "      <th>dew_or_rime:idx</th>\n",
       "      <th>dew_point_2m:K</th>\n",
       "      <th>diffuse_rad:W</th>\n",
       "      <th>diffuse_rad_1h:J</th>\n",
       "      <th>direct_rad:W</th>\n",
       "      <th>direct_rad_1h:J</th>\n",
       "      <th>...</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofmonth</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>quarter</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.300001</td>\n",
       "      <td>5.147</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1086.600098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2023</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.100000</td>\n",
       "      <td>5.144</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1085.800049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2023</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.599998</td>\n",
       "      <td>5.135</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1084.199951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2023</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.100000</td>\n",
       "      <td>5.128</td>\n",
       "      <td>4.049770e+04</td>\n",
       "      <td>46.700001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1082.599976</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>67380.906250</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>15061.400391</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2023</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.600000</td>\n",
       "      <td>5.124</td>\n",
       "      <td>5.669944e+05</td>\n",
       "      <td>307.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1081.500000</td>\n",
       "      <td>189.600006</td>\n",
       "      <td>408838.812500</td>\n",
       "      <td>101.800003</td>\n",
       "      <td>198284.796875</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2023</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>33.599998</td>\n",
       "      <td>4.787</td>\n",
       "      <td>1.903926e+06</td>\n",
       "      <td>339.100006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1126.800049</td>\n",
       "      <td>128.800003</td>\n",
       "      <td>650270.125000</td>\n",
       "      <td>53.800003</td>\n",
       "      <td>212259.687500</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2023</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>34.400002</td>\n",
       "      <td>4.800</td>\n",
       "      <td>7.330454e+05</td>\n",
       "      <td>98.199997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1128.099976</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>331501.406250</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>114095.203125</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2023</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>35.500000</td>\n",
       "      <td>4.814</td>\n",
       "      <td>1.473243e+05</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1129.400024</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>108841.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17289.900391</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2023</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>4.826</td>\n",
       "      <td>1.378300e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1130.400024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8968.599609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2023</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>35.799999</td>\n",
       "      <td>4.828</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1129.900024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2023</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2160 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      absolute_humidity_2m:gm3  air_density_2m:kgm3  clear_sky_energy_1h:J  \\\n",
       "0                    17.300001                5.147           0.000000e+00   \n",
       "1                    17.100000                5.144           0.000000e+00   \n",
       "2                    16.599998                5.135           0.000000e+00   \n",
       "3                    16.100000                5.128           4.049770e+04   \n",
       "4                    15.600000                5.124           5.669944e+05   \n",
       "...                        ...                  ...                    ...   \n",
       "2155                 33.599998                4.787           1.903926e+06   \n",
       "2156                 34.400002                4.800           7.330454e+05   \n",
       "2157                 35.500000                4.814           1.473243e+05   \n",
       "2158                 36.000000                4.826           1.378300e+03   \n",
       "2159                 35.799999                4.828           0.000000e+00   \n",
       "\n",
       "      clear_sky_rad:W  dew_or_rime:idx  dew_point_2m:K  diffuse_rad:W  \\\n",
       "0            0.000000              0.0     1086.600098       0.000000   \n",
       "1            0.000000              0.0     1085.800049       0.000000   \n",
       "2            0.000000              0.0     1084.199951       0.000000   \n",
       "3           46.700001              0.0     1082.599976      37.500000   \n",
       "4          307.500000              0.0     1081.500000     189.600006   \n",
       "...               ...              ...             ...            ...   \n",
       "2155       339.100006              0.0     1126.800049     128.800003   \n",
       "2156        98.199997              0.0     1128.099976      55.500000   \n",
       "2157         4.900000              0.0     1129.400024       5.000000   \n",
       "2158         0.000000              0.0     1130.400024       0.000000   \n",
       "2159         0.000000              0.0     1129.900024       0.000000   \n",
       "\n",
       "      diffuse_rad_1h:J  direct_rad:W  direct_rad_1h:J  ...  hour  dayofmonth  \\\n",
       "0             0.000000      0.000000         0.000000  ...     0           1   \n",
       "1             0.000000      0.000000         0.000000  ...     1           1   \n",
       "2             0.000000      0.000000         0.000000  ...     2           1   \n",
       "3         67380.906250      8.400000     15061.400391  ...     3           1   \n",
       "4        408838.812500    101.800003    198284.796875  ...     4           1   \n",
       "...                ...           ...              ...  ...   ...         ...   \n",
       "2155     650270.125000     53.800003    212259.687500  ...    19           3   \n",
       "2156     331501.406250      9.600000    114095.203125  ...    20           3   \n",
       "2157     108841.000000      0.000000     17289.900391  ...    21           3   \n",
       "2158       8968.599609      0.000000         0.000000  ...    22           3   \n",
       "2159          0.000000      0.000000         0.000000  ...    23           3   \n",
       "\n",
       "      dayofweek  quarter  month  year  dayofyear  A  B  C  \n",
       "0             0        2      5  2023        121  1  0  0  \n",
       "1             0        2      5  2023        121  1  0  0  \n",
       "2             0        2      5  2023        121  1  0  0  \n",
       "3             0        2      5  2023        121  1  0  0  \n",
       "4             0        2      5  2023        121  1  0  0  \n",
       "...         ...      ...    ...   ...        ... .. .. ..  \n",
       "2155          0        3      7  2023        184  0  0  1  \n",
       "2156          0        3      7  2023        184  0  0  1  \n",
       "2157          0        3      7  2023        184  0  0  1  \n",
       "2158          0        3      7  2023        184  0  0  1  \n",
       "2159          0        3      7  2023        184  0  0  1  \n",
       "\n",
       "[2160 rows x 45 columns]"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reset_index().drop(columns=\"index\")\n",
    "one_hot = pd.get_dummies(X_train[\"location\"]).astype(int)\n",
    "X_train = X_train.drop(\"location\", axis=1)\n",
    "X_train = pd.merge(X_train, one_hot, left_index=True, right_index=True)\n",
    "\n",
    "X_validate = X_validate.reset_index().drop(columns=\"index\")\n",
    "one_hot = pd.get_dummies(X_validate[\"location\"]).astype(int)\n",
    "X_validate = X_validate.drop(\"location\", axis=1)\n",
    "X_validate = pd.merge(X_validate, one_hot, left_index=True, right_index=True)\n",
    "\n",
    "X_test = X_test.reset_index().drop(columns=\"index\")\n",
    "one_hot = pd.get_dummies(X_test[\"location\"]).astype(int)\n",
    "X_test = X_test.drop(\"location\", axis=1)\n",
    "X_test = pd.merge(X_test, one_hot, left_index=True, right_index=True)\n",
    "\n",
    "X_test\n",
    "# one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_exclude = [\"A\", \"B\", \"C\", \"dew_or_rime:idx\", \"is_day:idx\", \"_in_shadow:idx\"]\n",
    "\n",
    "columns_to_normalize = [col for col in X_train.columns if col not in columns_to_exclude]\n",
    "\n",
    "#Mean - std normalization\n",
    "\n",
    "# X_train_mean = X_train.mean()\n",
    "# X_train_std = X_train.std()\n",
    "\n",
    "# X_train = (X_train - X_train_mean) / X_train_std\n",
    "# X_validate = (X_validate- X_train_mean) / X_train_std\n",
    "# X_test =  (X_test - X_train_mean) / X_train_std\n",
    "\n",
    "\n",
    "#Min-max\n",
    "# Calculate min and max values for scaling\n",
    "X_min = X_train[columns_to_normalize].min()\n",
    "X_max = X_train[columns_to_normalize].max()\n",
    "\n",
    "# Apply min-max scaling to the columns to be normalized\n",
    "X_train[columns_to_normalize] = (X_train[columns_to_normalize] - X_min) / (X_max - X_min)\n",
    "X_validate[columns_to_normalize] = (X_validate[columns_to_normalize] - X_min) / (X_max - X_min)\n",
    "X_test[columns_to_normalize] = (X_test[columns_to_normalize] - X_min) / (X_max - X_min)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       index  pv_measurement location\n",
      "0          0            0.00        A\n",
      "1          1            0.00        A\n",
      "2          2            0.00        A\n",
      "3          3            0.00        A\n",
      "4          4           19.36        A\n",
      "...      ...             ...      ...\n",
      "21164  32150           50.96        C\n",
      "21165  32151            2.94        C\n",
      "21166  32152            0.00        C\n",
      "21167  32153           -0.00        C\n",
      "21168  32154           -0.00        C\n",
      "\n",
      "[81166 rows x 3 columns]\n",
      "       index  pv_measurement location\n",
      "0          0        0.000000        A\n",
      "1          1        0.000000        A\n",
      "2          2        0.000000        A\n",
      "3          3        0.000000        A\n",
      "4          4        0.003377        A\n",
      "...      ...             ...      ...\n",
      "21164  32150        0.008888        C\n",
      "21165  32151        0.000513        C\n",
      "21166  32152        0.000000        C\n",
      "21167  32153        0.000000        C\n",
      "21168  32154        0.000000        C\n",
      "\n",
      "[81166 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "y_scaler = MinMaxScaler()\n",
    "print(y_train)\n",
    "\n",
    "\n",
    "y_train[\"pv_measurement\"] = y_scaler.fit_transform(y_train[\"pv_measurement\"].values.reshape(-1,1))\n",
    "\n",
    "print(y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siver\\azure\\venv913\\lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\Users\\siver\\azure\\venv913\\lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\Users\\siver\\azure\\venv913\\lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\siver\\azure\\venv913\\lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\Users\\siver\\azure\\venv913\\lib\\site-packages\\xgboost\\data.py:520: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=True, eta=0.1, eval_metric=None,\n",
       "             feature_types=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=90,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=True, eta=0.1, eval_metric=None,\n",
       "             feature_types=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=90,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=True, eta=0.1, eval_metric=None,\n",
       "             feature_types=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=90,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = xgb.XGBRegressor(\n",
    "#     max_depth=7,\n",
    "#     colsample_bytree=0.8,\n",
    "#     eta=0.1,\n",
    "#     n_estimators=90,\n",
    "#     reg_alpha=0.01,\n",
    "#     reg_lambda=0.01,\n",
    "#     enable_categorical=True\n",
    "# )\n",
    "\n",
    "# model.fit(X_train, y_train[\"pv_measurement\"])\n",
    "\n",
    "# X_validate_a_loc = X_validate[X_validate_a[\"location\"]==\"A\"]\n",
    "# X_validate_a_loc = X_validate_a_loc.drop(\"location\", axis=1)\n",
    "\n",
    "# prediction = model.predict(X_validate)\n",
    "\n",
    "# prediction_a = model.predict(X_validate_a)\n",
    "# prediction_b = model.predict(X_validate_b)\n",
    "# prediction_c = model.predict(X_validate_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [0, 13250]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\siver\\NTNU Høst 2023\\Machine Learning\\Group Project\\tdt4173-forecasting\\notebooks\\siverts_super_model.ipynb Cell 60\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/siver/NTNU%20H%C3%B8st%202023/Machine%20Learning/Group%20Project/tdt4173-forecasting/notebooks/siverts_super_model.ipynb#Y111sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/siver/NTNU%20H%C3%B8st%202023/Machine%20Learning/Group%20Project/tdt4173-forecasting/notebooks/siverts_super_model.ipynb#Y111sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mMAE: \u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/siver/NTNU%20H%C3%B8st%202023/Machine%20Learning/Group%20Project/tdt4173-forecasting/notebooks/siverts_super_model.ipynb#Y111sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mround\u001b[39m(\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/siver/NTNU%20H%C3%B8st%202023/Machine%20Learning/Group%20Project/tdt4173-forecasting/notebooks/siverts_super_model.ipynb#Y111sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         mean_absolute_error(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/siver/NTNU%20H%C3%B8st%202023/Machine%20Learning/Group%20Project/tdt4173-forecasting/notebooks/siverts_super_model.ipynb#Y111sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m             y_true\u001b[39m=\u001b[39;49my_validate[\u001b[39m\"\u001b[39;49m\u001b[39mpv_measurement\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/siver/NTNU%20H%C3%B8st%202023/Machine%20Learning/Group%20Project/tdt4173-forecasting/notebooks/siverts_super_model.ipynb#Y111sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m             y_pred\u001b[39m=\u001b[39;49mprediction,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/siver/NTNU%20H%C3%B8st%202023/Machine%20Learning/Group%20Project/tdt4173-forecasting/notebooks/siverts_super_model.ipynb#Y111sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         ),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/siver/NTNU%20H%C3%B8st%202023/Machine%20Learning/Group%20Project/tdt4173-forecasting/notebooks/siverts_super_model.ipynb#Y111sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         \u001b[39m3\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/siver/NTNU%20H%C3%B8st%202023/Machine%20Learning/Group%20Project/tdt4173-forecasting/notebooks/siverts_super_model.ipynb#Y111sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     ),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/siver/NTNU%20H%C3%B8st%202023/Machine%20Learning/Group%20Project/tdt4173-forecasting/notebooks/siverts_super_model.ipynb#Y111sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\siver\\azure\\venv913\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\siver\\azure\\venv913\\lib\\site-packages\\sklearn\\metrics\\_regression.py:204\u001b[0m, in \u001b[0;36mmean_absolute_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[0;32m    141\u001b[0m     {\n\u001b[0;32m    142\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, multioutput\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39muniform_average\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    151\u001b[0m ):\n\u001b[0;32m    152\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Mean absolute error regression loss.\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \n\u001b[0;32m    154\u001b[0m \u001b[39m    Read more in the :ref:`User Guide <mean_absolute_error>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39m    0.85...\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 204\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[39m=\u001b[39m _check_reg_targets(\n\u001b[0;32m    205\u001b[0m         y_true, y_pred, multioutput\n\u001b[0;32m    206\u001b[0m     )\n\u001b[0;32m    207\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    208\u001b[0m     output_errors \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39maverage(np\u001b[39m.\u001b[39mabs(y_pred \u001b[39m-\u001b[39m y_true), weights\u001b[39m=\u001b[39msample_weight, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\siver\\azure\\venv913\\lib\\site-packages\\sklearn\\metrics\\_regression.py:99\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_reg_targets\u001b[39m(y_true, y_pred, multioutput, dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     66\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \n\u001b[0;32m     68\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[39m        correct keyword.\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[0;32m    100\u001b[0m     y_true \u001b[39m=\u001b[39m check_array(y_true, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    101\u001b[0m     y_pred \u001b[39m=\u001b[39m check_array(y_pred, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\siver\\azure\\venv913\\lib\\site-packages\\sklearn\\utils\\validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    405\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    406\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 407\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    408\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    409\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    410\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [0, 13250]"
     ]
    }
   ],
   "source": [
    "# print(\n",
    "#     \"MAE: \",\n",
    "#     round(\n",
    "#         mean_absolute_error(\n",
    "#             y_true=y_validate[\"pv_measurement\"],\n",
    "#             y_pred=prediction,\n",
    "#         ),\n",
    "#         3,\n",
    "#     ),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2160,)\n",
      "(2160, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siver\\azure\\venv913\\lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\Users\\siver\\azure\\venv913\\lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\Users\\siver\\azure\\venv913\\lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\siver\\azure\\venv913\\lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n"
     ]
    }
   ],
   "source": [
    "# predicting:\n",
    "# predict = model.predict(X_test)\n",
    "# print(predict.head())\n",
    "# predict = y_scaler.inverse_transform(predict.reshape(-1, 1))\n",
    "# print(predict.head())\n",
    "\n",
    "# resultframe = pd.DataFrame(columns = [\"id\", \"prediction\"])\n",
    "# resultframe[\"prediction\"] = predict\n",
    "# print(resultframe.shape)\n",
    "# resultframe[\"id\"] = range(len(resultframe))\n",
    "# resultframe.head()\n",
    "# # making the csv\n",
    "# # final = prediction.reset_index().reset_index().rename(columns={\"level_0\": \"id\", \"y\": \"prediction\"})[[\"id\", \"prediction\"]]\n",
    "\n",
    "# resultframe.to_csv(\"submission_super_all_the_guys_6.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute_humidity_2m:gm3</th>\n",
       "      <th>air_density_2m:kgm3</th>\n",
       "      <th>clear_sky_energy_1h:J</th>\n",
       "      <th>clear_sky_rad:W</th>\n",
       "      <th>dew_or_rime:idx</th>\n",
       "      <th>dew_point_2m:K</th>\n",
       "      <th>diffuse_rad:W</th>\n",
       "      <th>diffuse_rad_1h:J</th>\n",
       "      <th>direct_rad:W</th>\n",
       "      <th>direct_rad_1h:J</th>\n",
       "      <th>...</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofmonth</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>quarter</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.249280</td>\n",
       "      <td>0.902191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.925160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.328767</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.246398</td>\n",
       "      <td>0.901665</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.924479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.328767</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.239193</td>\n",
       "      <td>0.900088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.923116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.328767</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.231988</td>\n",
       "      <td>0.898861</td>\n",
       "      <td>0.003385</td>\n",
       "      <td>0.013971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.921754</td>\n",
       "      <td>0.028006</td>\n",
       "      <td>0.014057</td>\n",
       "      <td>0.003073</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.328767</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.224784</td>\n",
       "      <td>0.898160</td>\n",
       "      <td>0.047398</td>\n",
       "      <td>0.091994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.920817</td>\n",
       "      <td>0.141598</td>\n",
       "      <td>0.085295</td>\n",
       "      <td>0.037240</td>\n",
       "      <td>0.020301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.328767</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   absolute_humidity_2m:gm3  air_density_2m:kgm3  clear_sky_energy_1h:J  \\\n",
       "0                  0.249280             0.902191               0.000000   \n",
       "1                  0.246398             0.901665               0.000000   \n",
       "2                  0.239193             0.900088               0.000000   \n",
       "3                  0.231988             0.898861               0.003385   \n",
       "4                  0.224784             0.898160               0.047398   \n",
       "\n",
       "   clear_sky_rad:W  dew_or_rime:idx  dew_point_2m:K  diffuse_rad:W  \\\n",
       "0         0.000000              0.0        0.925160       0.000000   \n",
       "1         0.000000              0.0        0.924479       0.000000   \n",
       "2         0.000000              0.0        0.923116       0.000000   \n",
       "3         0.013971              0.0        0.921754       0.028006   \n",
       "4         0.091994              0.0        0.920817       0.141598   \n",
       "\n",
       "   diffuse_rad_1h:J  direct_rad:W  direct_rad_1h:J  ...      hour  dayofmonth  \\\n",
       "0          0.000000      0.000000         0.000000  ...  0.000000         0.0   \n",
       "1          0.000000      0.000000         0.000000  ...  0.043478         0.0   \n",
       "2          0.000000      0.000000         0.000000  ...  0.086957         0.0   \n",
       "3          0.014057      0.003073         0.001542  ...  0.130435         0.0   \n",
       "4          0.085295      0.037240         0.020301  ...  0.173913         0.0   \n",
       "\n",
       "   dayofweek   quarter     month  year  dayofyear  A  B  C  \n",
       "0        0.0  0.333333  0.363636   1.0   0.328767  1  0  0  \n",
       "1        0.0  0.333333  0.363636   1.0   0.328767  1  0  0  \n",
       "2        0.0  0.333333  0.363636   1.0   0.328767  1  0  0  \n",
       "3        0.0  0.333333  0.363636   1.0   0.328767  1  0  0  \n",
       "4        0.0  0.333333  0.363636   1.0   0.328767  1  0  0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-3.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-3 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-3 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-3 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table th,\n",
       "#h2o-table-3 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-3 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-3\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>58 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Oslo</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.42.0.4</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>9 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_siver_g59qy3</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>1.427 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.9.13 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         58 secs\n",
       "H2O_cluster_timezone:       Europe/Oslo\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.42.0.4\n",
       "H2O_cluster_version_age:    9 days\n",
       "H2O_cluster_name:           H2O_from_python_siver_g59qy3\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    1.427 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.9.13 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |█\n",
      "09:55:36.721: AutoML: XGBoost is not available; skipping it.\n",
      "\n",
      "██████████████████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "h2o.init()\n",
    "\n",
    "X_train = X_train.reset_index().drop(columns=\"index\")\n",
    "y_train = y_train.reset_index().drop(columns=\"index\")\n",
    "new_train = pd.merge(X_train, y_train[\"pv_measurement\"], left_index=True, right_index=True)\n",
    "\n",
    "X_validate = X_validate.reset_index().drop(columns=\"index\")\n",
    "y_validate = y_validate.reset_index().drop(columns=\"index\")\n",
    "new_validate = pd.merge(X_validate, y_validate[\"pv_measurement\"], left_index=True, right_index=True)\n",
    "\n",
    "h2o_train= h2o.H2OFrame(new_train)\n",
    "h2o_validate= h2o.H2OFrame(new_validate)\n",
    "h2o_test = h2o.H2OFrame(X_test)\n",
    "\n",
    "aml = H2OAutoML(max_models=20, seed=1, stopping_metric=\"MAE\", sort_metric=\"MAE\", stopping_tolerance=0.01)\n",
    "# aml.train(x=h2o_train.columns, y=\"pv_measurement\", training_frame=h2o_train, validation_frame=h2o_validate)\n",
    "aml.train(x=h2o_train.columns, y=\"pv_measurement\", training_frame=h2o_train)\n",
    "lb = aml.leaderboard\n",
    "preds = aml.leader.predict(h2o_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th>model_id                                              </th><th style=\"text-align: right;\">      mae</th><th style=\"text-align: right;\">     rmse</th><th style=\"text-align: right;\">       mse</th><th style=\"text-align: right;\">    rmsle</th><th style=\"text-align: right;\">  mean_residual_deviance</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20231013_95536_model_5            </td><td style=\"text-align: right;\">0.0146351</td><td style=\"text-align: right;\">0.0441073</td><td style=\"text-align: right;\">0.00194545</td><td style=\"text-align: right;\">0.0325936</td><td style=\"text-align: right;\">              0.00194545</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_1_AutoML_1_20231013_95536   </td><td style=\"text-align: right;\">0.0148685</td><td style=\"text-align: right;\">0.0429196</td><td style=\"text-align: right;\">0.00184209</td><td style=\"text-align: right;\">0.031728 </td><td style=\"text-align: right;\">              0.00184209</td></tr>\n",
       "<tr><td>GBM_4_AutoML_1_20231013_95536                         </td><td style=\"text-align: right;\">0.0149636</td><td style=\"text-align: right;\">0.0445948</td><td style=\"text-align: right;\">0.0019887 </td><td style=\"text-align: right;\">0.0329688</td><td style=\"text-align: right;\">              0.0019887 </td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_1_AutoML_1_20231013_95536</td><td style=\"text-align: right;\">0.0151436</td><td style=\"text-align: right;\">0.0439629</td><td style=\"text-align: right;\">0.00193274</td><td style=\"text-align: right;\">0.0325099</td><td style=\"text-align: right;\">              0.00193274</td></tr>\n",
       "<tr><td>GBM_3_AutoML_1_20231013_95536                         </td><td style=\"text-align: right;\">0.0154723</td><td style=\"text-align: right;\">0.0456152</td><td style=\"text-align: right;\">0.00208074</td><td style=\"text-align: right;\">0.0337079</td><td style=\"text-align: right;\">              0.00208074</td></tr>\n",
       "<tr><td>GBM_1_AutoML_1_20231013_95536                         </td><td style=\"text-align: right;\">0.0157797</td><td style=\"text-align: right;\">0.0464368</td><td style=\"text-align: right;\">0.00215637</td><td style=\"text-align: right;\">0.0343431</td><td style=\"text-align: right;\">              0.00215637</td></tr>\n",
       "<tr><td>DRF_1_AutoML_1_20231013_95536                         </td><td style=\"text-align: right;\">0.0158048</td><td style=\"text-align: right;\">0.0464803</td><td style=\"text-align: right;\">0.00216042</td><td style=\"text-align: right;\">0.0344129</td><td style=\"text-align: right;\">              0.00216042</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20231013_95536_model_4            </td><td style=\"text-align: right;\">0.0159132</td><td style=\"text-align: right;\">0.0445029</td><td style=\"text-align: right;\">0.00198051</td><td style=\"text-align: right;\">0.032943 </td><td style=\"text-align: right;\">              0.00198051</td></tr>\n",
       "<tr><td>GBM_2_AutoML_1_20231013_95536                         </td><td style=\"text-align: right;\">0.0160824</td><td style=\"text-align: right;\">0.0466329</td><td style=\"text-align: right;\">0.00217462</td><td style=\"text-align: right;\">0.0345066</td><td style=\"text-align: right;\">              0.00217462</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20231013_95536_model_1            </td><td style=\"text-align: right;\">0.0164544</td><td style=\"text-align: right;\">0.044885 </td><td style=\"text-align: right;\">0.00201466</td><td style=\"text-align: right;\">0.0332722</td><td style=\"text-align: right;\">              0.00201466</td></tr>\n",
       "<tr><td>GBM_5_AutoML_1_20231013_95536                         </td><td style=\"text-align: right;\">0.0164982</td><td style=\"text-align: right;\">0.0475775</td><td style=\"text-align: right;\">0.00226362</td><td style=\"text-align: right;\">0.0352173</td><td style=\"text-align: right;\">              0.00226362</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20231013_95536_model_3            </td><td style=\"text-align: right;\">0.0171798</td><td style=\"text-align: right;\">0.0487559</td><td style=\"text-align: right;\">0.00237714</td><td style=\"text-align: right;\">0.0360994</td><td style=\"text-align: right;\">              0.00237714</td></tr>\n",
       "<tr><td>XRT_1_AutoML_1_20231013_95536                         </td><td style=\"text-align: right;\">0.0173415</td><td style=\"text-align: right;\">0.0473872</td><td style=\"text-align: right;\">0.00224554</td><td style=\"text-align: right;\">0.0350301</td><td style=\"text-align: right;\">              0.00224554</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20231013_95536_model_2            </td><td style=\"text-align: right;\">0.0183952</td><td style=\"text-align: right;\">0.0505604</td><td style=\"text-align: right;\">0.00255635</td><td style=\"text-align: right;\">0.0375088</td><td style=\"text-align: right;\">              0.00255635</td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_1_20231013_95536                </td><td style=\"text-align: right;\">0.0215289</td><td style=\"text-align: right;\">0.0514568</td><td style=\"text-align: right;\">0.0026478 </td><td style=\"text-align: right;\">0.0383562</td><td style=\"text-align: right;\">              0.0026478 </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20231013_95536_model_1   </td><td style=\"text-align: right;\">0.0219313</td><td style=\"text-align: right;\">0.0529569</td><td style=\"text-align: right;\">0.00280444</td><td style=\"text-align: right;\">0.0393086</td><td style=\"text-align: right;\">              0.00280444</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20231013_95536_model_1   </td><td style=\"text-align: right;\">0.0241295</td><td style=\"text-align: right;\">0.0570698</td><td style=\"text-align: right;\">0.00325697</td><td style=\"text-align: right;\">0.043116 </td><td style=\"text-align: right;\">              0.00325697</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20231013_95536_model_1   </td><td style=\"text-align: right;\">0.0242561</td><td style=\"text-align: right;\">0.0549772</td><td style=\"text-align: right;\">0.00302249</td><td style=\"text-align: right;\">0.0409852</td><td style=\"text-align: right;\">              0.00302249</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20231013_95536_model_2   </td><td style=\"text-align: right;\">0.029609 </td><td style=\"text-align: right;\">0.0676529</td><td style=\"text-align: right;\">0.00457691</td><td style=\"text-align: right;\">0.050987 </td><td style=\"text-align: right;\">              0.00457691</td></tr>\n",
       "<tr><td>GLM_1_AutoML_1_20231013_95536                         </td><td style=\"text-align: right;\">0.0621817</td><td style=\"text-align: right;\">0.0931605</td><td style=\"text-align: right;\">0.00867887</td><td style=\"text-align: right;\">0.0729854</td><td style=\"text-align: right;\">              0.00867887</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20231013_95536_model_2   </td><td style=\"text-align: right;\">0.0673087</td><td style=\"text-align: right;\">0.09482  </td><td style=\"text-align: right;\">0.00899083</td><td style=\"text-align: right;\">0.0749262</td><td style=\"text-align: right;\">              0.00899083</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20231013_95536_model_2   </td><td style=\"text-align: right;\">0.0719574</td><td style=\"text-align: right;\">0.0982114</td><td style=\"text-align: right;\">0.00964548</td><td style=\"text-align: right;\">0.0788129</td><td style=\"text-align: right;\">              0.00964548</td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[22 rows x 6 columns]</pre>"
      ],
      "text/plain": [
       "model_id                                                      mae       rmse         mse      rmsle    mean_residual_deviance\n",
       "------------------------------------------------------  ---------  ---------  ----------  ---------  ------------------------\n",
       "GBM_grid_1_AutoML_1_20231013_95536_model_5              0.0146351  0.0441073  0.00194545  0.0325936                0.00194545\n",
       "StackedEnsemble_AllModels_1_AutoML_1_20231013_95536     0.0148685  0.0429196  0.00184209  0.031728                 0.00184209\n",
       "GBM_4_AutoML_1_20231013_95536                           0.0149636  0.0445948  0.0019887   0.0329688                0.0019887\n",
       "StackedEnsemble_BestOfFamily_1_AutoML_1_20231013_95536  0.0151436  0.0439629  0.00193274  0.0325099                0.00193274\n",
       "GBM_3_AutoML_1_20231013_95536                           0.0154723  0.0456152  0.00208074  0.0337079                0.00208074\n",
       "GBM_1_AutoML_1_20231013_95536                           0.0157797  0.0464368  0.00215637  0.0343431                0.00215637\n",
       "DRF_1_AutoML_1_20231013_95536                           0.0158048  0.0464803  0.00216042  0.0344129                0.00216042\n",
       "GBM_grid_1_AutoML_1_20231013_95536_model_4              0.0159132  0.0445029  0.00198051  0.032943                 0.00198051\n",
       "GBM_2_AutoML_1_20231013_95536                           0.0160824  0.0466329  0.00217462  0.0345066                0.00217462\n",
       "GBM_grid_1_AutoML_1_20231013_95536_model_1              0.0164544  0.044885   0.00201466  0.0332722                0.00201466\n",
       "GBM_5_AutoML_1_20231013_95536                           0.0164982  0.0475775  0.00226362  0.0352173                0.00226362\n",
       "GBM_grid_1_AutoML_1_20231013_95536_model_3              0.0171798  0.0487559  0.00237714  0.0360994                0.00237714\n",
       "XRT_1_AutoML_1_20231013_95536                           0.0173415  0.0473872  0.00224554  0.0350301                0.00224554\n",
       "GBM_grid_1_AutoML_1_20231013_95536_model_2              0.0183952  0.0505604  0.00255635  0.0375088                0.00255635\n",
       "DeepLearning_1_AutoML_1_20231013_95536                  0.0215289  0.0514568  0.0026478   0.0383562                0.0026478\n",
       "DeepLearning_grid_2_AutoML_1_20231013_95536_model_1     0.0219313  0.0529569  0.00280444  0.0393086                0.00280444\n",
       "DeepLearning_grid_1_AutoML_1_20231013_95536_model_1     0.0241295  0.0570698  0.00325697  0.043116                 0.00325697\n",
       "DeepLearning_grid_3_AutoML_1_20231013_95536_model_1     0.0242561  0.0549772  0.00302249  0.0409852                0.00302249\n",
       "DeepLearning_grid_1_AutoML_1_20231013_95536_model_2     0.029609   0.0676529  0.00457691  0.050987                 0.00457691\n",
       "GLM_1_AutoML_1_20231013_95536                           0.0621817  0.0931605  0.00867887  0.0729854                0.00867887\n",
       "DeepLearning_grid_2_AutoML_1_20231013_95536_model_2     0.0673087  0.09482    0.00899083  0.0749262                0.00899083\n",
       "DeepLearning_grid_3_AutoML_1_20231013_95536_model_2     0.0719574  0.0982114  0.00964548  0.0788129                0.00964548\n",
       "[22 rows x 6 columns]\n"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lb.head(rows=lb.nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">    predict</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">5.37204e-05</td></tr>\n",
       "<tr><td style=\"text-align: right;\">5.09456e-05</td></tr>\n",
       "<tr><td style=\"text-align: right;\">6.52742e-05</td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.0132792  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.0759911  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.109085   </td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.341765   </td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.510781   </td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.591147   </td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.530364   </td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[10 rows x 1 column]</pre>"
      ],
      "text/plain": [
       "    predict\n",
       "-----------\n",
       "5.37204e-05\n",
       "5.09456e-05\n",
       "6.52742e-05\n",
       "0.0132792\n",
       "0.0759911\n",
       "0.109085\n",
       "0.341765\n",
       "0.510781\n",
       "0.591147\n",
       "0.530364\n",
       "[10 rows x 1 column]\n"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaderboard_df = lb.as_data_frame() \n",
    "prediction_df = preds.as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H2O session _sid_8c7d closed.\n"
     ]
    }
   ],
   "source": [
    "h2o.cluster().shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       predict\n",
      "0     0.000054\n",
      "1     0.000051\n",
      "2     0.000065\n",
      "3     0.013279\n",
      "4     0.075991\n",
      "...        ...\n",
      "2155  0.010484\n",
      "2156  0.004932\n",
      "2157  0.001229\n",
      "2158  0.000608\n",
      "2159  0.000475\n",
      "\n",
      "[2160 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(prediction_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_df_arr = prediction_df.reshape(-1, 1)\n",
    "prediction_df_scaled = y_scaler.inverse_transform(prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3080016 ]\n",
      " [0.29209274]\n",
      " [0.37424413]\n",
      " ...\n",
      " [7.04677938]\n",
      " [3.48745235]\n",
      " [2.72115091]]\n",
      "               0\n",
      "0       0.308002\n",
      "1       0.292093\n",
      "2       0.374244\n",
      "3      76.135051\n",
      "4     435.688777\n",
      "...          ...\n",
      "2155   60.110230\n",
      "2156   28.279916\n",
      "2157    7.046779\n",
      "2158    3.487452\n",
      "2159    2.721151\n",
      "\n",
      "[2160 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(prediction_df_scaled)\n",
    "prediction_df_scaled_df = pd.DataFrame(prediction_df_scaled)\n",
    "print(prediction_df_scaled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing negative values and replacing with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.308002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.292093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.374244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>76.135051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>435.688777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  prediction\n",
       "0   0    0.308002\n",
       "1   1    0.292093\n",
       "2   2    0.374244\n",
       "3   3   76.135051\n",
       "4   4  435.688777"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultframe = pd.DataFrame(columns = [\"id\", \"prediction\"])\n",
    "resultframe[\"prediction\"] = prediction_df_scaled_df\n",
    "resultframe['prediction'] = np.where(resultframe['prediction'] < 0, 0, resultframe['prediction'])\n",
    "resultframe[\"id\"] = range(len(resultframe))\n",
    "resultframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Okay lets create a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resultframe.to_csv(\"sumbission_all_the_boys_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"submission_sivert_super_model_5.csv\")\n",
    "\n",
    "# df['prediction'] = np.where(df['prediction'] < 0, 0, df['prediction'])\n",
    "# df['prediction'] = np.where(df['prediction'] > 0, df['prediction']+3, 0)\n",
    "# df.describe()\n",
    "# df.to_csv(\"submission_sivert_super_model_5_with_no_negatives_copy_plus_scaled.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
