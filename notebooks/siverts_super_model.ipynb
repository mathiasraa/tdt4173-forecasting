{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import IPython\n",
    "import IPython.display\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "# mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "# mpl.rcParams['axes.grid'] = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan:\n",
    " - Load sets\n",
    " - Clean:\n",
    "    - remove duplicate entries from sets\n",
    "    - Drop the unimportant coloumns that we found\n",
    "    - Make querters into hours\n",
    "    - remove values from train_targets that are nan in both x and y sets\n",
    "    - make time features\n",
    "    - drop datetime coloumns\n",
    " - Set prep:\n",
    "    - 75/25 fordeling. 75% av OBSERVED er trening, resterende 25% er validation, 75% av ESTIMATED er trening, resterende 25% er validation\n",
    "- Concat the different locations into 1 set, where location is a feature as well\n",
    "   - 1 hot encoding\n",
    "- Make a time series model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A\n",
    "y_a = pd.read_parquet('../data/A/train_targets.parquet')\n",
    "X_test_estimated_a = pd.read_parquet('../data/A/X_test_estimated.parquet')\n",
    "X_train_estimated_a = pd.read_parquet('../data/A/X_train_estimated.parquet')\n",
    "X_train_observed_a = pd.read_parquet('../data/A/X_train_observed.parquet')\n",
    "\n",
    "# B\n",
    "y_b = pd.read_parquet('../data/B/train_targets.parquet')\n",
    "X_test_estimated_b = pd.read_parquet('../data/B/X_test_estimated.parquet')\n",
    "X_train_estimated_b = pd.read_parquet('../data/B/X_train_estimated.parquet')\n",
    "X_train_observed_b = pd.read_parquet('../data/B/X_train_observed.parquet')\n",
    "\n",
    "# C\n",
    "y_c = pd.read_parquet('../data/C/train_targets.parquet')\n",
    "X_test_estimated_c = pd.read_parquet('../data/C/X_test_estimated.parquet')\n",
    "X_train_estimated_c = pd.read_parquet('../data/C/X_train_estimated.parquet')\n",
    "X_train_observed_c = pd.read_parquet('../data/C/X_train_observed.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing duplicate entries from the sets if any exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that removes the duplicates if it finds duplicates in the specified coloumn\n",
    "def remove_duplicates_in_coloumn(df, col):\n",
    "    duplicate_mask = df[col].duplicated(keep=\"first\")\n",
    "    if duplicate_mask.any():\n",
    "        df = df[~duplicate_mask]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A\n",
    "y_a = remove_duplicates_in_coloumn(y_a, \"time\")\n",
    "X_test_estimated_a = remove_duplicates_in_coloumn(X_test_estimated_a, \"date_forecast\")\n",
    "X_train_estimated_a = remove_duplicates_in_coloumn(X_train_estimated_a, \"date_forecast\")\n",
    "X_train_observed_a = remove_duplicates_in_coloumn(X_train_observed_a, \"date_forecast\")\n",
    "\n",
    "#B\n",
    "y_b = remove_duplicates_in_coloumn(y_b, \"time\")\n",
    "X_test_estimated_b = remove_duplicates_in_coloumn(X_test_estimated_b, \"date_forecast\")\n",
    "X_train_estimated_b = remove_duplicates_in_coloumn(X_train_estimated_b, \"date_forecast\")\n",
    "X_train_observed_b = remove_duplicates_in_coloumn(X_train_observed_b, \"date_forecast\")\n",
    "\n",
    "#C\n",
    "y_c = remove_duplicates_in_coloumn(y_c, \"time\")\n",
    "X_test_estimated_c = remove_duplicates_in_coloumn(X_test_estimated_c, \"date_forecast\")\n",
    "X_train_estimated_c = remove_duplicates_in_coloumn(X_train_estimated_c, \"date_forecast\")\n",
    "X_train_observed_c = remove_duplicates_in_coloumn(X_train_observed_c, \"date_forecast\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of all estimated and observed sets\n",
    "\n",
    "list_of_all_estimated_and_observed_sets = [X_test_estimated_a, X_train_estimated_a, X_train_observed_a,\n",
    "                                           X_test_estimated_b, X_train_estimated_b, X_train_observed_b,\n",
    "                                           X_test_estimated_c, X_train_estimated_c, X_train_observed_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping some coloumns for the bants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "for set in list_of_all_estimated_and_observed_sets:\n",
    "    # set.drop(\"snow_density:kgm3\", axis=1, inplace=True)\n",
    "    # these 2 had a lot of NaN values\n",
    "    set.drop(\"ceiling_height_agl:m\", axis=1, inplace=True) \n",
    "    set.drop(\"cloud_base_agl:m\", axis=1,inplace=True) # could potentially not drop this, but set all nan values to 0\n",
    "    set.drop(\"snow_density:kgm3\", axis=1, inplace=True)\n",
    "    set.drop(\"elevation:m\", axis=1, inplace=True) \n",
    "    set.drop(\"precip_5min:mm\", axis=1, inplace=True)\n",
    "    set.drop(\"precip_type_5min:idx\", axis=1, inplace=True)\n",
    "    set.drop(\"pressure_50m:hPa\", axis=1, inplace=True)\n",
    "    set.drop(\"snow_drift:idx\", axis=1, inplace=True)\n",
    "    set.drop(\"wind_speed_u_10m:ms\", axis=1, inplace=True)\n",
    "    set.drop(\"wind_speed_v_10m:ms\", axis=1, inplace=True)\n",
    "    set.drop(\"wind_speed_w_1000hPa:ms\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting degree features to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_from_degree_to_ciruclar(df, feature):\n",
    "    df[feature+'_sin'] = np.sin(np.radians(df[feature]))\n",
    "    df[feature+'_cos'] = np.cos(np.radians(df[feature]))\n",
    "    df = df.drop(feature, axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2880, 36)\n",
      "(2880, 37)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_estimated_a.shape)\n",
    "\n",
    "X_train_estimated_a = convert_from_degree_to_ciruclar(X_train_estimated_a, \"sun_azimuth:d\")\n",
    "X_train_observed_a = convert_from_degree_to_ciruclar(X_train_observed_a, \"sun_azimuth:d\")\n",
    "X_test_estimated_a = convert_from_degree_to_ciruclar(X_test_estimated_a, \"sun_azimuth:d\")\n",
    "X_train_estimated_b = convert_from_degree_to_ciruclar(X_train_estimated_b, \"sun_azimuth:d\")\n",
    "X_train_observed_b = convert_from_degree_to_ciruclar(X_train_observed_b, \"sun_azimuth:d\")\n",
    "X_test_estimated_b = convert_from_degree_to_ciruclar(X_test_estimated_b, \"sun_azimuth:d\")\n",
    "X_train_estimated_c = convert_from_degree_to_ciruclar(X_train_estimated_c, \"sun_azimuth:d\")\n",
    "X_train_observed_c = convert_from_degree_to_ciruclar(X_train_observed_c, \"sun_azimuth:d\")\n",
    "X_test_estimated_c = convert_from_degree_to_ciruclar(X_test_estimated_c, \"sun_azimuth:d\")\n",
    "\n",
    "print(X_test_estimated_a.shape)\n",
    "\n",
    "# X_train_observed_a.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing date_calc from all estimated sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_estimated_a.drop(\"date_calc\", axis=1, inplace=True)\n",
    "X_train_estimated_a.drop(\"date_calc\", axis=1, inplace=True)\n",
    "X_test_estimated_b.drop(\"date_calc\", axis=1, inplace=True)\n",
    "X_train_estimated_b.drop(\"date_calc\", axis=1, inplace=True)\n",
    "X_test_estimated_c.drop(\"date_calc\", axis=1, inplace=True)\n",
    "X_train_estimated_c.drop(\"date_calc\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting every 4 quarters into an whole hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "## It might be better not to resample actually, but just use the actual hours that correspond perfectly\n",
    "\n",
    "def convert_df_into_hourly(df):\n",
    "    df.set_index(\"date_forecast\", inplace=True)\n",
    "    df = df.resample('1H').sum()\n",
    "    df.reset_index(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2880, 36)\n",
      "(1536, 36)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_forecast</th>\n",
       "      <th>absolute_humidity_2m:gm3</th>\n",
       "      <th>air_density_2m:kgm3</th>\n",
       "      <th>clear_sky_energy_1h:J</th>\n",
       "      <th>clear_sky_rad:W</th>\n",
       "      <th>dew_or_rime:idx</th>\n",
       "      <th>dew_point_2m:K</th>\n",
       "      <th>diffuse_rad:W</th>\n",
       "      <th>diffuse_rad_1h:J</th>\n",
       "      <th>direct_rad:W</th>\n",
       "      <th>...</th>\n",
       "      <th>snow_melt_10min:mm</th>\n",
       "      <th>snow_water:kgm2</th>\n",
       "      <th>sun_elevation:d</th>\n",
       "      <th>super_cooled_liquid_water:kgm2</th>\n",
       "      <th>t_1000hPa:K</th>\n",
       "      <th>total_cloud_cover:p</th>\n",
       "      <th>visibility:m</th>\n",
       "      <th>wind_speed_10m:ms</th>\n",
       "      <th>sun_azimuth:d_sin</th>\n",
       "      <th>sun_azimuth:d_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-10-28 22:00:00</td>\n",
       "      <td>33.400002</td>\n",
       "      <td>4.932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1125.099976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>-156.261002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1138.700073</td>\n",
       "      <td>400.0</td>\n",
       "      <td>82850.101562</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>-0.840212</td>\n",
       "      <td>3.893597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-10-28 23:00:00</td>\n",
       "      <td>32.400002</td>\n",
       "      <td>4.936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1123.400024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>-157.529007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1137.300049</td>\n",
       "      <td>400.0</td>\n",
       "      <td>22496.699219</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>0.468029</td>\n",
       "      <td>3.955367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-10-29 00:00:00</td>\n",
       "      <td>32.599998</td>\n",
       "      <td>4.919</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1123.699951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>-152.162003</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1135.500000</td>\n",
       "      <td>400.0</td>\n",
       "      <td>12961.700195</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.635808</td>\n",
       "      <td>3.632862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-10-29 01:00:00</td>\n",
       "      <td>32.799999</td>\n",
       "      <td>4.914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1124.199951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-137.561996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1137.400024</td>\n",
       "      <td>400.0</td>\n",
       "      <td>12974.000000</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>2.658692</td>\n",
       "      <td>2.970362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-10-29 02:00:00</td>\n",
       "      <td>33.500000</td>\n",
       "      <td>4.908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1125.399902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-117.074997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1138.099976</td>\n",
       "      <td>400.0</td>\n",
       "      <td>10113.799805</td>\n",
       "      <td>8.799999</td>\n",
       "      <td>3.382308</td>\n",
       "      <td>2.114047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date_forecast  absolute_humidity_2m:gm3  air_density_2m:kgm3  \\\n",
       "0 2022-10-28 22:00:00                 33.400002                4.932   \n",
       "1 2022-10-28 23:00:00                 32.400002                4.936   \n",
       "2 2022-10-29 00:00:00                 32.599998                4.919   \n",
       "3 2022-10-29 01:00:00                 32.799999                4.914   \n",
       "4 2022-10-29 02:00:00                 33.500000                4.908   \n",
       "\n",
       "   clear_sky_energy_1h:J  clear_sky_rad:W  dew_or_rime:idx  dew_point_2m:K  \\\n",
       "0                    0.0              0.0              4.0     1125.099976   \n",
       "1                    0.0              0.0              4.0     1123.400024   \n",
       "2                    0.0              0.0              4.0     1123.699951   \n",
       "3                    0.0              0.0              4.0     1124.199951   \n",
       "4                    0.0              0.0              4.0     1125.399902   \n",
       "\n",
       "   diffuse_rad:W  diffuse_rad_1h:J  direct_rad:W  ...  snow_melt_10min:mm  \\\n",
       "0            0.0               0.0           0.0  ...                 0.0   \n",
       "1            0.0               0.0           0.0  ...                 0.0   \n",
       "2            0.0               0.0           0.0  ...                 0.0   \n",
       "3            0.0               0.0           0.0  ...                 0.0   \n",
       "4            0.0               0.0           0.0  ...                 0.0   \n",
       "\n",
       "   snow_water:kgm2  sun_elevation:d  super_cooled_liquid_water:kgm2  \\\n",
       "0              1.9      -156.261002                             0.0   \n",
       "1              2.8      -157.529007                             0.0   \n",
       "2              4.7      -152.162003                             0.8   \n",
       "3              3.5      -137.561996                             1.0   \n",
       "4              4.0      -117.074997                             1.0   \n",
       "\n",
       "   t_1000hPa:K  total_cloud_cover:p  visibility:m  wind_speed_10m:ms  \\\n",
       "0  1138.700073                400.0  82850.101562           2.800000   \n",
       "1  1137.300049                400.0  22496.699219           3.100000   \n",
       "2  1135.500000                400.0  12961.700195           6.000000   \n",
       "3  1137.400024                400.0  12974.000000           6.300000   \n",
       "4  1138.099976                400.0  10113.799805           8.799999   \n",
       "\n",
       "   sun_azimuth:d_sin  sun_azimuth:d_cos  \n",
       "0          -0.840212           3.893597  \n",
       "1           0.468029           3.955367  \n",
       "2           1.635808           3.632862  \n",
       "3           2.658692           2.970362  \n",
       "4           3.382308           2.114047  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(X_test_estimated_a.shape)\n",
    "\n",
    "X_train_estimated_a = convert_df_into_hourly(X_train_estimated_a)\n",
    "X_train_observed_a = convert_df_into_hourly(X_train_observed_a)\n",
    "X_test_estimated_a = convert_df_into_hourly(X_test_estimated_a)\n",
    "X_train_estimated_b = convert_df_into_hourly(X_train_estimated_b)\n",
    "X_train_observed_b = convert_df_into_hourly(X_train_observed_b)\n",
    "X_test_estimated_b = convert_df_into_hourly(X_test_estimated_b)\n",
    "X_train_estimated_c = convert_df_into_hourly(X_train_estimated_c)\n",
    "X_train_observed_c = convert_df_into_hourly(X_train_observed_c)\n",
    "X_test_estimated_c = convert_df_into_hourly(X_test_estimated_c)\n",
    "\n",
    "print(X_test_estimated_a.shape)\n",
    "\n",
    "X_train_estimated_a.head()\n",
    "## We should probably do it for the test_sets here as well\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing all NaN from y_targets\n",
    " - Removing all NaN from y_targets and their corresponding dates in the X_train sets, both observed and estimated\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that returns train_targets, observed and estimated sets left after filtering away NaN\n",
    "def drop_nan_rows_in_target_and_train(y_df, observed_train_df, estimated_train_df):\n",
    "    y_df = y_df.dropna(subset=['pv_measurement'])\n",
    "    valid_dates = y_df['time']\n",
    "    observed_train_df = observed_train_df[observed_train_df['date_forecast'].isin(valid_dates)]\n",
    "    estimated_train_df = estimated_train_df[estimated_train_df['date_forecast'].isin(valid_dates)]\n",
    "    return (y_df, observed_train_df, estimated_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>pv_measurement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5913</th>\n",
       "      <td>2019-09-04 08:00:00</td>\n",
       "      <td>137.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5914</th>\n",
       "      <td>2019-09-04 09:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5915</th>\n",
       "      <td>2019-09-04 10:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5916</th>\n",
       "      <td>2019-09-04 11:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5917</th>\n",
       "      <td>2019-09-04 12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    time  pv_measurement\n",
       "5913 2019-09-04 08:00:00           137.2\n",
       "5914 2019-09-04 09:00:00             0.0\n",
       "5915 2019-09-04 10:00:00             0.0\n",
       "5916 2019-09-04 11:00:00             0.0\n",
       "5917 2019-09-04 12:00:00             0.0"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#doing the NaN filtering\n",
    "y_a, X_train_observed_a, X_train_estimated_a = drop_nan_rows_in_target_and_train(y_a, X_train_observed_a, X_train_estimated_a)\n",
    "y_b, X_train_observed_b, X_train_estimated_b = drop_nan_rows_in_target_and_train(y_b, X_train_observed_b, X_train_estimated_b)\n",
    "y_c, X_train_observed_c, X_train_estimated_c = drop_nan_rows_in_target_and_train(y_c, X_train_observed_c, X_train_estimated_c)\n",
    "\n",
    "y_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_forecast</th>\n",
       "      <th>absolute_humidity_2m:gm3</th>\n",
       "      <th>air_density_2m:kgm3</th>\n",
       "      <th>clear_sky_energy_1h:J</th>\n",
       "      <th>clear_sky_rad:W</th>\n",
       "      <th>dew_or_rime:idx</th>\n",
       "      <th>dew_point_2m:K</th>\n",
       "      <th>diffuse_rad:W</th>\n",
       "      <th>diffuse_rad_1h:J</th>\n",
       "      <th>direct_rad:W</th>\n",
       "      <th>...</th>\n",
       "      <th>snow_melt_10min:mm</th>\n",
       "      <th>snow_water:kgm2</th>\n",
       "      <th>sun_elevation:d</th>\n",
       "      <th>super_cooled_liquid_water:kgm2</th>\n",
       "      <th>t_1000hPa:K</th>\n",
       "      <th>total_cloud_cover:p</th>\n",
       "      <th>visibility:m</th>\n",
       "      <th>wind_speed_10m:ms</th>\n",
       "      <th>sun_azimuth:d_sin</th>\n",
       "      <th>sun_azimuth:d_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5912</th>\n",
       "      <td>2019-09-04 08:00:00</td>\n",
       "      <td>26.5</td>\n",
       "      <td>4.883</td>\n",
       "      <td>5283377.5</td>\n",
       "      <td>1684.900024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1112.800049</td>\n",
       "      <td>271.899994</td>\n",
       "      <td>9.320397e+05</td>\n",
       "      <td>1352.599976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.019997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1134.900024</td>\n",
       "      <td>124.799995</td>\n",
       "      <td>198197.796875</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.039486</td>\n",
       "      <td>-2.582547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5913</th>\n",
       "      <td>2019-09-04 09:00:00</td>\n",
       "      <td>25.1</td>\n",
       "      <td>4.857</td>\n",
       "      <td>6726922.0</td>\n",
       "      <td>2032.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1109.699951</td>\n",
       "      <td>306.500000</td>\n",
       "      <td>1.041404e+06</td>\n",
       "      <td>1624.199951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.817001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1139.199951</td>\n",
       "      <td>345.000000</td>\n",
       "      <td>209239.906250</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.200736</td>\n",
       "      <td>-3.324243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5914</th>\n",
       "      <td>2019-09-04 10:00:00</td>\n",
       "      <td>23.6</td>\n",
       "      <td>4.833</td>\n",
       "      <td>7747199.5</td>\n",
       "      <td>2247.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1106.600098</td>\n",
       "      <td>450.299988</td>\n",
       "      <td>1.362371e+06</td>\n",
       "      <td>1598.800049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.110001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1143.599976</td>\n",
       "      <td>380.599976</td>\n",
       "      <td>215915.203125</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.117962</td>\n",
       "      <td>-3.825162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5915</th>\n",
       "      <td>2019-09-04 11:00:00</td>\n",
       "      <td>23.5</td>\n",
       "      <td>4.814</td>\n",
       "      <td>8254105.0</td>\n",
       "      <td>2312.100098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1106.599976</td>\n",
       "      <td>780.599976</td>\n",
       "      <td>2.215590e+06</td>\n",
       "      <td>1090.799927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.548004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1147.699951</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>218043.703125</td>\n",
       "      <td>7.8</td>\n",
       "      <td>-0.108947</td>\n",
       "      <td>-3.983159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5916</th>\n",
       "      <td>2019-09-04 12:00:00</td>\n",
       "      <td>24.6</td>\n",
       "      <td>4.807</td>\n",
       "      <td>8205280.0</td>\n",
       "      <td>2220.699951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1109.000000</td>\n",
       "      <td>973.500000</td>\n",
       "      <td>3.157120e+06</td>\n",
       "      <td>449.399994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>130.675995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1150.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>217138.593750</td>\n",
       "      <td>6.1</td>\n",
       "      <td>-1.321110</td>\n",
       "      <td>-3.760065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date_forecast  absolute_humidity_2m:gm3  air_density_2m:kgm3  \\\n",
       "5912 2019-09-04 08:00:00                      26.5                4.883   \n",
       "5913 2019-09-04 09:00:00                      25.1                4.857   \n",
       "5914 2019-09-04 10:00:00                      23.6                4.833   \n",
       "5915 2019-09-04 11:00:00                      23.5                4.814   \n",
       "5916 2019-09-04 12:00:00                      24.6                4.807   \n",
       "\n",
       "      clear_sky_energy_1h:J  clear_sky_rad:W  dew_or_rime:idx  dew_point_2m:K  \\\n",
       "5912              5283377.5      1684.900024              0.0     1112.800049   \n",
       "5913              6726922.0      2032.500000              0.0     1109.699951   \n",
       "5914              7747199.5      2247.500000              0.0     1106.600098   \n",
       "5915              8254105.0      2312.100098              0.0     1106.599976   \n",
       "5916              8205280.0      2220.699951              0.0     1109.000000   \n",
       "\n",
       "      diffuse_rad:W  diffuse_rad_1h:J  direct_rad:W  ...  snow_melt_10min:mm  \\\n",
       "5912     271.899994      9.320397e+05   1352.599976  ...                 0.0   \n",
       "5913     306.500000      1.041404e+06   1624.199951  ...                 0.0   \n",
       "5914     450.299988      1.362371e+06   1598.800049  ...                 0.0   \n",
       "5915     780.599976      2.215590e+06   1090.799927  ...                 0.0   \n",
       "5916     973.500000      3.157120e+06    449.399994  ...                 0.0   \n",
       "\n",
       "      snow_water:kgm2  sun_elevation:d  super_cooled_liquid_water:kgm2  \\\n",
       "5912              0.0       103.019997                             0.0   \n",
       "5913              0.0       120.817001                             0.0   \n",
       "5914              0.0       132.110001                             0.0   \n",
       "5915              0.0       135.548004                             0.0   \n",
       "5916              0.2       130.675995                             0.0   \n",
       "\n",
       "      t_1000hPa:K  total_cloud_cover:p   visibility:m  wind_speed_10m:ms  \\\n",
       "5912  1134.900024           124.799995  198197.796875                5.0   \n",
       "5913  1139.199951           345.000000  209239.906250                6.0   \n",
       "5914  1143.599976           380.599976  215915.203125                8.0   \n",
       "5915  1147.699951           400.000000  218043.703125                7.8   \n",
       "5916  1150.000000           400.000000  217138.593750                6.1   \n",
       "\n",
       "      sun_azimuth:d_sin  sun_azimuth:d_cos  \n",
       "5912           3.039486          -2.582547  \n",
       "5913           2.200736          -3.324243  \n",
       "5914           1.117962          -3.825162  \n",
       "5915          -0.108947          -3.983159  \n",
       "5916          -1.321110          -3.760065  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_observed_c.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that creates timefeatures based on the specified coloumn\n",
    "def create_time_features_based_on_coloun(df, col):   \n",
    "    df['hour'] = df[col].dt.hour\n",
    "    df['dayofmonth'] = df[col].dt.day\n",
    "    df['dayofweek'] = df[col].dt.dayofweek\n",
    "    df['quarter'] = df[col].dt.quarter\n",
    "    df['month'] = df[col].dt.month\n",
    "    df['year'] = df[col].dt.year\n",
    "    df['dayofyear'] = df[col].dt.dayofyear\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding time features\n",
    "\n",
    "#A\n",
    "X_train_estimated_a = create_time_features_based_on_coloun(X_train_estimated_a, \"date_forecast\")\n",
    "X_train_observed_a = create_time_features_based_on_coloun(X_train_observed_a, \"date_forecast\")\n",
    "X_test_estimated_a = create_time_features_based_on_coloun(X_test_estimated_a, \"date_forecast\")\n",
    "\n",
    "#B\n",
    "X_train_estimated_b = create_time_features_based_on_coloun(X_train_estimated_b, \"date_forecast\")\n",
    "X_train_observed_b = create_time_features_based_on_coloun(X_train_observed_b, \"date_forecast\")\n",
    "X_test_estimated_b = create_time_features_based_on_coloun(X_test_estimated_b, \"date_forecast\")\n",
    "\n",
    "#C\n",
    "X_train_estimated_c = create_time_features_based_on_coloun(X_train_estimated_c, \"date_forecast\")\n",
    "X_train_observed_c = create_time_features_based_on_coloun(X_train_observed_c, \"date_forecast\")\n",
    "X_test_estimated_c = create_time_features_based_on_coloun(X_test_estimated_c, \"date_forecast\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just showing the shapes to se if i havent f'ed up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "(4418, 43)\n",
      "(29667, 43)\n",
      "34085\n",
      "(34085, 2)\n",
      "B\n",
      "(3625, 43)\n",
      "(29218, 43)\n",
      "32843\n",
      "(32844, 2)\n",
      "C\n",
      "(2954, 43)\n",
      "(23141, 43)\n",
      "26095\n",
      "(26095, 2)\n"
     ]
    }
   ],
   "source": [
    "# printing shapes\n",
    "print(\"A\")\n",
    "print(X_train_estimated_a.shape)\n",
    "print(X_train_observed_a.shape)\n",
    "print(X_train_estimated_a.shape[0]+X_train_observed_a.shape[0])\n",
    "print(y_a.shape)\n",
    "\n",
    "print(\"B\")\n",
    "print(X_train_estimated_b.shape)\n",
    "print(X_train_observed_b.shape)\n",
    "print(X_train_estimated_b.shape[0]+X_train_observed_b.shape[0])  ## this one seems to be of by 1??????\n",
    "print(y_b.shape)\n",
    "\n",
    "print(\"C\")\n",
    "print(X_train_estimated_c.shape)\n",
    "print(X_train_observed_c.shape)\n",
    "print(X_train_estimated_c.shape[0]+X_train_observed_c.shape[0])\n",
    "print(y_c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for B there is actually on row more in the target set for some reason, finding that row and deleting it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 time  pv_measurement\n",
      "0 2018-12-31 23:00:00             0.0\n"
     ]
    }
   ],
   "source": [
    "## Finding the row in y_b that does not have a match\n",
    "\n",
    "# renaming\n",
    "date_times_estimated = X_train_estimated_b['date_forecast']\n",
    "date_times_observed = X_train_observed_b['date_forecast']\n",
    "result_df = y_b[~y_b['time'].isin(date_times_estimated) & ~y_b['time'].isin(date_times_observed)]\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okey so let's remove that row and verify that everything is correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n",
      "(3625, 43)\n",
      "(29218, 43)\n",
      "32843\n",
      "(32843, 2)\n"
     ]
    }
   ],
   "source": [
    "# removing row\n",
    "y_b = y_b[~y_b['time'].isin(result_df['time'])]\n",
    "\n",
    "# checking that the numbers add up again\n",
    "print(\"B\")\n",
    "print(X_train_estimated_b.shape)\n",
    "print(X_train_observed_b.shape)\n",
    "print(X_train_estimated_b.shape[0]+X_train_observed_b.shape[0])\n",
    "print(y_b.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing repeated indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dividing the sets into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_forecast</th>\n",
       "      <th>absolute_humidity_2m:gm3</th>\n",
       "      <th>air_density_2m:kgm3</th>\n",
       "      <th>clear_sky_energy_1h:J</th>\n",
       "      <th>clear_sky_rad:W</th>\n",
       "      <th>dew_or_rime:idx</th>\n",
       "      <th>dew_point_2m:K</th>\n",
       "      <th>diffuse_rad:W</th>\n",
       "      <th>diffuse_rad_1h:J</th>\n",
       "      <th>direct_rad:W</th>\n",
       "      <th>...</th>\n",
       "      <th>wind_speed_10m:ms</th>\n",
       "      <th>sun_azimuth:d_sin</th>\n",
       "      <th>sun_azimuth:d_cos</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofmonth</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>quarter</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>dayofyear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-02 22:00:00</td>\n",
       "      <td>30.799999</td>\n",
       "      <td>4.913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1121.199951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.4</td>\n",
       "      <td>-0.827235</td>\n",
       "      <td>3.904145</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-06-02 23:00:00</td>\n",
       "      <td>30.799999</td>\n",
       "      <td>4.894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1121.199951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.4</td>\n",
       "      <td>0.137934</td>\n",
       "      <td>3.988335</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-06-03 00:00:00</td>\n",
       "      <td>31.500000</td>\n",
       "      <td>4.879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1122.599976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1.028531</td>\n",
       "      <td>3.856086</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-03 01:00:00</td>\n",
       "      <td>33.700001</td>\n",
       "      <td>4.872</td>\n",
       "      <td>834.599976</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1126.699951</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>2107.100098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.9</td>\n",
       "      <td>1.912442</td>\n",
       "      <td>3.503262</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-06-03 02:00:00</td>\n",
       "      <td>35.799999</td>\n",
       "      <td>4.872</td>\n",
       "      <td>129872.601562</td>\n",
       "      <td>92.400002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1130.000000</td>\n",
       "      <td>47.900002</td>\n",
       "      <td>88275.796875</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>10.2</td>\n",
       "      <td>2.670854</td>\n",
       "      <td>2.966543</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date_forecast  absolute_humidity_2m:gm3  air_density_2m:kgm3  \\\n",
       "0 2019-06-02 22:00:00                 30.799999                4.913   \n",
       "1 2019-06-02 23:00:00                 30.799999                4.894   \n",
       "2 2019-06-03 00:00:00                 31.500000                4.879   \n",
       "3 2019-06-03 01:00:00                 33.700001                4.872   \n",
       "4 2019-06-03 02:00:00                 35.799999                4.872   \n",
       "\n",
       "   clear_sky_energy_1h:J  clear_sky_rad:W  dew_or_rime:idx  dew_point_2m:K  \\\n",
       "0               0.000000         0.000000              0.0     1121.199951   \n",
       "1               0.000000         0.000000              0.0     1121.199951   \n",
       "2               0.000000         0.000000              0.0     1122.599976   \n",
       "3             834.599976         3.000000              0.0     1126.699951   \n",
       "4          129872.601562        92.400002              0.0     1130.000000   \n",
       "\n",
       "   diffuse_rad:W  diffuse_rad_1h:J  direct_rad:W  ...  wind_speed_10m:ms  \\\n",
       "0       0.000000          0.000000           0.0  ...               14.4   \n",
       "1       0.000000          0.000000           0.0  ...               13.4   \n",
       "2       0.000000          0.000000           0.0  ...               12.2   \n",
       "3       1.200000       2107.100098           0.0  ...               10.9   \n",
       "4      47.900002      88275.796875           0.6  ...               10.2   \n",
       "\n",
       "   sun_azimuth:d_sin  sun_azimuth:d_cos  hour  dayofmonth  dayofweek  quarter  \\\n",
       "0          -0.827235           3.904145    22           2          6        2   \n",
       "1           0.137934           3.988335    23           2          6        2   \n",
       "2           1.028531           3.856086     0           3          0        2   \n",
       "3           1.912442           3.503262     1           3          0        2   \n",
       "4           2.670854           2.966543     2           3          0        2   \n",
       "\n",
       "   month  year  dayofyear  \n",
       "0      6  2019        153  \n",
       "1      6  2019        153  \n",
       "2      6  2019        154  \n",
       "3      6  2019        154  \n",
       "4      6  2019        154  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first renaming the date_forecast columns to time  (DOES NOT WORK)\n",
    "for df in list_of_all_estimated_and_observed_sets:               \n",
    "    df.rename(columns={'date_forecast': 'time'}, inplace=True)\n",
    "\n",
    "#maybe we can drop it here already actually\n",
    "X_train_observed_a.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data = first 75% of observed + first 75% of estimated\n",
    "Validation data = last 25% of observed + last 25% of estimated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34085, 43) (34085, 2)\n",
      "(32843, 43) (32843, 2)\n",
      "(26095, 43) (26095, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Making training and validation data for A\n",
    "percent_observed_train_a = 1\n",
    "percent_estimated_train_a = 1\n",
    "\n",
    "split_index_obs_a = int(len(X_train_observed_a)*percent_observed_train_a)\n",
    "X_train_observed_a_first_75 = X_train_observed_a[:split_index_obs_a]\n",
    "X_train_observed_a_last_25 = X_train_observed_a[split_index_obs_a:]\n",
    "\n",
    "split_index_est_a = int(len(X_train_estimated_a)*percent_estimated_train_a)\n",
    "X_train_estimated_a_first_75 = X_train_estimated_a[:split_index_est_a]\n",
    "X_train_estimated_a_last_25 = X_train_estimated_a[split_index_est_a:]\n",
    "\n",
    "X_train_a = pd.concat([X_train_observed_a_first_75, X_train_estimated_a_first_75])\n",
    "y_train_a = y_a[y_a[\"time\"].isin(X_train_a['date_forecast'])]\n",
    "print(X_train_a.shape, y_train_a.shape)\n",
    "\n",
    "X_validate_a = pd.concat([X_train_observed_a_last_25, X_train_estimated_a_last_25])\n",
    "y_validate_a = y_a[y_a[\"time\"].isin(X_validate_a['date_forecast'])]\n",
    "\n",
    "\n",
    "# making training and validation for B\n",
    "percent_observed_train_b = 1\n",
    "percent_estimated_train_b = 1\n",
    "\n",
    "split_index_obs_b = int(len(X_train_observed_b)*percent_observed_train_b)\n",
    "X_train_observed_b_first_75 = X_train_observed_b[:split_index_obs_b]\n",
    "X_train_observed_b_last_25 = X_train_observed_b[split_index_obs_b:]\n",
    "\n",
    "\n",
    "split_index_est_b = int(len(X_train_estimated_b)*percent_estimated_train_b)\n",
    "X_train_estimated_b_first_75 = X_train_estimated_b[:split_index_est_b]\n",
    "X_train_estimated_b_last_25 = X_train_estimated_b[split_index_est_b:]\n",
    "\n",
    "X_train_b = pd.concat([X_train_observed_b_first_75, X_train_estimated_b_first_75])\n",
    "y_train_b = y_b[y_b[\"time\"].isin(X_train_b['date_forecast'])]\n",
    "print(X_train_b.shape, y_train_b.shape)\n",
    "\n",
    "X_validate_b = pd.concat([X_train_observed_b_last_25, X_train_estimated_b_last_25])\n",
    "y_validate_b = y_b[y_b[\"time\"].isin(X_validate_b['date_forecast'])]\n",
    "\n",
    "# making training and validation for C\n",
    "percent_observed_train_c = 1\n",
    "percent_estimated_train_c = 1\n",
    "\n",
    "split_index_obs_c = int(len(X_train_observed_c)*percent_observed_train_c)\n",
    "X_train_observed_c_first_75 = X_train_observed_c[:split_index_obs_c]\n",
    "X_train_observed_c_last_25 = X_train_observed_c[split_index_obs_c:]\n",
    "\n",
    "split_index_est_c = int(len(X_train_estimated_c)*percent_estimated_train_c)\n",
    "X_train_estimated_c_first_75 = X_train_estimated_c[:split_index_est_c]\n",
    "X_train_estimated_c_last_25 = X_train_estimated_c[split_index_est_c:]\n",
    "\n",
    "X_train_c = pd.concat([X_train_observed_c_first_75, X_train_estimated_c_first_75])\n",
    "y_train_c = y_c[y_c[\"time\"].isin(X_train_c['date_forecast'])]\n",
    "print(X_train_c.shape, y_train_c.shape)\n",
    "\n",
    "X_validate_c = pd.concat([X_train_observed_c_last_25, X_train_estimated_c_last_25])\n",
    "y_validate_c = y_c[y_c[\"time\"].isin(X_validate_c['date_forecast'])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing repeated indexes here, think this might be the wrong place to do it, should probably to it for the concat BUT hEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_repeated_indexes(df, column_name, repeat_count=12):\n",
    "    \"\"\"\n",
    "    Find and return the indexes of rows with a specified number of repeated values in a given column.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame to search for repeated rows.\n",
    "    - column_name: Name of the column to check for repeated values.\n",
    "    - repeat_count: Number of repeated values required to consider a row as a match.\n",
    "\n",
    "    Returns:\n",
    "    - List of indexes for rows with the specified number of repeated values in the given column.\n",
    "    \"\"\"\n",
    "    df = df.reset_index()\n",
    "    repeated_indexes = []\n",
    "    temp_repeated_indexes = []\n",
    "    current_value = None\n",
    "    count = 0\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        value = row[column_name]\n",
    "\n",
    "        if value == current_value:\n",
    "            count += 1\n",
    "            temp_repeated_indexes.append(index)\n",
    "        else:\n",
    "            current_value = value\n",
    "            if count <= repeat_count:\n",
    "                temp_repeated_indexes = []\n",
    "                count = 1\n",
    "            else:\n",
    "                for i in temp_repeated_indexes:\n",
    "                    if i not in repeated_indexes:\n",
    "                        repeated_indexes.append(i)\n",
    "                temp_repeated_indexes = []\n",
    "                count = 1\n",
    "            \n",
    "\n",
    "    return repeated_indexes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34085, 43) (34085, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34043, 43) (34043, 3)\n"
     ]
    }
   ],
   "source": [
    "#removing repeated indexes\n",
    "\n",
    "#A\n",
    "print(X_train_a.shape, y_train_a.shape)\n",
    "repeated_indices = find_repeated_indexes(y_train_a,\"pv_measurement\", 24)\n",
    "y_train_a = y_train_a.reset_index()\n",
    "y_train_a = y_train_a.drop(repeated_indices)\n",
    "X_train_a = X_train_a[X_train_a[\"date_forecast\"].isin(y_train_a[\"time\"])]\n",
    "print(X_train_a.shape, y_train_a.shape)\n",
    "\n",
    "repeated_indices = find_repeated_indexes(y_validate_a,\"pv_measurement\",22)\n",
    "y_validate_a = y_validate_a.reset_index()\n",
    "y_validate_a = y_validate_a.drop(repeated_indices)\n",
    "X_validate_a = X_validate_a[X_validate_a[\"date_forecast\"].isin(y_validate_a[\"time\"])]\n",
    "\n",
    "y_train_a.reset_index(drop=True, inplace=True)\n",
    "X_train_a.reset_index(drop=True, inplace=True)\n",
    "y_validate_a.reset_index(drop=True, inplace=True)\n",
    "X_validate_a.reset_index(drop=True, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32843, 43) (32843, 2)\n",
      "(25954, 43) (25954, 3)\n"
     ]
    }
   ],
   "source": [
    "#B  -  works reeaaaly well for B\n",
    "print(X_train_b.shape, y_train_b.shape)\n",
    "repeated_indices = find_repeated_indexes(y_train_b,\"pv_measurement\", 24)\n",
    "y_train_b = y_train_b.reset_index()\n",
    "y_train_b = y_train_b.drop(repeated_indices)\n",
    "X_train_b = X_train_b[X_train_b[\"date_forecast\"].isin(y_train_b[\"time\"])]\n",
    "print(X_train_b.shape, y_train_b.shape)\n",
    "\n",
    "repeated_indices = find_repeated_indexes(y_validate_b,\"pv_measurement\",24)\n",
    "y_validate_b = y_validate_b.reset_index()\n",
    "y_validate_b = y_validate_b.drop(repeated_indices)\n",
    "X_validate_b = X_validate_b[X_validate_b[\"date_forecast\"].isin(y_validate_b[\"time\"])]\n",
    "\n",
    "y_train_b.reset_index(drop=True, inplace=True)\n",
    "X_train_b.reset_index(drop=True, inplace=True)\n",
    "y_validate_b.reset_index(drop=True, inplace=True)\n",
    "X_validate_b.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26095, 43) (26095, 2)\n",
      "(21169, 43) (21169, 3)\n"
     ]
    }
   ],
   "source": [
    "#C\n",
    "print(X_train_c.shape, y_train_c.shape)\n",
    "repeated_indices = find_repeated_indexes(y_train_c,\"pv_measurement\", 24)\n",
    "y_train_c = y_train_c.reset_index()\n",
    "y_train_c = y_train_c.drop(repeated_indices)\n",
    "X_train_c = X_train_c[X_train_c[\"date_forecast\"].isin(y_train_c[\"time\"])]\n",
    "print(X_train_c.shape, y_train_c.shape)\n",
    "\n",
    "repeated_indices = find_repeated_indexes(y_validate_c,\"pv_measurement\",24)\n",
    "y_validate_c = y_validate_c.reset_index()\n",
    "y_validate_c = y_validate_c.drop(repeated_indices)\n",
    "X_validate_c = X_validate_c[X_validate_c[\"date_forecast\"].isin(y_validate_c[\"time\"])]\n",
    "\n",
    "y_train_c.reset_index(drop=True, inplace=True)\n",
    "X_train_c.reset_index(drop=True, inplace=True)\n",
    "y_validate_c.reset_index(drop=True, inplace=True)\n",
    "X_validate_c.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing time feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_a.drop(\"date_forecast\", axis=1, inplace=True)\n",
    "y_train_a.drop(\"time\", axis=1, inplace=True)\n",
    "X_validate_a.drop(\"date_forecast\", axis=1, inplace=True)\n",
    "y_validate_a.drop(\"time\", axis=1, inplace=True)\n",
    "\n",
    "X_train_b.drop(\"date_forecast\", axis=1, inplace=True)\n",
    "y_train_b.drop(\"time\", axis=1, inplace=True)\n",
    "X_validate_b.drop(\"date_forecast\", axis=1, inplace=True)\n",
    "y_validate_b.drop(\"time\", axis=1, inplace=True)\n",
    "\n",
    "X_train_c.drop(\"date_forecast\", axis=1, inplace=True)\n",
    "y_train_c.drop(\"time\", axis=1, inplace=True)\n",
    "X_validate_c.drop(\"date_forecast\", axis=1, inplace=True)\n",
    "y_validate_c.drop(\"time\", axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding location features to the sets before merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_a[\"location\"] =  \"A\" \n",
    "y_train_a[\"location\"] = \"A\"\n",
    "X_validate_a[\"location\"] = \"A\"\n",
    "y_validate_a[\"location\"] = \"A\"\n",
    "\n",
    "X_train_b[\"location\"] = \"B\"\n",
    "y_train_b[\"location\"] = \"B\"\n",
    "X_validate_b[\"location\"] = \"B\"\n",
    "y_validate_b[\"location\"] = \"B\"\n",
    "\n",
    "X_train_c[\"location\"] = \"C\"\n",
    "y_train_c[\"location\"] = \"C\"\n",
    "X_validate_c[\"location\"] = \"C\"\n",
    "y_validate_c[\"location\"] = \"C\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging tranining data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81166, 43)\n",
      "(81166, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.concat([X_train_a, X_train_b, X_train_c])\n",
    "y_train = pd.concat([y_train_a, y_train_b, y_train_c])\n",
    "\n",
    "X_validate = pd.concat([X_validate_a, X_validate_b, X_validate_c])\n",
    "y_validate = pd.concat([y_validate_a, y_validate_b, y_validate_c])\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding and dropping location feature   some fuckery here\n",
    "# one_hot = pd.get_dummies(X_train[\"location\"]).astype(int)\n",
    "# X_train = X_train.drop(\"location\", axis=1)\n",
    "# X_train = pd.merge(X_train, one_hot, left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "# one_hot = pd.get_dummies(X_validate[\"location\"]).astype(int)\n",
    "# X_validate = pd.merge(X_validate, one_hot, left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixing test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load valid dates function\n",
    "import os\n",
    "\n",
    "\n",
    "dir_path = os.getcwd()\n",
    "def load_valid_dates():\n",
    "    \n",
    "    test = pd.read_csv(f\"{dir_path}/../data/test.csv\")\n",
    "\n",
    "    return test[\"time\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding location feature\n",
    "\n",
    "X_test_estimated_a[\"location\"] = \"A\"\n",
    "X_test_estimated_b[\"location\"] = \"B\"\n",
    "X_test_estimated_c[\"location\"] = \"C\"\n",
    "\n",
    "# concatting:\n",
    "X_test = pd.concat([X_test_estimated_a, X_test_estimated_b, X_test_estimated_c])\n",
    "# filtering out invalid dates:\n",
    "X_test = X_test[X_test[\"date_forecast\"].isin(load_valid_dates())]\n",
    "# removing forecast coloum\n",
    "X_test = X_test.drop(\"date_forecast\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute_humidity_2m:gm3</th>\n",
       "      <th>air_density_2m:kgm3</th>\n",
       "      <th>clear_sky_energy_1h:J</th>\n",
       "      <th>clear_sky_rad:W</th>\n",
       "      <th>dew_or_rime:idx</th>\n",
       "      <th>dew_point_2m:K</th>\n",
       "      <th>diffuse_rad:W</th>\n",
       "      <th>diffuse_rad_1h:J</th>\n",
       "      <th>direct_rad:W</th>\n",
       "      <th>direct_rad_1h:J</th>\n",
       "      <th>...</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofmonth</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>quarter</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.300001</td>\n",
       "      <td>5.147</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1086.600098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2023</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.100000</td>\n",
       "      <td>5.144</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1085.800049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2023</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.599998</td>\n",
       "      <td>5.135</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1084.199951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2023</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.100000</td>\n",
       "      <td>5.128</td>\n",
       "      <td>4.049770e+04</td>\n",
       "      <td>46.700001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1082.599976</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>67380.906250</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>15061.400391</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2023</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.600000</td>\n",
       "      <td>5.124</td>\n",
       "      <td>5.669944e+05</td>\n",
       "      <td>307.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1081.500000</td>\n",
       "      <td>189.600006</td>\n",
       "      <td>408838.812500</td>\n",
       "      <td>101.800003</td>\n",
       "      <td>198284.796875</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2023</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>33.599998</td>\n",
       "      <td>4.787</td>\n",
       "      <td>1.903926e+06</td>\n",
       "      <td>339.100006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1126.800049</td>\n",
       "      <td>128.800003</td>\n",
       "      <td>650270.125000</td>\n",
       "      <td>53.800003</td>\n",
       "      <td>212259.687500</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2023</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>34.400002</td>\n",
       "      <td>4.800</td>\n",
       "      <td>7.330454e+05</td>\n",
       "      <td>98.199997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1128.099976</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>331501.406250</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>114095.203125</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2023</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>35.500000</td>\n",
       "      <td>4.814</td>\n",
       "      <td>1.473243e+05</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1129.400024</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>108841.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17289.900391</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2023</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>4.826</td>\n",
       "      <td>1.378300e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1130.400024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8968.599609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2023</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>35.799999</td>\n",
       "      <td>4.828</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1129.900024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2023</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2160 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      absolute_humidity_2m:gm3  air_density_2m:kgm3  clear_sky_energy_1h:J  \\\n",
       "0                    17.300001                5.147           0.000000e+00   \n",
       "1                    17.100000                5.144           0.000000e+00   \n",
       "2                    16.599998                5.135           0.000000e+00   \n",
       "3                    16.100000                5.128           4.049770e+04   \n",
       "4                    15.600000                5.124           5.669944e+05   \n",
       "...                        ...                  ...                    ...   \n",
       "2155                 33.599998                4.787           1.903926e+06   \n",
       "2156                 34.400002                4.800           7.330454e+05   \n",
       "2157                 35.500000                4.814           1.473243e+05   \n",
       "2158                 36.000000                4.826           1.378300e+03   \n",
       "2159                 35.799999                4.828           0.000000e+00   \n",
       "\n",
       "      clear_sky_rad:W  dew_or_rime:idx  dew_point_2m:K  diffuse_rad:W  \\\n",
       "0            0.000000              0.0     1086.600098       0.000000   \n",
       "1            0.000000              0.0     1085.800049       0.000000   \n",
       "2            0.000000              0.0     1084.199951       0.000000   \n",
       "3           46.700001              0.0     1082.599976      37.500000   \n",
       "4          307.500000              0.0     1081.500000     189.600006   \n",
       "...               ...              ...             ...            ...   \n",
       "2155       339.100006              0.0     1126.800049     128.800003   \n",
       "2156        98.199997              0.0     1128.099976      55.500000   \n",
       "2157         4.900000              0.0     1129.400024       5.000000   \n",
       "2158         0.000000              0.0     1130.400024       0.000000   \n",
       "2159         0.000000              0.0     1129.900024       0.000000   \n",
       "\n",
       "      diffuse_rad_1h:J  direct_rad:W  direct_rad_1h:J  ...  hour  dayofmonth  \\\n",
       "0             0.000000      0.000000         0.000000  ...     0           1   \n",
       "1             0.000000      0.000000         0.000000  ...     1           1   \n",
       "2             0.000000      0.000000         0.000000  ...     2           1   \n",
       "3         67380.906250      8.400000     15061.400391  ...     3           1   \n",
       "4        408838.812500    101.800003    198284.796875  ...     4           1   \n",
       "...                ...           ...              ...  ...   ...         ...   \n",
       "2155     650270.125000     53.800003    212259.687500  ...    19           3   \n",
       "2156     331501.406250      9.600000    114095.203125  ...    20           3   \n",
       "2157     108841.000000      0.000000     17289.900391  ...    21           3   \n",
       "2158       8968.599609      0.000000         0.000000  ...    22           3   \n",
       "2159          0.000000      0.000000         0.000000  ...    23           3   \n",
       "\n",
       "      dayofweek  quarter  month  year  dayofyear  A  B  C  \n",
       "0             0        2      5  2023        121  1  0  0  \n",
       "1             0        2      5  2023        121  1  0  0  \n",
       "2             0        2      5  2023        121  1  0  0  \n",
       "3             0        2      5  2023        121  1  0  0  \n",
       "4             0        2      5  2023        121  1  0  0  \n",
       "...         ...      ...    ...   ...        ... .. .. ..  \n",
       "2155          0        3      7  2023        184  0  0  1  \n",
       "2156          0        3      7  2023        184  0  0  1  \n",
       "2157          0        3      7  2023        184  0  0  1  \n",
       "2158          0        3      7  2023        184  0  0  1  \n",
       "2159          0        3      7  2023        184  0  0  1  \n",
       "\n",
       "[2160 rows x 45 columns]"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reset_index().drop(columns=\"index\")\n",
    "one_hot = pd.get_dummies(X_train[\"location\"]).astype(int)\n",
    "X_train = X_train.drop(\"location\", axis=1)\n",
    "X_train = pd.merge(X_train, one_hot, left_index=True, right_index=True)\n",
    "\n",
    "X_validate = X_validate.reset_index().drop(columns=\"index\")\n",
    "one_hot = pd.get_dummies(X_validate[\"location\"]).astype(int)\n",
    "X_validate = X_validate.drop(\"location\", axis=1)\n",
    "X_validate = pd.merge(X_validate, one_hot, left_index=True, right_index=True)\n",
    "\n",
    "X_test = X_test.reset_index().drop(columns=\"index\")\n",
    "one_hot = pd.get_dummies(X_test[\"location\"]).astype(int)\n",
    "X_test = X_test.drop(\"location\", axis=1)\n",
    "X_test = pd.merge(X_test, one_hot, left_index=True, right_index=True)\n",
    "\n",
    "X_test\n",
    "# one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_exclude = [\"A\", \"B\", \"C\", \"dew_or_rime:idx\", \"is_day:idx\", \"_in_shadow:idx\"]\n",
    "\n",
    "columns_to_normalize = [col for col in X_train.columns if col not in columns_to_exclude]\n",
    "\n",
    "#Mean - std normalization\n",
    "\n",
    "# X_train_mean = X_train.mean()\n",
    "# X_train_std = X_train.std()\n",
    "\n",
    "# X_train = (X_train - X_train_mean) / X_train_std\n",
    "# X_validate = (X_validate- X_train_mean) / X_train_std\n",
    "# X_test =  (X_test - X_train_mean) / X_train_std\n",
    "\n",
    "\n",
    "#Min-max\n",
    "# Calculate min and max values for scaling\n",
    "X_min = X_train[columns_to_normalize].min()\n",
    "X_max = X_train[columns_to_normalize].max()\n",
    "\n",
    "# Apply min-max scaling to the columns to be normalized\n",
    "X_train[columns_to_normalize] = (X_train[columns_to_normalize] - X_min) / (X_max - X_min)\n",
    "X_validate[columns_to_normalize] = (X_validate[columns_to_normalize] - X_min) / (X_max - X_min)\n",
    "X_test[columns_to_normalize] = (X_test[columns_to_normalize] - X_min) / (X_max - X_min)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       index  pv_measurement location\n",
      "0          0            0.00        A\n",
      "1          1            0.00        A\n",
      "2          2            0.00        A\n",
      "3          3            0.00        A\n",
      "4          4           19.36        A\n",
      "...      ...             ...      ...\n",
      "21164  32150           50.96        C\n",
      "21165  32151            2.94        C\n",
      "21166  32152            0.00        C\n",
      "21167  32153           -0.00        C\n",
      "21168  32154           -0.00        C\n",
      "\n",
      "[81166 rows x 3 columns]\n",
      "       index  pv_measurement location\n",
      "0          0        0.000000        A\n",
      "1          1        0.000000        A\n",
      "2          2        0.000000        A\n",
      "3          3        0.000000        A\n",
      "4          4        0.003377        A\n",
      "...      ...             ...      ...\n",
      "21164  32150        0.008888        C\n",
      "21165  32151        0.000513        C\n",
      "21166  32152        0.000000        C\n",
      "21167  32153        0.000000        C\n",
      "21168  32154        0.000000        C\n",
      "\n",
      "[81166 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "y_scaler = MinMaxScaler()\n",
    "print(y_train)\n",
    "\n",
    "\n",
    "y_train[\"pv_measurement\"] = y_scaler.fit_transform(y_train[\"pv_measurement\"].values.reshape(-1,1))\n",
    "\n",
    "print(y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = xgb.XGBRegressor(\n",
    "#     max_depth=7,\n",
    "#     colsample_bytree=0.8,\n",
    "#     eta=0.1,\n",
    "#     n_estimators=90,\n",
    "#     reg_alpha=0.01,\n",
    "#     reg_lambda=0.01,\n",
    "#     enable_categorical=True\n",
    "# )\n",
    "\n",
    "# model.fit(X_train, y_train[\"pv_measurement\"])\n",
    "\n",
    "# X_validate_a_loc = X_validate[X_validate_a[\"location\"]==\"A\"]\n",
    "# X_validate_a_loc = X_validate_a_loc.drop(\"location\", axis=1)\n",
    "\n",
    "# prediction = model.predict(X_validate)\n",
    "\n",
    "# prediction_a = model.predict(X_validate_a)\n",
    "# prediction_b = model.predict(X_validate_b)\n",
    "# prediction_c = model.predict(X_validate_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\n",
    "#     \"MAE: \",\n",
    "#     round(\n",
    "#         mean_absolute_error(\n",
    "#             y_true=y_validate[\"pv_measurement\"],\n",
    "#             y_pred=prediction,\n",
    "#         ),\n",
    "#         3,\n",
    "#     ),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting:\n",
    "# predict = model.predict(X_test)\n",
    "# print(predict.head())\n",
    "# predict = y_scaler.inverse_transform(predict.reshape(-1, 1))\n",
    "# print(predict.head())\n",
    "\n",
    "# resultframe = pd.DataFrame(columns = [\"id\", \"prediction\"])\n",
    "# resultframe[\"prediction\"] = predict\n",
    "# print(resultframe.shape)\n",
    "# resultframe[\"id\"] = range(len(resultframe))\n",
    "# resultframe.head()\n",
    "# # making the csv\n",
    "# # final = prediction.reset_index().reset_index().rename(columns={\"level_0\": \"id\", \"y\": \"prediction\"})[[\"id\", \"prediction\"]]\n",
    "\n",
    "# resultframe.to_csv(\"submission_super_all_the_guys_6.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute_humidity_2m:gm3</th>\n",
       "      <th>air_density_2m:kgm3</th>\n",
       "      <th>clear_sky_energy_1h:J</th>\n",
       "      <th>clear_sky_rad:W</th>\n",
       "      <th>dew_or_rime:idx</th>\n",
       "      <th>dew_point_2m:K</th>\n",
       "      <th>diffuse_rad:W</th>\n",
       "      <th>diffuse_rad_1h:J</th>\n",
       "      <th>direct_rad:W</th>\n",
       "      <th>direct_rad_1h:J</th>\n",
       "      <th>...</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofmonth</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>quarter</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.249280</td>\n",
       "      <td>0.902191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.925160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.328767</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.246398</td>\n",
       "      <td>0.901665</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.924479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.328767</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.239193</td>\n",
       "      <td>0.900088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.923116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.328767</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.231988</td>\n",
       "      <td>0.898861</td>\n",
       "      <td>0.003385</td>\n",
       "      <td>0.013971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.921754</td>\n",
       "      <td>0.028006</td>\n",
       "      <td>0.014057</td>\n",
       "      <td>0.003073</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.328767</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.224784</td>\n",
       "      <td>0.898160</td>\n",
       "      <td>0.047398</td>\n",
       "      <td>0.091994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.920817</td>\n",
       "      <td>0.141598</td>\n",
       "      <td>0.085295</td>\n",
       "      <td>0.037240</td>\n",
       "      <td>0.020301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.328767</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   absolute_humidity_2m:gm3  air_density_2m:kgm3  clear_sky_energy_1h:J  \\\n",
       "0                  0.249280             0.902191               0.000000   \n",
       "1                  0.246398             0.901665               0.000000   \n",
       "2                  0.239193             0.900088               0.000000   \n",
       "3                  0.231988             0.898861               0.003385   \n",
       "4                  0.224784             0.898160               0.047398   \n",
       "\n",
       "   clear_sky_rad:W  dew_or_rime:idx  dew_point_2m:K  diffuse_rad:W  \\\n",
       "0         0.000000              0.0        0.925160       0.000000   \n",
       "1         0.000000              0.0        0.924479       0.000000   \n",
       "2         0.000000              0.0        0.923116       0.000000   \n",
       "3         0.013971              0.0        0.921754       0.028006   \n",
       "4         0.091994              0.0        0.920817       0.141598   \n",
       "\n",
       "   diffuse_rad_1h:J  direct_rad:W  direct_rad_1h:J  ...      hour  dayofmonth  \\\n",
       "0          0.000000      0.000000         0.000000  ...  0.000000         0.0   \n",
       "1          0.000000      0.000000         0.000000  ...  0.043478         0.0   \n",
       "2          0.000000      0.000000         0.000000  ...  0.086957         0.0   \n",
       "3          0.014057      0.003073         0.001542  ...  0.130435         0.0   \n",
       "4          0.085295      0.037240         0.020301  ...  0.173913         0.0   \n",
       "\n",
       "   dayofweek   quarter     month  year  dayofyear  A  B  C  \n",
       "0        0.0  0.333333  0.363636   1.0   0.328767  1  0  0  \n",
       "1        0.0  0.333333  0.363636   1.0   0.328767  1  0  0  \n",
       "2        0.0  0.333333  0.363636   1.0   0.328767  1  0  0  \n",
       "3        0.0  0.333333  0.363636   1.0   0.328767  1  0  0  \n",
       "4        0.0  0.333333  0.363636   1.0   0.328767  1  0  0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the h20 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-5.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-5 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-5 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-5 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table th,\n",
       "#h2o-table-5 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-5 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-5\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>33 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Oslo</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.42.0.4</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>9 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_siver_e1nsav</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>1.466 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.9.13 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         33 secs\n",
       "H2O_cluster_timezone:       Europe/Oslo\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.42.0.4\n",
       "H2O_cluster_version_age:    9 days\n",
       "H2O_cluster_name:           H2O_from_python_siver_e1nsav\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    1.466 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.9.13 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |█\n",
      "13:57:06.313: AutoML: XGBoost is not available; skipping it.\n",
      "\n",
      "██████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "h2o.init()\n",
    "\n",
    "X_train = X_train.reset_index().drop(columns=\"index\")\n",
    "y_train = y_train.reset_index().drop(columns=\"index\")\n",
    "new_train = pd.merge(X_train, y_train[\"pv_measurement\"], left_index=True, right_index=True)\n",
    "\n",
    "X_validate = X_validate.reset_index().drop(columns=\"index\")\n",
    "y_validate = y_validate.reset_index().drop(columns=\"index\")\n",
    "new_validate = pd.merge(X_validate, y_validate[\"pv_measurement\"], left_index=True, right_index=True)\n",
    "\n",
    "h2o_train= h2o.H2OFrame(new_train)\n",
    "h2o_validate= h2o.H2OFrame(new_validate)\n",
    "h2o_test = h2o.H2OFrame(X_test)\n",
    "\n",
    "aml = H2OAutoML(max_models=20, seed=1, stopping_metric=\"MAE\", sort_metric=\"MAE\", stopping_tolerance=0.001)\n",
    "# aml.train(x=h2o_train.columns, y=\"pv_measurement\", training_frame=h2o_train, validation_frame=h2o_validate)\n",
    "aml.train(x=h2o_train.columns, y=\"pv_measurement\", training_frame=h2o_train)\n",
    "lb = aml.leaderboard\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th>model_id                                               </th><th style=\"text-align: right;\">      mae</th><th style=\"text-align: right;\">     rmse</th><th style=\"text-align: right;\">       mse</th><th style=\"text-align: right;\">    rmsle</th><th style=\"text-align: right;\">  mean_residual_deviance</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20231013_135706_model_5            </td><td style=\"text-align: right;\">0.0146351</td><td style=\"text-align: right;\">0.0441073</td><td style=\"text-align: right;\">0.00194545</td><td style=\"text-align: right;\">0.0325936</td><td style=\"text-align: right;\">              0.00194545</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_1_AutoML_1_20231013_135706   </td><td style=\"text-align: right;\">0.0148682</td><td style=\"text-align: right;\">0.0429199</td><td style=\"text-align: right;\">0.00184212</td><td style=\"text-align: right;\">0.0317281</td><td style=\"text-align: right;\">              0.00184212</td></tr>\n",
       "<tr><td>GBM_4_AutoML_1_20231013_135706                         </td><td style=\"text-align: right;\">0.0149636</td><td style=\"text-align: right;\">0.0445948</td><td style=\"text-align: right;\">0.0019887 </td><td style=\"text-align: right;\">0.0329688</td><td style=\"text-align: right;\">              0.0019887 </td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_1_AutoML_1_20231013_135706</td><td style=\"text-align: right;\">0.0150808</td><td style=\"text-align: right;\">0.0439552</td><td style=\"text-align: right;\">0.00193206</td><td style=\"text-align: right;\">0.0325   </td><td style=\"text-align: right;\">              0.00193206</td></tr>\n",
       "<tr><td>GBM_3_AutoML_1_20231013_135706                         </td><td style=\"text-align: right;\">0.0154723</td><td style=\"text-align: right;\">0.0456152</td><td style=\"text-align: right;\">0.00208074</td><td style=\"text-align: right;\">0.0337079</td><td style=\"text-align: right;\">              0.00208074</td></tr>\n",
       "<tr><td>GBM_1_AutoML_1_20231013_135706                         </td><td style=\"text-align: right;\">0.0157797</td><td style=\"text-align: right;\">0.0464368</td><td style=\"text-align: right;\">0.00215637</td><td style=\"text-align: right;\">0.0343431</td><td style=\"text-align: right;\">              0.00215637</td></tr>\n",
       "<tr><td>DRF_1_AutoML_1_20231013_135706                         </td><td style=\"text-align: right;\">0.0158048</td><td style=\"text-align: right;\">0.0464803</td><td style=\"text-align: right;\">0.00216042</td><td style=\"text-align: right;\">0.0344129</td><td style=\"text-align: right;\">              0.00216042</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20231013_135706_model_4            </td><td style=\"text-align: right;\">0.0159132</td><td style=\"text-align: right;\">0.0445029</td><td style=\"text-align: right;\">0.00198051</td><td style=\"text-align: right;\">0.032943 </td><td style=\"text-align: right;\">              0.00198051</td></tr>\n",
       "<tr><td>GBM_2_AutoML_1_20231013_135706                         </td><td style=\"text-align: right;\">0.0160824</td><td style=\"text-align: right;\">0.0466329</td><td style=\"text-align: right;\">0.00217462</td><td style=\"text-align: right;\">0.0345066</td><td style=\"text-align: right;\">              0.00217462</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20231013_135706_model_1            </td><td style=\"text-align: right;\">0.0164544</td><td style=\"text-align: right;\">0.044885 </td><td style=\"text-align: right;\">0.00201466</td><td style=\"text-align: right;\">0.0332722</td><td style=\"text-align: right;\">              0.00201466</td></tr>\n",
       "<tr><td>GBM_5_AutoML_1_20231013_135706                         </td><td style=\"text-align: right;\">0.0164982</td><td style=\"text-align: right;\">0.0475775</td><td style=\"text-align: right;\">0.00226362</td><td style=\"text-align: right;\">0.0352173</td><td style=\"text-align: right;\">              0.00226362</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20231013_135706_model_3            </td><td style=\"text-align: right;\">0.0171798</td><td style=\"text-align: right;\">0.0487559</td><td style=\"text-align: right;\">0.00237714</td><td style=\"text-align: right;\">0.0360994</td><td style=\"text-align: right;\">              0.00237714</td></tr>\n",
       "<tr><td>XRT_1_AutoML_1_20231013_135706                         </td><td style=\"text-align: right;\">0.0173415</td><td style=\"text-align: right;\">0.0473872</td><td style=\"text-align: right;\">0.00224554</td><td style=\"text-align: right;\">0.0350301</td><td style=\"text-align: right;\">              0.00224554</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20231013_135706_model_2            </td><td style=\"text-align: right;\">0.0183952</td><td style=\"text-align: right;\">0.0505604</td><td style=\"text-align: right;\">0.00255635</td><td style=\"text-align: right;\">0.0375088</td><td style=\"text-align: right;\">              0.00255635</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20231013_135706_model_1   </td><td style=\"text-align: right;\">0.0216486</td><td style=\"text-align: right;\">0.0529449</td><td style=\"text-align: right;\">0.00280316</td><td style=\"text-align: right;\">0.039324 </td><td style=\"text-align: right;\">              0.00280316</td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_1_20231013_135706                </td><td style=\"text-align: right;\">0.0222841</td><td style=\"text-align: right;\">0.0521083</td><td style=\"text-align: right;\">0.00271528</td><td style=\"text-align: right;\">0.0389498</td><td style=\"text-align: right;\">              0.00271528</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20231013_135706_model_1   </td><td style=\"text-align: right;\">0.0224479</td><td style=\"text-align: right;\">0.0542921</td><td style=\"text-align: right;\">0.00294763</td><td style=\"text-align: right;\">0.0400488</td><td style=\"text-align: right;\">              0.00294763</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20231013_135706_model_1   </td><td style=\"text-align: right;\">0.0240321</td><td style=\"text-align: right;\">0.0577214</td><td style=\"text-align: right;\">0.00333176</td><td style=\"text-align: right;\">0.0434506</td><td style=\"text-align: right;\">              0.00333176</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20231013_135706_model_2   </td><td style=\"text-align: right;\">0.0285855</td><td style=\"text-align: right;\">0.0673981</td><td style=\"text-align: right;\">0.0045425 </td><td style=\"text-align: right;\">0.0521815</td><td style=\"text-align: right;\">              0.0045425 </td></tr>\n",
       "<tr><td>GLM_1_AutoML_1_20231013_135706                         </td><td style=\"text-align: right;\">0.0621817</td><td style=\"text-align: right;\">0.0931605</td><td style=\"text-align: right;\">0.00867887</td><td style=\"text-align: right;\">0.0729854</td><td style=\"text-align: right;\">              0.00867887</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20231013_135706_model_2   </td><td style=\"text-align: right;\">0.0668712</td><td style=\"text-align: right;\">0.0863912</td><td style=\"text-align: right;\">0.00746344</td><td style=\"text-align: right;\">0.0703526</td><td style=\"text-align: right;\">              0.00746344</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20231013_135706_model_2   </td><td style=\"text-align: right;\">0.0682228</td><td style=\"text-align: right;\">0.0913177</td><td style=\"text-align: right;\">0.00833893</td><td style=\"text-align: right;\">0.0744592</td><td style=\"text-align: right;\">              0.00833893</td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[22 rows x 6 columns]</pre>"
      ],
      "text/plain": [
       "model_id                                                       mae       rmse         mse      rmsle    mean_residual_deviance\n",
       "-------------------------------------------------------  ---------  ---------  ----------  ---------  ------------------------\n",
       "GBM_grid_1_AutoML_1_20231013_135706_model_5              0.0146351  0.0441073  0.00194545  0.0325936                0.00194545\n",
       "StackedEnsemble_AllModels_1_AutoML_1_20231013_135706     0.0148682  0.0429199  0.00184212  0.0317281                0.00184212\n",
       "GBM_4_AutoML_1_20231013_135706                           0.0149636  0.0445948  0.0019887   0.0329688                0.0019887\n",
       "StackedEnsemble_BestOfFamily_1_AutoML_1_20231013_135706  0.0150808  0.0439552  0.00193206  0.0325                   0.00193206\n",
       "GBM_3_AutoML_1_20231013_135706                           0.0154723  0.0456152  0.00208074  0.0337079                0.00208074\n",
       "GBM_1_AutoML_1_20231013_135706                           0.0157797  0.0464368  0.00215637  0.0343431                0.00215637\n",
       "DRF_1_AutoML_1_20231013_135706                           0.0158048  0.0464803  0.00216042  0.0344129                0.00216042\n",
       "GBM_grid_1_AutoML_1_20231013_135706_model_4              0.0159132  0.0445029  0.00198051  0.032943                 0.00198051\n",
       "GBM_2_AutoML_1_20231013_135706                           0.0160824  0.0466329  0.00217462  0.0345066                0.00217462\n",
       "GBM_grid_1_AutoML_1_20231013_135706_model_1              0.0164544  0.044885   0.00201466  0.0332722                0.00201466\n",
       "GBM_5_AutoML_1_20231013_135706                           0.0164982  0.0475775  0.00226362  0.0352173                0.00226362\n",
       "GBM_grid_1_AutoML_1_20231013_135706_model_3              0.0171798  0.0487559  0.00237714  0.0360994                0.00237714\n",
       "XRT_1_AutoML_1_20231013_135706                           0.0173415  0.0473872  0.00224554  0.0350301                0.00224554\n",
       "GBM_grid_1_AutoML_1_20231013_135706_model_2              0.0183952  0.0505604  0.00255635  0.0375088                0.00255635\n",
       "DeepLearning_grid_2_AutoML_1_20231013_135706_model_1     0.0216486  0.0529449  0.00280316  0.039324                 0.00280316\n",
       "DeepLearning_1_AutoML_1_20231013_135706                  0.0222841  0.0521083  0.00271528  0.0389498                0.00271528\n",
       "DeepLearning_grid_3_AutoML_1_20231013_135706_model_1     0.0224479  0.0542921  0.00294763  0.0400488                0.00294763\n",
       "DeepLearning_grid_1_AutoML_1_20231013_135706_model_1     0.0240321  0.0577214  0.00333176  0.0434506                0.00333176\n",
       "DeepLearning_grid_1_AutoML_1_20231013_135706_model_2     0.0285855  0.0673981  0.0045425   0.0521815                0.0045425\n",
       "GLM_1_AutoML_1_20231013_135706                           0.0621817  0.0931605  0.00867887  0.0729854                0.00867887\n",
       "DeepLearning_grid_2_AutoML_1_20231013_135706_model_2     0.0668712  0.0863912  0.00746344  0.0703526                0.00746344\n",
       "DeepLearning_grid_3_AutoML_1_20231013_135706_model_2     0.0682228  0.0913177  0.00833893  0.0744592                0.00833893\n",
       "[22 rows x 6 columns]\n"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.head(rows=lb.nrows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict with the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "prediction_best_model = aml.leader.predict(h2o_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions with the best 3 models: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "second_model_id = lb[1, \"model_id\"]\n",
    "\n",
    "model = h2o.get_model(second_model_id)\n",
    "\n",
    "# Make predictions using the second model on the test dataset\n",
    "second_model_predictions = model.predict(h2o_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_model_predictions = second_model_predictions.as_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the best model to valid format:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaderboard_df = lb.as_data_frame() \n",
    "prediction_df = prediction_best_model.as_data_frame()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renormalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_best__df_scaled = y_scaler.inverse_transform(prediction_df)\n",
    "print(prediction_best__df_scaled)\n",
    "prediction_best__df_scaled = pd.DataFrame(prediction_best__df_scaled)\n",
    "print(prediction_best__df_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing the same for the top 3 models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-8.17388162]\n",
      " [-8.19603506]\n",
      " [-7.91539723]\n",
      " ...\n",
      " [-0.56578328]\n",
      " [-9.40780357]\n",
      " [-6.42414963]]\n",
      "               0\n",
      "0      -8.173882\n",
      "1      -8.196035\n",
      "2      -7.915397\n",
      "3      70.044301\n",
      "4     399.795769\n",
      "...          ...\n",
      "2155   46.563659\n",
      "2156   27.804607\n",
      "2157   -0.565783\n",
      "2158   -9.407804\n",
      "2159   -6.424150\n",
      "\n",
      "[2160 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "prediction_second_best_scaled = y_scaler.inverse_transform(second_model_predictions)\n",
    "print(prediction_second_best_scaled)\n",
    "prediction_second_best_scaled_df = pd.DataFrame(prediction_second_best_scaled)\n",
    "print(prediction_second_best_scaled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shutting down the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H2O session _sid_8e03 closed.\n"
     ]
    }
   ],
   "source": [
    "h2o.cluster().shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a submission for the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultframe = pd.DataFrame(columns = [\"id\", \"prediction\"])\n",
    "resultframe[\"prediction\"] = prediction_best__df_scaled\n",
    "resultframe['prediction'] = np.where(resultframe['prediction'] < 0, 0, resultframe['prediction'])\n",
    "resultframe[\"id\"] = range(len(resultframe))\n",
    "resultframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultframe.to_csv(\"sumbission_all_the_boys_5_001_tolerance.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a submission for second best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>70.044301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>399.795769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  prediction\n",
       "0   0    0.000000\n",
       "1   1    0.000000\n",
       "2   2    0.000000\n",
       "3   3   70.044301\n",
       "4   4  399.795769"
      ]
     },
     "execution_count": 644,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resultframe2 = pd.DataFrame(columns = [\"id\", \"prediction\"])\n",
    "# resultframe2[\"prediction\"] = prediction_second_best_scaled_df\n",
    "# resultframe2['prediction'] = np.where(resultframe2['prediction'] < 0, 0, resultframe2['prediction'])\n",
    "# resultframe2[\"id\"] = range(len(resultframe2))\n",
    "# resultframe2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultframe2.to_csv(\"sumbission_all_the_boys_4_second_best.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
