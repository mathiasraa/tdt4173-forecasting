{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from src.utils import load_all_locations\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_all_locations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_features(df):\n",
    "    df['hour'] = df.time.dt.hour\n",
    "    df['dayofmonth'] = df.time.dt.day\n",
    "    df['dayofweek'] = df.time.dt.dayofweek\n",
    "    df['quarter'] = df.time.dt.quarter\n",
    "    df['month'] = df.time.dt.month\n",
    "    df['year'] = df.time.dt.year\n",
    "    df['dayofyear'] = df.time.dt.dayofyear\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((81118, 53), (81118, 4))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = data[0].copy(), data[1].copy()\n",
    "\n",
    "\n",
    "# One-hot Encoding\n",
    "X = X.reset_index().drop(columns=\"index\")\n",
    "one_hot = pd.get_dummies(X[\"location\"]).astype(int)\n",
    "X = X.drop(\"location\", axis=1)\n",
    "X = pd.merge(X, one_hot, left_index=True, right_index=True)\n",
    "\n",
    "# Add time based features\n",
    "X = create_time_features(X)\n",
    "\n",
    "# Drop datetime\n",
    "X = X.drop(columns=[\"time\"])\n",
    "\n",
    "# Drop missing column values\n",
    "nan_columns = X.columns[X.isna().any()].tolist()\n",
    "X = X.drop(columns=nan_columns)\n",
    "\n",
    "X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[X.set_type == \"TRAIN\"].copy().drop(columns=[\"set_type\"])\n",
    "X_train_scaler = MinMaxScaler()\n",
    "X_train_scaler = X_train_scaler.fit(X_train)\n",
    "X_train = X_train_scaler.transform(X_train)\n",
    "\n",
    "y_train = y[y.set_type == \"TRAIN\"].copy()[[\"y\"]]\n",
    "y_train_scaler = MinMaxScaler()\n",
    "y_train_scaler = y_train_scaler.fit(y_train)\n",
    "y_train = y_train_scaler.transform(y_train)\n",
    "\n",
    "X_test = X[(X.set_type == \"TEST\")].copy().drop(columns=[\"set_type\"])\n",
    "y_test = y[(y.set_type == \"TEST\")].copy()[[\"y\"]]\n",
    "# X_test = X[(X.set_type == \"TEST\") & (X.A == True)].copy().drop(columns=[\"set_type\"])\n",
    "# y_test = y[(y.set_type == \"TEST\") & (y.location == \"A\")].copy()[[\"y\"]]\n",
    "\n",
    "X_test = X_train_scaler.transform(X_test)\n",
    "y_test = y_train_scaler.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        #Hidden Dimension\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        #Building the RNN\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='relu')\n",
    "        \n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initializing the hidden state with zeros\n",
    "        # (layer_dim, batch_size, hidden_dim)\n",
    "        h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
    "        \n",
    "        #One time step (the last one perhaps?)\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        \n",
    "        # Indexing hidden state of the last time step\n",
    "        # out.size() --> ??\n",
    "        #out[:,-1,:] --> is it going to be 100,100\n",
    "        out = self.fc(out[:,-1,:])\n",
    "        # out.size() --> 100,1\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating Model Class\n",
    "input_dim = 52\n",
    "hidden_dim = 15\n",
    "layer_dim = 1\n",
    "output_dim = 1\n",
    "batch_size = 100\n",
    "\n",
    "model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "\n",
    "# Instantiating Loss Class\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "# Instantiate Optimizer Class\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# converting numpy array to torch tensor\n",
    "X_train = torch.from_numpy(X_train)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "\n",
    "# initializing lists to store losses over epochs:\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_iter = []\n",
    "test_iter = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Iteration: 100. Train_MSE: 0.05778791010379791. Test_MSE: 0.14487548172473907\n",
      "Epoch: 0 Iteration: 200. Train_MSE: 0.036992281675338745. Test_MSE: 0.16550526022911072\n",
      "Epoch: 0 Iteration: 300. Train_MSE: 0.03886037692427635. Test_MSE: 0.19611285626888275\n",
      "Epoch: 0 Iteration: 400. Train_MSE: 0.030084479600191116. Test_MSE: 0.08194906264543533\n",
      "Epoch: 0 Iteration: 500. Train_MSE: 0.017009183764457703. Test_MSE: 0.08715450763702393\n",
      "Epoch: 0 Iteration: 600. Train_MSE: 0.016365056857466698. Test_MSE: 0.04855775088071823\n",
      "Epoch: 0 Iteration: 700. Train_MSE: 0.017803030088543892. Test_MSE: 0.04498094320297241\n",
      "Epoch: 1 Iteration: 800. Train_MSE: 0.10470663011074066. Test_MSE: 0.11872787028551102\n",
      "Epoch: 1 Iteration: 900. Train_MSE: 0.07634609192609787. Test_MSE: 0.16360022127628326\n",
      "Epoch: 1 Iteration: 1000. Train_MSE: 0.012640422210097313. Test_MSE: 0.207649827003479\n",
      "Epoch: 1 Iteration: 1100. Train_MSE: 0.029316317290067673. Test_MSE: 0.062269825488328934\n",
      "Epoch: 1 Iteration: 1200. Train_MSE: 0.006818024907261133. Test_MSE: 0.062032300978899\n",
      "Epoch: 1 Iteration: 1300. Train_MSE: 0.010126478970050812. Test_MSE: 0.04480631649494171\n",
      "Epoch: 1 Iteration: 1400. Train_MSE: 0.01743159256875515. Test_MSE: 0.04017746075987816\n",
      "Epoch: 2 Iteration: 1500. Train_MSE: 0.09434513002634048. Test_MSE: 0.1218595802783966\n",
      "Epoch: 2 Iteration: 1600. Train_MSE: 0.05879444628953934. Test_MSE: 0.19246096909046173\n",
      "Epoch: 2 Iteration: 1700. Train_MSE: 0.02830786071717739. Test_MSE: 0.19991818070411682\n",
      "Epoch: 2 Iteration: 1800. Train_MSE: 0.015835586935281754. Test_MSE: 0.05929591506719589\n",
      "Epoch: 2 Iteration: 1900. Train_MSE: 0.008968088775873184. Test_MSE: 0.05191289633512497\n",
      "Epoch: 2 Iteration: 2000. Train_MSE: 0.010974900797009468. Test_MSE: 0.04318997636437416\n",
      "Epoch: 2 Iteration: 2100. Train_MSE: 0.01081386674195528. Test_MSE: 0.03977241367101669\n",
      "Epoch: 3 Iteration: 2200. Train_MSE: 0.12660740315914154. Test_MSE: 0.13200443983078003\n",
      "Epoch: 3 Iteration: 2300. Train_MSE: 0.04369056224822998. Test_MSE: 0.17776256799697876\n",
      "Epoch: 3 Iteration: 2400. Train_MSE: 0.023465709760785103. Test_MSE: 0.17957882583141327\n",
      "Epoch: 3 Iteration: 2500. Train_MSE: 0.024239948019385338. Test_MSE: 0.059708356857299805\n",
      "Epoch: 3 Iteration: 2600. Train_MSE: 0.005934653338044882. Test_MSE: 0.05228890851140022\n",
      "Epoch: 3 Iteration: 2700. Train_MSE: 0.010883011855185032. Test_MSE: 0.04313123971223831\n",
      "Epoch: 3 Iteration: 2800. Train_MSE: 0.010516849346458912. Test_MSE: 0.040023073554039\n",
      "Epoch: 4 Iteration: 2900. Train_MSE: 0.07579388469457626. Test_MSE: 0.14423689246177673\n",
      "Epoch: 4 Iteration: 3000. Train_MSE: 0.09370911866426468. Test_MSE: 0.14698396623134613\n",
      "Epoch: 4 Iteration: 3100. Train_MSE: 0.05130086839199066. Test_MSE: 0.14096784591674805\n",
      "Epoch: 4 Iteration: 3200. Train_MSE: 0.017087645828723907. Test_MSE: 0.0693577229976654\n",
      "Epoch: 4 Iteration: 3300. Train_MSE: 0.00521578174084425. Test_MSE: 0.05509252846240997\n",
      "Epoch: 4 Iteration: 3400. Train_MSE: 0.010880466550588608. Test_MSE: 0.04529644921422005\n",
      "Epoch: 4 Iteration: 3500. Train_MSE: 0.008711045607924461. Test_MSE: 0.04085828363895416\n",
      "Epoch: 5 Iteration: 3600. Train_MSE: 0.05906924232840538. Test_MSE: 0.12079284340143204\n",
      "Epoch: 5 Iteration: 3700. Train_MSE: 0.10437307506799698. Test_MSE: 0.1153995469212532\n",
      "Epoch: 5 Iteration: 3800. Train_MSE: 0.02086915448307991. Test_MSE: 0.1163749024271965\n",
      "Epoch: 5 Iteration: 3900. Train_MSE: 0.012063381262123585. Test_MSE: 0.0719817578792572\n",
      "Epoch: 5 Iteration: 4000. Train_MSE: 0.007413424085825682. Test_MSE: 0.05630486458539963\n",
      "Epoch: 5 Iteration: 4100. Train_MSE: 0.009120696224272251. Test_MSE: 0.04662059620022774\n",
      "Epoch: 5 Iteration: 4200. Train_MSE: 0.008098054677248001. Test_MSE: 0.043398384004831314\n",
      "Epoch: 6 Iteration: 4300. Train_MSE: 0.08021991699934006. Test_MSE: 0.12210488319396973\n",
      "Epoch: 6 Iteration: 4400. Train_MSE: 0.07108356803655624. Test_MSE: 0.09080854803323746\n",
      "Epoch: 6 Iteration: 4500. Train_MSE: 0.02810494974255562. Test_MSE: 0.10328764468431473\n",
      "Epoch: 6 Iteration: 4600. Train_MSE: 0.015397395938634872. Test_MSE: 0.07219261676073074\n",
      "Epoch: 6 Iteration: 4700. Train_MSE: 0.004272017627954483. Test_MSE: 0.05417542904615402\n",
      "Epoch: 6 Iteration: 4800. Train_MSE: 0.008093224838376045. Test_MSE: 0.046463772654533386\n",
      "Epoch: 6 Iteration: 4900. Train_MSE: 0.002512978622689843. Test_MSE: 0.044094305485486984\n",
      "Epoch: 7 Iteration: 5000. Train_MSE: 0.10432440042495728. Test_MSE: 0.11362342536449432\n",
      "Epoch: 7 Iteration: 5100. Train_MSE: 0.07244367897510529. Test_MSE: 0.0760766938328743\n",
      "Epoch: 7 Iteration: 5200. Train_MSE: 0.07772623002529144. Test_MSE: 0.09283187240362167\n",
      "Epoch: 7 Iteration: 5300. Train_MSE: 0.008916054852306843. Test_MSE: 0.07379448413848877\n",
      "Epoch: 7 Iteration: 5400. Train_MSE: 0.008681255392730236. Test_MSE: 0.05354447662830353\n",
      "Epoch: 7 Iteration: 5500. Train_MSE: 0.010518626309931278. Test_MSE: 0.046555131673812866\n",
      "Epoch: 7 Iteration: 5600. Train_MSE: 0.0028647363651543856. Test_MSE: 0.045255955308675766\n",
      "Epoch: 8 Iteration: 5700. Train_MSE: 0.061692845076322556. Test_MSE: 0.1034439206123352\n",
      "Epoch: 8 Iteration: 5800. Train_MSE: 0.06852488219738007. Test_MSE: 0.0686446875333786\n",
      "Epoch: 8 Iteration: 5900. Train_MSE: 0.0525437630712986. Test_MSE: 0.08378417789936066\n",
      "Epoch: 8 Iteration: 6000. Train_MSE: 0.006677716970443726. Test_MSE: 0.06711000204086304\n",
      "Epoch: 8 Iteration: 6100. Train_MSE: 0.009347711689770222. Test_MSE: 0.05434190854430199\n",
      "Epoch: 8 Iteration: 6200. Train_MSE: 0.008891068398952484. Test_MSE: 0.04726887121796608\n",
      "Epoch: 8 Iteration: 6300. Train_MSE: 0.0019027129746973515. Test_MSE: 0.04628046974539757\n",
      "Epoch: 9 Iteration: 6400. Train_MSE: 0.0796879231929779. Test_MSE: 0.09856119751930237\n",
      "Epoch: 9 Iteration: 6500. Train_MSE: 0.052250541746616364. Test_MSE: 0.0662856251001358\n",
      "Epoch: 9 Iteration: 6600. Train_MSE: 0.06223373860120773. Test_MSE: 0.07448296993970871\n",
      "Epoch: 9 Iteration: 6700. Train_MSE: 0.002726738341152668. Test_MSE: 0.06533607095479965\n",
      "Epoch: 9 Iteration: 6800. Train_MSE: 0.008376426994800568. Test_MSE: 0.05300679802894592\n",
      "Epoch: 9 Iteration: 6900. Train_MSE: 0.011063453741371632. Test_MSE: 0.04752505198121071\n",
      "Epoch: 9 Iteration: 7000. Train_MSE: 0.003012692555785179. Test_MSE: 0.046919070184230804\n",
      "Epoch: 10 Iteration: 7100. Train_MSE: 0.07719296216964722. Test_MSE: 0.09093734622001648\n",
      "Epoch: 10 Iteration: 7200. Train_MSE: 0.08444762229919434. Test_MSE: 0.0635901466012001\n",
      "Epoch: 10 Iteration: 7300. Train_MSE: 0.06736697256565094. Test_MSE: 0.06453772634267807\n",
      "Epoch: 10 Iteration: 7400. Train_MSE: 0.0021049624774605036. Test_MSE: 0.06083153560757637\n",
      "Epoch: 10 Iteration: 7500. Train_MSE: 0.008018597029149532. Test_MSE: 0.050886623561382294\n",
      "Epoch: 10 Iteration: 7600. Train_MSE: 0.014780830591917038. Test_MSE: 0.048461973667144775\n",
      "Epoch: 10 Iteration: 7700. Train_MSE: 0.0022865759674459696. Test_MSE: 0.04724286124110222\n",
      "Epoch: 11 Iteration: 7800. Train_MSE: 0.06419757008552551. Test_MSE: 0.0795837864279747\n",
      "Epoch: 11 Iteration: 7900. Train_MSE: 0.0504893884062767. Test_MSE: 0.06248767673969269\n",
      "Epoch: 11 Iteration: 8000. Train_MSE: 0.06909157335758209. Test_MSE: 0.05324807018041611\n",
      "Epoch: 11 Iteration: 8100. Train_MSE: 0.0021473888773471117. Test_MSE: 0.05838413164019585\n",
      "Epoch: 11 Iteration: 8200. Train_MSE: 0.012497736141085625. Test_MSE: 0.047435179352760315\n",
      "Epoch: 11 Iteration: 8300. Train_MSE: 0.011080080643296242. Test_MSE: 0.04845025762915611\n",
      "Epoch: 11 Iteration: 8400. Train_MSE: 0.003423387184739113. Test_MSE: 0.04687003046274185\n",
      "Epoch: 12 Iteration: 8500. Train_MSE: 0.027748335152864456. Test_MSE: 0.07321816682815552\n",
      "Epoch: 12 Iteration: 8600. Train_MSE: 0.060257166624069214. Test_MSE: 0.06475533545017242\n",
      "Epoch: 12 Iteration: 8700. Train_MSE: 0.06519397348165512. Test_MSE: 0.04743899405002594\n",
      "Epoch: 12 Iteration: 8800. Train_MSE: 0.003058177884668112. Test_MSE: 0.056274011731147766\n",
      "Epoch: 12 Iteration: 8900. Train_MSE: 0.013763356022536755. Test_MSE: 0.04618080332875252\n",
      "Epoch: 12 Iteration: 9000. Train_MSE: 0.010805449448525906. Test_MSE: 0.04906527325510979\n",
      "Epoch: 12 Iteration: 9100. Train_MSE: 0.003095377003774047. Test_MSE: 0.04575109854340553\n",
      "Epoch: 13 Iteration: 9200. Train_MSE: 0.0517137385904789. Test_MSE: 0.06768505275249481\n",
      "Epoch: 13 Iteration: 9300. Train_MSE: 0.0770065039396286. Test_MSE: 0.06781422346830368\n",
      "Epoch: 13 Iteration: 9400. Train_MSE: 0.05221816524863243. Test_MSE: 0.04436970874667168\n",
      "Epoch: 13 Iteration: 9500. Train_MSE: 0.0009182044304907322. Test_MSE: 0.05503828078508377\n",
      "Epoch: 13 Iteration: 9600. Train_MSE: 0.013287260197103024. Test_MSE: 0.0472288578748703\n",
      "Epoch: 13 Iteration: 9700. Train_MSE: 0.011987538076937199. Test_MSE: 0.047565802931785583\n",
      "Epoch: 13 Iteration: 9800. Train_MSE: 0.003103992436081171. Test_MSE: 0.04476245865225792\n",
      "Epoch: 14 Iteration: 9900. Train_MSE: 0.051492754369974136. Test_MSE: 0.06746699661016464\n",
      "Epoch: 14 Iteration: 10000. Train_MSE: 0.07669203728437424. Test_MSE: 0.0719318762421608\n",
      "Epoch: 14 Iteration: 10100. Train_MSE: 0.05013241246342659. Test_MSE: 0.044882047921419144\n",
      "Epoch: 14 Iteration: 10200. Train_MSE: 0.0017420616932213306. Test_MSE: 0.05339574068784714\n",
      "Epoch: 14 Iteration: 10300. Train_MSE: 0.0138709032908082. Test_MSE: 0.0496358759701252\n",
      "Epoch: 14 Iteration: 10400. Train_MSE: 0.008867195807397366. Test_MSE: 0.047342121601104736\n",
      "Epoch: 14 Iteration: 10500. Train_MSE: 0.004223233088850975. Test_MSE: 0.04397546127438545\n",
      "Epoch: 15 Iteration: 10600. Train_MSE: 0.0602281279861927. Test_MSE: 0.06524233520030975\n",
      "Epoch: 15 Iteration: 10700. Train_MSE: 0.04565351828932762. Test_MSE: 0.07216539233922958\n",
      "Epoch: 15 Iteration: 10800. Train_MSE: 0.07417081296443939. Test_MSE: 0.046794597059488297\n",
      "Epoch: 15 Iteration: 10900. Train_MSE: 0.000605600536800921. Test_MSE: 0.052011583000421524\n",
      "Epoch: 15 Iteration: 11000. Train_MSE: 0.017782382667064667. Test_MSE: 0.051071662455797195\n",
      "Epoch: 15 Iteration: 11100. Train_MSE: 0.008670773357152939. Test_MSE: 0.048260267823934555\n",
      "Epoch: 15 Iteration: 11200. Train_MSE: 0.0035386511590331793. Test_MSE: 0.043521612882614136\n",
      "Epoch: 16 Iteration: 11300. Train_MSE: 0.028166748583316803. Test_MSE: 0.0639648586511612\n",
      "Epoch: 16 Iteration: 11400. Train_MSE: 0.0768766850233078. Test_MSE: 0.07231418788433075\n",
      "Epoch: 16 Iteration: 11500. Train_MSE: 0.05072014033794403. Test_MSE: 0.04950573295354843\n",
      "Epoch: 16 Iteration: 11600. Train_MSE: 0.00178169971331954. Test_MSE: 0.0519731380045414\n",
      "Epoch: 16 Iteration: 11700. Train_MSE: 0.019649816676974297. Test_MSE: 0.0519920289516449\n",
      "Epoch: 16 Iteration: 11800. Train_MSE: 0.02287651225924492. Test_MSE: 0.04909752309322357\n",
      "Epoch: 16 Iteration: 11900. Train_MSE: 0.004376310855150223. Test_MSE: 0.043064750730991364\n",
      "Epoch: 17 Iteration: 12000. Train_MSE: 0.033961232751607895. Test_MSE: 0.06232674419879913\n",
      "Epoch: 17 Iteration: 12100. Train_MSE: 0.05271504446864128. Test_MSE: 0.06952910125255585\n",
      "Epoch: 17 Iteration: 12200. Train_MSE: 0.05820908024907112. Test_MSE: 0.05378343537449837\n",
      "Epoch: 17 Iteration: 12300. Train_MSE: 0.0023884172551333904. Test_MSE: 0.0497121699154377\n",
      "Epoch: 17 Iteration: 12400. Train_MSE: 0.01634478010237217. Test_MSE: 0.0530475452542305\n",
      "Epoch: 17 Iteration: 12500. Train_MSE: 0.007899422198534012. Test_MSE: 0.051301781088113785\n",
      "Epoch: 17 Iteration: 12600. Train_MSE: 0.007061355281621218. Test_MSE: 0.04268967732787132\n",
      "Epoch: 18 Iteration: 12700. Train_MSE: 0.02124551683664322. Test_MSE: 0.0651618093252182\n",
      "Epoch: 18 Iteration: 12800. Train_MSE: 0.049125298857688904. Test_MSE: 0.06837635487318039\n",
      "Epoch: 18 Iteration: 12900. Train_MSE: 0.06672517955303192. Test_MSE: 0.05961785092949867\n",
      "Epoch: 18 Iteration: 13000. Train_MSE: 0.0022020929027348757. Test_MSE: 0.04767278581857681\n",
      "Epoch: 18 Iteration: 13100. Train_MSE: 0.008902537636458874. Test_MSE: 0.05132414400577545\n",
      "Epoch: 18 Iteration: 13200. Train_MSE: 0.005820745136588812. Test_MSE: 0.05250750854611397\n",
      "Epoch: 18 Iteration: 13300. Train_MSE: 0.006840292830020189. Test_MSE: 0.04257363826036453\n",
      "Epoch: 19 Iteration: 13400. Train_MSE: 0.037455350160598755. Test_MSE: 0.06784731149673462\n",
      "Epoch: 19 Iteration: 13500. Train_MSE: 0.054634518921375275. Test_MSE: 0.0681128203868866\n",
      "Epoch: 19 Iteration: 13600. Train_MSE: 0.07676343619823456. Test_MSE: 0.06591284275054932\n",
      "Epoch: 19 Iteration: 13700. Train_MSE: 0.0027171489782631397. Test_MSE: 0.04956097900867462\n",
      "Epoch: 19 Iteration: 13800. Train_MSE: 0.015178700909018517. Test_MSE: 0.04774756357073784\n",
      "Epoch: 19 Iteration: 13900. Train_MSE: 0.006723376922309399. Test_MSE: 0.05331409350037575\n",
      "Epoch: 19 Iteration: 14000. Train_MSE: 0.0078300591558218. Test_MSE: 0.04177958890795708\n",
      "Epoch: 20 Iteration: 14100. Train_MSE: 0.009537775069475174. Test_MSE: 0.06771694868803024\n",
      "Epoch: 20 Iteration: 14200. Train_MSE: 0.062278080731630325. Test_MSE: 0.06833776086568832\n",
      "Epoch: 20 Iteration: 14300. Train_MSE: 0.06844779849052429. Test_MSE: 0.07557343691587448\n",
      "Epoch: 20 Iteration: 14400. Train_MSE: 0.0038352799601852894. Test_MSE: 0.05044667422771454\n",
      "Epoch: 20 Iteration: 14500. Train_MSE: 0.016672305762767792. Test_MSE: 0.044549595564603806\n",
      "Epoch: 20 Iteration: 14600. Train_MSE: 0.006487604230642319. Test_MSE: 0.05343195050954819\n",
      "Epoch: 20 Iteration: 14700. Train_MSE: 0.00753143010661006. Test_MSE: 0.042243409901857376\n",
      "Epoch: 21 Iteration: 14800. Train_MSE: 0.0227658748626709. Test_MSE: 0.06800749152898788\n",
      "Epoch: 21 Iteration: 14900. Train_MSE: 0.02398822270333767. Test_MSE: 0.06852681189775467\n",
      "Epoch: 21 Iteration: 15000. Train_MSE: 0.05793130025267601. Test_MSE: 0.08012264221906662\n",
      "Epoch: 21 Iteration: 15100. Train_MSE: 0.005839872173964977. Test_MSE: 0.05401932820677757\n",
      "Epoch: 21 Iteration: 15200. Train_MSE: 0.02042376808822155. Test_MSE: 0.04211147502064705\n",
      "Epoch: 21 Iteration: 15300. Train_MSE: 0.010400197468698025. Test_MSE: 0.0541619211435318\n",
      "Epoch: 21 Iteration: 15400. Train_MSE: 0.009331382811069489. Test_MSE: 0.04285448044538498\n",
      "Epoch: 22 Iteration: 15500. Train_MSE: 0.0026131088379770517. Test_MSE: 0.06700178235769272\n",
      "Epoch: 22 Iteration: 15600. Train_MSE: 0.08638705313205719. Test_MSE: 0.06576462835073471\n",
      "Epoch: 22 Iteration: 15700. Train_MSE: 0.0634363517165184. Test_MSE: 0.07906799018383026\n",
      "Epoch: 22 Iteration: 15800. Train_MSE: 0.005148572847247124. Test_MSE: 0.05632483959197998\n",
      "Epoch: 22 Iteration: 15900. Train_MSE: 0.01733296550810337. Test_MSE: 0.040501516312360764\n",
      "Epoch: 22 Iteration: 16000. Train_MSE: 0.004629417322576046. Test_MSE: 0.055406346917152405\n",
      "Epoch: 22 Iteration: 16100. Train_MSE: 0.007661717943847179. Test_MSE: 0.04377414286136627\n",
      "Epoch: 23 Iteration: 16200. Train_MSE: 0.009161900728940964. Test_MSE: 0.06694461405277252\n",
      "Epoch: 23 Iteration: 16300. Train_MSE: 0.014503535814583302. Test_MSE: 0.06429295986890793\n",
      "Epoch: 23 Iteration: 16400. Train_MSE: 0.03474890813231468. Test_MSE: 0.07582823187112808\n",
      "Epoch: 23 Iteration: 16500. Train_MSE: 0.003660109592601657. Test_MSE: 0.05764190852642059\n",
      "Epoch: 23 Iteration: 16600. Train_MSE: 0.0033017112873494625. Test_MSE: 0.04079277440905571\n",
      "Epoch: 23 Iteration: 16700. Train_MSE: 0.006650216411799192. Test_MSE: 0.05569718778133392\n",
      "Epoch: 23 Iteration: 16800. Train_MSE: 0.006765016820281744. Test_MSE: 0.045099250972270966\n",
      "Epoch: 24 Iteration: 16900. Train_MSE: 0.0028128165286034346. Test_MSE: 0.0669376403093338\n",
      "Epoch: 24 Iteration: 17000. Train_MSE: 0.04409344494342804. Test_MSE: 0.06255944818258286\n",
      "Epoch: 24 Iteration: 17100. Train_MSE: 0.0839003399014473. Test_MSE: 0.07239330559968948\n",
      "Epoch: 24 Iteration: 17200. Train_MSE: 0.006625194568186998. Test_MSE: 0.05857248604297638\n",
      "Epoch: 24 Iteration: 17300. Train_MSE: 0.0022113784216344357. Test_MSE: 0.04069036245346069\n",
      "Epoch: 24 Iteration: 17400. Train_MSE: 0.0020940997637808323. Test_MSE: 0.05589815229177475\n",
      "Epoch: 24 Iteration: 17500. Train_MSE: 0.0075590359047055244. Test_MSE: 0.04673420265316963\n",
      "Epoch: 25 Iteration: 17600. Train_MSE: 0.006960052996873856. Test_MSE: 0.06687138974666595\n",
      "Epoch: 25 Iteration: 17700. Train_MSE: 0.021126024425029755. Test_MSE: 0.059920623898506165\n",
      "Epoch: 25 Iteration: 17800. Train_MSE: 0.03738917410373688. Test_MSE: 0.06767213344573975\n",
      "Epoch: 25 Iteration: 17900. Train_MSE: 0.007730522658675909. Test_MSE: 0.0578291192650795\n",
      "Epoch: 25 Iteration: 18000. Train_MSE: 0.0009360919939354062. Test_MSE: 0.04014923423528671\n",
      "Epoch: 25 Iteration: 18100. Train_MSE: 0.001696402090601623. Test_MSE: 0.056281059980392456\n",
      "Epoch: 25 Iteration: 18200. Train_MSE: 0.01054614782333374. Test_MSE: 0.04735583811998367\n",
      "Epoch: 26 Iteration: 18300. Train_MSE: 0.008232352323830128. Test_MSE: 0.06840624660253525\n",
      "Epoch: 26 Iteration: 18400. Train_MSE: 0.011277475394308567. Test_MSE: 0.05920626223087311\n",
      "Epoch: 26 Iteration: 18500. Train_MSE: 0.0589107945561409. Test_MSE: 0.06570640206336975\n",
      "Epoch: 26 Iteration: 18600. Train_MSE: 0.012933587655425072. Test_MSE: 0.05976934731006622\n",
      "Epoch: 26 Iteration: 18700. Train_MSE: 0.0007164763519540429. Test_MSE: 0.041258469223976135\n",
      "Epoch: 26 Iteration: 18800. Train_MSE: 0.0009321392863057554. Test_MSE: 0.056032441556453705\n",
      "Epoch: 26 Iteration: 18900. Train_MSE: 0.009966665878891945. Test_MSE: 0.049564555287361145\n",
      "Epoch: 27 Iteration: 19000. Train_MSE: 0.007783412933349609. Test_MSE: 0.06520687788724899\n",
      "Epoch: 27 Iteration: 19100. Train_MSE: 0.008165138773620129. Test_MSE: 0.058760374784469604\n",
      "Epoch: 27 Iteration: 19200. Train_MSE: 0.03976938873529434. Test_MSE: 0.06135622411966324\n",
      "Epoch: 27 Iteration: 19300. Train_MSE: 0.009549657814204693. Test_MSE: 0.05786066874861717\n",
      "Epoch: 27 Iteration: 19400. Train_MSE: 9.670272265793756e-05. Test_MSE: 0.04039807990193367\n",
      "Epoch: 27 Iteration: 19500. Train_MSE: 0.0004889662959612906. Test_MSE: 0.05686694383621216\n",
      "Epoch: 27 Iteration: 19600. Train_MSE: 0.00455139996483922. Test_MSE: 0.048570916056632996\n",
      "Epoch: 28 Iteration: 19700. Train_MSE: 0.004222980234771967. Test_MSE: 0.060396697372198105\n",
      "Epoch: 28 Iteration: 19800. Train_MSE: 0.004724371246993542. Test_MSE: 0.05435802787542343\n",
      "Epoch: 28 Iteration: 19900. Train_MSE: 0.06360360980033875. Test_MSE: 0.05474254861474037\n",
      "Epoch: 28 Iteration: 20000. Train_MSE: 0.009218353778123856. Test_MSE: 0.054779138416051865\n",
      "Epoch: 28 Iteration: 20100. Train_MSE: 0.00036462998832575977. Test_MSE: 0.038441628217697144\n",
      "Epoch: 28 Iteration: 20200. Train_MSE: 0.0005554813542403281. Test_MSE: 0.05431041866540909\n",
      "Epoch: 28 Iteration: 20300. Train_MSE: 0.012354803271591663. Test_MSE: 0.04722749814391136\n",
      "Epoch: 29 Iteration: 20400. Train_MSE: 0.015687821432948112. Test_MSE: 0.05848698690533638\n",
      "Epoch: 29 Iteration: 20500. Train_MSE: 0.005153269972652197. Test_MSE: 0.052159760147333145\n",
      "Epoch: 29 Iteration: 20600. Train_MSE: 0.03293784335255623. Test_MSE: 0.050828687846660614\n",
      "Epoch: 29 Iteration: 20700. Train_MSE: 0.007814719341695309. Test_MSE: 0.05304117500782013\n",
      "Epoch: 29 Iteration: 20800. Train_MSE: 0.0002792953164316714. Test_MSE: 0.03695419430732727\n",
      "Epoch: 29 Iteration: 20900. Train_MSE: 0.00040115491719916463. Test_MSE: 0.052049849182367325\n",
      "Epoch: 29 Iteration: 21000. Train_MSE: 0.011999901384115219. Test_MSE: 0.04739301651716232\n",
      "Epoch: 30 Iteration: 21100. Train_MSE: 0.0220823734998703. Test_MSE: 0.058054834604263306\n",
      "Epoch: 30 Iteration: 21200. Train_MSE: 0.008948820643126965. Test_MSE: 0.052222058176994324\n",
      "Epoch: 30 Iteration: 21300. Train_MSE: 0.0325552336871624. Test_MSE: 0.04927506297826767\n",
      "Epoch: 30 Iteration: 21400. Train_MSE: 0.011505045928061008. Test_MSE: 0.05313333123922348\n",
      "Epoch: 30 Iteration: 21500. Train_MSE: 0.0005103560397401452. Test_MSE: 0.036214280873537064\n",
      "Epoch: 30 Iteration: 21600. Train_MSE: 0.0005008127773180604. Test_MSE: 0.05271601676940918\n",
      "Epoch: 30 Iteration: 21700. Train_MSE: 0.008714274503290653. Test_MSE: 0.04805460199713707\n",
      "Epoch: 31 Iteration: 21800. Train_MSE: 0.020332159474492073. Test_MSE: 0.05631063133478165\n",
      "Epoch: 31 Iteration: 21900. Train_MSE: 0.00514560379087925. Test_MSE: 0.05175255239009857\n",
      "Epoch: 31 Iteration: 22000. Train_MSE: 0.008334944024682045. Test_MSE: 0.04824931174516678\n",
      "Epoch: 31 Iteration: 22100. Train_MSE: 0.010151390917599201. Test_MSE: 0.055109716951847076\n",
      "Epoch: 31 Iteration: 22200. Train_MSE: 0.0007534489850513637. Test_MSE: 0.035393089056015015\n",
      "Epoch: 31 Iteration: 22300. Train_MSE: 0.0019240742549300194. Test_MSE: 0.0520005077123642\n",
      "Epoch: 31 Iteration: 22400. Train_MSE: 0.010263348929584026. Test_MSE: 0.0495661124587059\n",
      "Epoch: 32 Iteration: 22500. Train_MSE: 0.007646277081221342. Test_MSE: 0.05529772862792015\n",
      "Epoch: 32 Iteration: 22600. Train_MSE: 0.0069685811176896095. Test_MSE: 0.05367644131183624\n",
      "Epoch: 32 Iteration: 22700. Train_MSE: 0.008203807286918163. Test_MSE: 0.04948575422167778\n",
      "Epoch: 32 Iteration: 22800. Train_MSE: 0.012824833393096924. Test_MSE: 0.05914586782455444\n",
      "Epoch: 32 Iteration: 22900. Train_MSE: 0.0010506735416129231. Test_MSE: 0.03599736467003822\n",
      "Epoch: 32 Iteration: 23000. Train_MSE: 0.002278855536133051. Test_MSE: 0.05181979387998581\n",
      "Epoch: 32 Iteration: 23100. Train_MSE: 0.005847826600074768. Test_MSE: 0.0511840395629406\n",
      "Epoch: 33 Iteration: 23200. Train_MSE: 0.01913328282535076. Test_MSE: 0.05451417341828346\n",
      "Epoch: 33 Iteration: 23300. Train_MSE: 0.010561875067651272. Test_MSE: 0.05483192205429077\n",
      "Epoch: 33 Iteration: 23400. Train_MSE: 0.004727204795926809. Test_MSE: 0.05029186233878136\n",
      "Epoch: 33 Iteration: 23500. Train_MSE: 0.01759117841720581. Test_MSE: 0.06137841194868088\n",
      "Epoch: 33 Iteration: 23600. Train_MSE: 0.0010133216856047511. Test_MSE: 0.03700718283653259\n",
      "Epoch: 33 Iteration: 23700. Train_MSE: 0.001164809800684452. Test_MSE: 0.051339536905288696\n",
      "Epoch: 33 Iteration: 23800. Train_MSE: 0.019288938492536545. Test_MSE: 0.05239924415946007\n",
      "Epoch: 34 Iteration: 23900. Train_MSE: 0.034424662590026855. Test_MSE: 0.052191950380802155\n",
      "Epoch: 34 Iteration: 24000. Train_MSE: 0.005795763339847326. Test_MSE: 0.05493432655930519\n",
      "Epoch: 34 Iteration: 24100. Train_MSE: 0.0062461658380925655. Test_MSE: 0.0504717156291008\n",
      "Epoch: 34 Iteration: 24200. Train_MSE: 0.01342094037681818. Test_MSE: 0.061705607920885086\n",
      "Epoch: 34 Iteration: 24300. Train_MSE: 0.001279946300201118. Test_MSE: 0.037466250360012054\n",
      "Epoch: 34 Iteration: 24400. Train_MSE: 0.0019656482618302107. Test_MSE: 0.04865369573235512\n",
      "Epoch: 34 Iteration: 24500. Train_MSE: 0.00593211967498064. Test_MSE: 0.05230239778757095\n",
      "Epoch: 35 Iteration: 24600. Train_MSE: 0.04052900895476341. Test_MSE: 0.04983207583427429\n",
      "Epoch: 35 Iteration: 24700. Train_MSE: 0.005838670767843723. Test_MSE: 0.0552973710000515\n",
      "Epoch: 35 Iteration: 24800. Train_MSE: 0.0017836663173511624. Test_MSE: 0.05105885490775108\n",
      "Epoch: 35 Iteration: 24900. Train_MSE: 0.012645643204450607. Test_MSE: 0.06295321136713028\n",
      "Epoch: 35 Iteration: 25000. Train_MSE: 0.0021632856223732233. Test_MSE: 0.039338499307632446\n",
      "Epoch: 35 Iteration: 25100. Train_MSE: 0.0020966543816030025. Test_MSE: 0.04751306027173996\n",
      "Epoch: 35 Iteration: 25200. Train_MSE: 0.0049309637397527695. Test_MSE: 0.052354518324136734\n",
      "Epoch: 36 Iteration: 25300. Train_MSE: 0.061586298048496246. Test_MSE: 0.047669973224401474\n",
      "Epoch: 36 Iteration: 25400. Train_MSE: 0.0084463432431221. Test_MSE: 0.05551454424858093\n",
      "Epoch: 36 Iteration: 25500. Train_MSE: 0.002229175064712763. Test_MSE: 0.05174768716096878\n",
      "Epoch: 36 Iteration: 25600. Train_MSE: 0.0195306483656168. Test_MSE: 0.0626726895570755\n",
      "Epoch: 36 Iteration: 25700. Train_MSE: 0.0025682898703962564. Test_MSE: 0.041012126952409744\n",
      "Epoch: 36 Iteration: 25800. Train_MSE: 0.005357356276363134. Test_MSE: 0.045875079929828644\n",
      "Epoch: 36 Iteration: 25900. Train_MSE: 0.004511089529842138. Test_MSE: 0.05215621367096901\n",
      "Epoch: 37 Iteration: 26000. Train_MSE: 0.03665260598063469. Test_MSE: 0.04470449313521385\n",
      "Epoch: 37 Iteration: 26100. Train_MSE: 0.008983326144516468. Test_MSE: 0.05526895076036453\n",
      "Epoch: 37 Iteration: 26200. Train_MSE: 0.002021325286477804. Test_MSE: 0.05203702300786972\n",
      "Epoch: 37 Iteration: 26300. Train_MSE: 0.008755311369895935. Test_MSE: 0.061764344573020935\n",
      "Epoch: 37 Iteration: 26400. Train_MSE: 0.0030636354349553585. Test_MSE: 0.04329574108123779\n",
      "Epoch: 37 Iteration: 26500. Train_MSE: 0.0062925126403570175. Test_MSE: 0.044798027724027634\n",
      "Epoch: 37 Iteration: 26600. Train_MSE: 0.0024481674190610647. Test_MSE: 0.05215401574969292\n",
      "Epoch: 38 Iteration: 26700. Train_MSE: 0.06365194916725159. Test_MSE: 0.04262980818748474\n",
      "Epoch: 38 Iteration: 26800. Train_MSE: 0.020741306245326996. Test_MSE: 0.05451669171452522\n",
      "Epoch: 38 Iteration: 26900. Train_MSE: 0.0019266740418970585. Test_MSE: 0.051762279123067856\n",
      "Epoch: 38 Iteration: 27000. Train_MSE: 0.013640054501593113. Test_MSE: 0.06138427555561066\n",
      "Epoch: 38 Iteration: 27100. Train_MSE: 0.004486737307161093. Test_MSE: 0.04417891800403595\n",
      "Epoch: 38 Iteration: 27200. Train_MSE: 0.0043260203674435616. Test_MSE: 0.04244048148393631\n",
      "Epoch: 38 Iteration: 27300. Train_MSE: 0.001185698783956468. Test_MSE: 0.051996637135744095\n",
      "Epoch: 39 Iteration: 27400. Train_MSE: 0.0620441660284996. Test_MSE: 0.041173070669174194\n",
      "Epoch: 39 Iteration: 27500. Train_MSE: 0.024547962471842766. Test_MSE: 0.05371730774641037\n",
      "Epoch: 39 Iteration: 27600. Train_MSE: 0.0023613569792360067. Test_MSE: 0.05200459063053131\n",
      "Epoch: 39 Iteration: 27700. Train_MSE: 0.011585159227252007. Test_MSE: 0.05979560688138008\n",
      "Epoch: 39 Iteration: 27800. Train_MSE: 0.004503793548792601. Test_MSE: 0.046400878578424454\n",
      "Epoch: 39 Iteration: 27900. Train_MSE: 0.010510756634175777. Test_MSE: 0.04087425395846367\n",
      "Epoch: 39 Iteration: 28000. Train_MSE: 0.00023665931075811386. Test_MSE: 0.05210939794778824\n",
      "Epoch: 40 Iteration: 28100. Train_MSE: 0.08874110877513885. Test_MSE: 0.04007364436984062\n",
      "Epoch: 40 Iteration: 28200. Train_MSE: 0.02714027464389801. Test_MSE: 0.05297894775867462\n",
      "Epoch: 40 Iteration: 28300. Train_MSE: 0.011130466125905514. Test_MSE: 0.05190164968371391\n",
      "Epoch: 40 Iteration: 28400. Train_MSE: 0.00826581846922636. Test_MSE: 0.05949949845671654\n",
      "Epoch: 40 Iteration: 28500. Train_MSE: 0.004619016777724028. Test_MSE: 0.04795829579234123\n",
      "Epoch: 40 Iteration: 28600. Train_MSE: 0.01096726581454277. Test_MSE: 0.0395582839846611\n",
      "Epoch: 40 Iteration: 28700. Train_MSE: 0.00036548334173858166. Test_MSE: 0.052098266780376434\n",
      "Epoch: 41 Iteration: 28800. Train_MSE: 0.061352167278528214. Test_MSE: 0.038874302059412\n",
      "Epoch: 41 Iteration: 28900. Train_MSE: 0.0422348789870739. Test_MSE: 0.05223100632429123\n",
      "Epoch: 41 Iteration: 29000. Train_MSE: 0.009162024594843388. Test_MSE: 0.05105875805020332\n",
      "Epoch: 41 Iteration: 29100. Train_MSE: 0.007844626903533936. Test_MSE: 0.05981720611453056\n",
      "Epoch: 41 Iteration: 29200. Train_MSE: 0.009713778272271156. Test_MSE: 0.05060000717639923\n",
      "Epoch: 41 Iteration: 29300. Train_MSE: 0.018397241830825806. Test_MSE: 0.0379113107919693\n",
      "Epoch: 41 Iteration: 29400. Train_MSE: 0.0005071176565252244. Test_MSE: 0.05198516324162483\n",
      "Epoch: 42 Iteration: 29500. Train_MSE: 0.04719814285635948. Test_MSE: 0.038184668868780136\n",
      "Epoch: 42 Iteration: 29600. Train_MSE: 0.04889845848083496. Test_MSE: 0.05045261234045029\n",
      "Epoch: 42 Iteration: 29700. Train_MSE: 0.00349838612601161. Test_MSE: 0.05039076879620552\n",
      "Epoch: 42 Iteration: 29800. Train_MSE: 0.007860017009079456. Test_MSE: 0.05990958213806152\n",
      "Epoch: 42 Iteration: 29900. Train_MSE: 0.012775707058608532. Test_MSE: 0.05240645632147789\n",
      "Epoch: 42 Iteration: 30000. Train_MSE: 0.012562623247504234. Test_MSE: 0.03732835128903389\n",
      "Epoch: 42 Iteration: 30100. Train_MSE: 0.0006348761962726712. Test_MSE: 0.05111612007021904\n",
      "Epoch: 43 Iteration: 30200. Train_MSE: 0.046071410179138184. Test_MSE: 0.03809205815196037\n",
      "Epoch: 43 Iteration: 30300. Train_MSE: 0.02622958831489086. Test_MSE: 0.04769507795572281\n",
      "Epoch: 43 Iteration: 30400. Train_MSE: 0.017998559400439262. Test_MSE: 0.048927418887615204\n",
      "Epoch: 43 Iteration: 30500. Train_MSE: 0.00638968963176012. Test_MSE: 0.057650238275527954\n",
      "Epoch: 43 Iteration: 30600. Train_MSE: 0.01682102121412754. Test_MSE: 0.054423388093709946\n",
      "Epoch: 43 Iteration: 30700. Train_MSE: 0.01123131439089775. Test_MSE: 0.03657810762524605\n",
      "Epoch: 43 Iteration: 30800. Train_MSE: 0.0006275668274611235. Test_MSE: 0.05101640522480011\n",
      "Epoch: 44 Iteration: 30900. Train_MSE: 0.05108426511287689. Test_MSE: 0.039846811443567276\n",
      "Epoch: 44 Iteration: 31000. Train_MSE: 0.03320852294564247. Test_MSE: 0.04645783081650734\n",
      "Epoch: 44 Iteration: 31100. Train_MSE: 0.026320582255721092. Test_MSE: 0.04877322539687157\n",
      "Epoch: 44 Iteration: 31200. Train_MSE: 0.007487112656235695. Test_MSE: 0.057053107768297195\n",
      "Epoch: 44 Iteration: 31300. Train_MSE: 0.012604533694684505. Test_MSE: 0.055812302976846695\n",
      "Epoch: 44 Iteration: 31400. Train_MSE: 0.007777608465403318. Test_MSE: 0.03674780949950218\n",
      "Epoch: 44 Iteration: 31500. Train_MSE: 0.0010918400948867202. Test_MSE: 0.051124267280101776\n",
      "Epoch: 45 Iteration: 31600. Train_MSE: 0.07648781687021255. Test_MSE: 0.04204144701361656\n",
      "Epoch: 45 Iteration: 31700. Train_MSE: 0.055060628801584244. Test_MSE: 0.044787731021642685\n",
      "Epoch: 45 Iteration: 31800. Train_MSE: 0.021572554484009743. Test_MSE: 0.0484861396253109\n",
      "Epoch: 45 Iteration: 31900. Train_MSE: 0.004512394312769175. Test_MSE: 0.05579562857747078\n",
      "Epoch: 45 Iteration: 32000. Train_MSE: 0.00889951828867197. Test_MSE: 0.05572228506207466\n",
      "Epoch: 45 Iteration: 32100. Train_MSE: 0.003925314638763666. Test_MSE: 0.036522191017866135\n",
      "Epoch: 45 Iteration: 32200. Train_MSE: 0.0009328922023996711. Test_MSE: 0.051275767385959625\n",
      "Epoch: 46 Iteration: 32300. Train_MSE: 0.04885133355855942. Test_MSE: 0.04417479410767555\n",
      "Epoch: 46 Iteration: 32400. Train_MSE: 0.04942743852734566. Test_MSE: 0.04245579615235329\n",
      "Epoch: 46 Iteration: 32500. Train_MSE: 0.021421320736408234. Test_MSE: 0.04753579571843147\n",
      "Epoch: 46 Iteration: 32600. Train_MSE: 0.004314106423407793. Test_MSE: 0.05485174432396889\n",
      "Epoch: 46 Iteration: 32700. Train_MSE: 0.013584217056632042. Test_MSE: 0.05337560921907425\n",
      "Epoch: 46 Iteration: 32800. Train_MSE: 0.0016111902659758925. Test_MSE: 0.0374726839363575\n",
      "Epoch: 46 Iteration: 32900. Train_MSE: 0.0011180888395756483. Test_MSE: 0.05168930068612099\n",
      "Epoch: 47 Iteration: 33000. Train_MSE: 0.12471011281013489. Test_MSE: 0.04508064687252045\n",
      "Epoch: 47 Iteration: 33100. Train_MSE: 0.04575459659099579. Test_MSE: 0.04153206944465637\n",
      "Epoch: 47 Iteration: 33200. Train_MSE: 0.030019251629710197. Test_MSE: 0.046818360686302185\n",
      "Epoch: 47 Iteration: 33300. Train_MSE: 0.0037848991341888905. Test_MSE: 0.0544908307492733\n",
      "Epoch: 47 Iteration: 33400. Train_MSE: 0.011480138637125492. Test_MSE: 0.05144515261054039\n",
      "Epoch: 47 Iteration: 33500. Train_MSE: 0.0009583010687492788. Test_MSE: 0.03790407255291939\n",
      "Epoch: 47 Iteration: 33600. Train_MSE: 0.001390616176649928. Test_MSE: 0.051142141222953796\n",
      "Epoch: 48 Iteration: 33700. Train_MSE: 0.06567467004060745. Test_MSE: 0.046398408710956573\n",
      "Epoch: 48 Iteration: 33800. Train_MSE: 0.04722773656249046. Test_MSE: 0.04075893014669418\n",
      "Epoch: 48 Iteration: 33900. Train_MSE: 0.03731989860534668. Test_MSE: 0.045650843530893326\n",
      "Epoch: 48 Iteration: 34000. Train_MSE: 0.003964453935623169. Test_MSE: 0.05352579429745674\n",
      "Epoch: 48 Iteration: 34100. Train_MSE: 0.013535366393625736. Test_MSE: 0.05140310525894165\n",
      "Epoch: 48 Iteration: 34200. Train_MSE: 0.0009875782998278737. Test_MSE: 0.03955310210585594\n",
      "Epoch: 48 Iteration: 34300. Train_MSE: 0.0016392505494877696. Test_MSE: 0.051284197717905045\n",
      "Epoch: 49 Iteration: 34400. Train_MSE: 0.051155637949705124. Test_MSE: 0.04698016494512558\n",
      "Epoch: 49 Iteration: 34500. Train_MSE: 0.06661179661750793. Test_MSE: 0.03998859226703644\n",
      "Epoch: 49 Iteration: 34600. Train_MSE: 0.04015345498919487. Test_MSE: 0.043361812829971313\n",
      "Epoch: 49 Iteration: 34700. Train_MSE: 0.0008326063398271799. Test_MSE: 0.05153597891330719\n",
      "Epoch: 49 Iteration: 34800. Train_MSE: 0.015040738508105278. Test_MSE: 0.05222243815660477\n",
      "Epoch: 49 Iteration: 34900. Train_MSE: 0.0015115339774638414. Test_MSE: 0.03963803872466087\n",
      "Epoch: 49 Iteration: 35000. Train_MSE: 0.003292256500571966. Test_MSE: 0.051231738179922104\n",
      "Epoch: 49 Iteration: 35100. Train_MSE: 0.005057519301772118. Test_MSE: 0.04712244123220444\n",
      "Epoch: 50 Iteration: 35200. Train_MSE: 0.05886524170637131. Test_MSE: 0.039517201483249664\n",
      "Epoch: 50 Iteration: 35300. Train_MSE: 0.029990078881382942. Test_MSE: 0.04284143075346947\n",
      "Epoch: 50 Iteration: 35400. Train_MSE: 0.0011031157337129116. Test_MSE: 0.05008913576602936\n",
      "Epoch: 50 Iteration: 35500. Train_MSE: 0.011454053223133087. Test_MSE: 0.051927875727415085\n",
      "Epoch: 50 Iteration: 35600. Train_MSE: 0.0005562379374168813. Test_MSE: 0.03839108347892761\n",
      "Epoch: 50 Iteration: 35700. Train_MSE: 0.003776062745600939. Test_MSE: 0.04967828094959259\n",
      "Epoch: 50 Iteration: 35800. Train_MSE: 0.013415301218628883. Test_MSE: 0.04823950678110123\n",
      "Epoch: 51 Iteration: 35900. Train_MSE: 0.06530661880970001. Test_MSE: 0.04077370464801788\n",
      "Epoch: 51 Iteration: 36000. Train_MSE: 0.05593010038137436. Test_MSE: 0.040556274354457855\n",
      "Epoch: 51 Iteration: 36100. Train_MSE: 0.0020286624785512686. Test_MSE: 0.048685021698474884\n",
      "Epoch: 51 Iteration: 36200. Train_MSE: 0.009848322719335556. Test_MSE: 0.0529959611594677\n",
      "Epoch: 51 Iteration: 36300. Train_MSE: 0.0009480674052610993. Test_MSE: 0.038316767662763596\n",
      "Epoch: 51 Iteration: 36400. Train_MSE: 0.004498958121985197. Test_MSE: 0.04973388835787773\n",
      "Epoch: 51 Iteration: 36500. Train_MSE: 0.005069006234407425. Test_MSE: 0.04787302017211914\n",
      "Epoch: 52 Iteration: 36600. Train_MSE: 0.08851731568574905. Test_MSE: 0.041733842343091965\n",
      "Epoch: 52 Iteration: 36700. Train_MSE: 0.050283096730709076. Test_MSE: 0.03980862721800804\n",
      "Epoch: 52 Iteration: 36800. Train_MSE: 0.018070176243782043. Test_MSE: 0.04756445810198784\n",
      "Epoch: 52 Iteration: 36900. Train_MSE: 0.009286617860198021. Test_MSE: 0.05510474368929863\n",
      "Epoch: 52 Iteration: 37000. Train_MSE: 0.0018655419116839767. Test_MSE: 0.039436500519514084\n",
      "Epoch: 52 Iteration: 37100. Train_MSE: 0.008142182603478432. Test_MSE: 0.049890611320734024\n",
      "Epoch: 52 Iteration: 37200. Train_MSE: 0.004396292380988598. Test_MSE: 0.047854356467723846\n",
      "Epoch: 53 Iteration: 37300. Train_MSE: 0.04328465834259987. Test_MSE: 0.04206329956650734\n",
      "Epoch: 53 Iteration: 37400. Train_MSE: 0.038811516016721725. Test_MSE: 0.0384298600256443\n",
      "Epoch: 53 Iteration: 37500. Train_MSE: 0.0203457809984684. Test_MSE: 0.04553375393152237\n",
      "Epoch: 53 Iteration: 37600. Train_MSE: 0.007029098924249411. Test_MSE: 0.05554993450641632\n",
      "Epoch: 53 Iteration: 37700. Train_MSE: 0.0024421520065516233. Test_MSE: 0.03980303183197975\n",
      "Epoch: 53 Iteration: 37800. Train_MSE: 0.007271585986018181. Test_MSE: 0.049081671983003616\n",
      "Epoch: 53 Iteration: 37900. Train_MSE: 0.0032818475738167763. Test_MSE: 0.0475035235285759\n",
      "Epoch: 54 Iteration: 38000. Train_MSE: 0.0409107506275177. Test_MSE: 0.043474290519952774\n",
      "Epoch: 54 Iteration: 38100. Train_MSE: 0.09023207426071167. Test_MSE: 0.03746683523058891\n",
      "Epoch: 54 Iteration: 38200. Train_MSE: 0.04473550617694855. Test_MSE: 0.043255873024463654\n",
      "Epoch: 54 Iteration: 38300. Train_MSE: 0.004200905095785856. Test_MSE: 0.05545005574822426\n",
      "Epoch: 54 Iteration: 38400. Train_MSE: 0.0023275853600353003. Test_MSE: 0.03966211527585983\n",
      "Epoch: 54 Iteration: 38500. Train_MSE: 0.009492344222962856. Test_MSE: 0.049707215279340744\n",
      "Epoch: 54 Iteration: 38600. Train_MSE: 0.004735906142741442. Test_MSE: 0.047444332391023636\n",
      "Epoch: 55 Iteration: 38700. Train_MSE: 0.04544198885560036. Test_MSE: 0.04492824524641037\n",
      "Epoch: 55 Iteration: 38800. Train_MSE: 0.10508701205253601. Test_MSE: 0.03736252710223198\n",
      "Epoch: 55 Iteration: 38900. Train_MSE: 0.022674664855003357. Test_MSE: 0.040894974023103714\n",
      "Epoch: 55 Iteration: 39000. Train_MSE: 0.004019028507173061. Test_MSE: 0.054847944527864456\n",
      "Epoch: 55 Iteration: 39100. Train_MSE: 0.0025846275966614485. Test_MSE: 0.039324112236499786\n",
      "Epoch: 55 Iteration: 39200. Train_MSE: 0.006629603914916515. Test_MSE: 0.05048206448554993\n",
      "Epoch: 55 Iteration: 39300. Train_MSE: 0.0004674798983614892. Test_MSE: 0.047400880604982376\n",
      "Epoch: 56 Iteration: 39400. Train_MSE: 0.05894897133111954. Test_MSE: 0.04826134443283081\n",
      "Epoch: 56 Iteration: 39500. Train_MSE: 0.04860428720712662. Test_MSE: 0.037474941462278366\n",
      "Epoch: 56 Iteration: 39600. Train_MSE: 0.025149263441562653. Test_MSE: 0.03911174088716507\n",
      "Epoch: 56 Iteration: 39700. Train_MSE: 0.0073669590055942535. Test_MSE: 0.054519861936569214\n",
      "Epoch: 56 Iteration: 39800. Train_MSE: 0.0027749966830015182. Test_MSE: 0.039356764405965805\n",
      "Epoch: 56 Iteration: 39900. Train_MSE: 0.008414166048169136. Test_MSE: 0.051777344197034836\n",
      "Epoch: 56 Iteration: 40000. Train_MSE: 0.000581627304200083. Test_MSE: 0.047286540269851685\n",
      "Epoch: 57 Iteration: 40100. Train_MSE: 0.08066915720701218. Test_MSE: 0.05170164629817009\n",
      "Epoch: 57 Iteration: 40200. Train_MSE: 0.07074465602636337. Test_MSE: 0.03914770483970642\n",
      "Epoch: 57 Iteration: 40300. Train_MSE: 0.05759468674659729. Test_MSE: 0.037546560168266296\n",
      "Epoch: 57 Iteration: 40400. Train_MSE: 0.0028289202600717545. Test_MSE: 0.05574384704232216\n",
      "Epoch: 57 Iteration: 40500. Train_MSE: 0.005167133640497923. Test_MSE: 0.040059737861156464\n",
      "Epoch: 57 Iteration: 40600. Train_MSE: 0.010886263102293015. Test_MSE: 0.052829042077064514\n",
      "Epoch: 57 Iteration: 40700. Train_MSE: 0.0009423235896974802. Test_MSE: 0.047198664397001266\n",
      "Epoch: 58 Iteration: 40800. Train_MSE: 0.05453399568796158. Test_MSE: 0.05285383760929108\n",
      "Epoch: 58 Iteration: 40900. Train_MSE: 0.061050090938806534. Test_MSE: 0.040295280516147614\n",
      "Epoch: 58 Iteration: 41000. Train_MSE: 0.04752971604466438. Test_MSE: 0.036552608013153076\n",
      "Epoch: 58 Iteration: 41100. Train_MSE: 0.0026784080546349287. Test_MSE: 0.05586734786629677\n",
      "Epoch: 58 Iteration: 41200. Train_MSE: 0.009535426273941994. Test_MSE: 0.040479693561792374\n",
      "Epoch: 58 Iteration: 41300. Train_MSE: 0.006837146822363138. Test_MSE: 0.0532408207654953\n",
      "Epoch: 58 Iteration: 41400. Train_MSE: 0.0009583156788721681. Test_MSE: 0.047233130782842636\n",
      "Epoch: 59 Iteration: 41500. Train_MSE: 0.07230991125106812. Test_MSE: 0.05244901776313782\n",
      "Epoch: 59 Iteration: 41600. Train_MSE: 0.05349909886717796. Test_MSE: 0.04263431578874588\n",
      "Epoch: 59 Iteration: 41700. Train_MSE: 0.05912253260612488. Test_MSE: 0.03631281480193138\n",
      "Epoch: 59 Iteration: 41800. Train_MSE: 0.0012379506370052695. Test_MSE: 0.05567830801010132\n",
      "Epoch: 59 Iteration: 41900. Train_MSE: 0.009059648029506207. Test_MSE: 0.0409291610121727\n",
      "Epoch: 59 Iteration: 42000. Train_MSE: 0.012016914784908295. Test_MSE: 0.05435573682188988\n",
      "Epoch: 59 Iteration: 42100. Train_MSE: 0.0011029656743630767. Test_MSE: 0.046384673565626144\n",
      "Epoch: 60 Iteration: 42200. Train_MSE: 0.07346925139427185. Test_MSE: 0.05122924968600273\n",
      "Epoch: 60 Iteration: 42300. Train_MSE: 0.07877331972122192. Test_MSE: 0.044448357075452805\n",
      "Epoch: 60 Iteration: 42400. Train_MSE: 0.06772768497467041. Test_MSE: 0.03583734109997749\n",
      "Epoch: 60 Iteration: 42500. Train_MSE: 0.0005768198752775788. Test_MSE: 0.05544682592153549\n",
      "Epoch: 60 Iteration: 42600. Train_MSE: 0.007674845401197672. Test_MSE: 0.04211706295609474\n",
      "Epoch: 60 Iteration: 42700. Train_MSE: 0.013607111759483814. Test_MSE: 0.05393029749393463\n",
      "Epoch: 60 Iteration: 42800. Train_MSE: 0.0017879280494526029. Test_MSE: 0.046643227338790894\n",
      "Epoch: 61 Iteration: 42900. Train_MSE: 0.05791210010647774. Test_MSE: 0.050622306764125824\n",
      "Epoch: 61 Iteration: 43000. Train_MSE: 0.05298362299799919. Test_MSE: 0.04770457744598389\n",
      "Epoch: 61 Iteration: 43100. Train_MSE: 0.06372770667076111. Test_MSE: 0.03597138449549675\n",
      "Epoch: 61 Iteration: 43200. Train_MSE: 0.0006365285953506827. Test_MSE: 0.05511311814188957\n",
      "Epoch: 61 Iteration: 43300. Train_MSE: 0.009586750529706478. Test_MSE: 0.04411626607179642\n",
      "Epoch: 61 Iteration: 43400. Train_MSE: 0.011249704286456108. Test_MSE: 0.053839098662137985\n",
      "Epoch: 61 Iteration: 43500. Train_MSE: 0.0023982697166502476. Test_MSE: 0.046505291014909744\n",
      "Epoch: 62 Iteration: 43600. Train_MSE: 0.025844883173704147. Test_MSE: 0.04999696835875511\n",
      "Epoch: 62 Iteration: 43700. Train_MSE: 0.056142400950193405. Test_MSE: 0.05235719680786133\n",
      "Epoch: 62 Iteration: 43800. Train_MSE: 0.057814255356788635. Test_MSE: 0.037324581295251846\n",
      "Epoch: 62 Iteration: 43900. Train_MSE: 0.00039224402280524373. Test_MSE: 0.05510136857628822\n",
      "Epoch: 62 Iteration: 44000. Train_MSE: 0.011298821307718754. Test_MSE: 0.04584929719567299\n",
      "Epoch: 62 Iteration: 44100. Train_MSE: 0.007769064977765083. Test_MSE: 0.05286795645952225\n",
      "Epoch: 62 Iteration: 44200. Train_MSE: 0.002897201804444194. Test_MSE: 0.04588671773672104\n",
      "Epoch: 63 Iteration: 44300. Train_MSE: 0.05430104583501816. Test_MSE: 0.050193607807159424\n",
      "Epoch: 63 Iteration: 44400. Train_MSE: 0.09549427777528763. Test_MSE: 0.055215876549482346\n",
      "Epoch: 63 Iteration: 44500. Train_MSE: 0.040927693247795105. Test_MSE: 0.03816968575119972\n",
      "Epoch: 63 Iteration: 44600. Train_MSE: 0.000352972827386111. Test_MSE: 0.05530785024166107\n",
      "Epoch: 63 Iteration: 44700. Train_MSE: 0.01367587223649025. Test_MSE: 0.04821939393877983\n",
      "Epoch: 63 Iteration: 44800. Train_MSE: 0.012224423699080944. Test_MSE: 0.051749493926763535\n",
      "Epoch: 63 Iteration: 44900. Train_MSE: 0.002860056236386299. Test_MSE: 0.045621998608112335\n",
      "Epoch: 64 Iteration: 45000. Train_MSE: 0.04907526075839996. Test_MSE: 0.04845155030488968\n",
      "Epoch: 64 Iteration: 45100. Train_MSE: 0.07181166112422943. Test_MSE: 0.05744565278291702\n",
      "Epoch: 64 Iteration: 45200. Train_MSE: 0.039894379675388336. Test_MSE: 0.039163652807474136\n",
      "Epoch: 64 Iteration: 45300. Train_MSE: 0.0004460674535948783. Test_MSE: 0.05526036396622658\n",
      "Epoch: 64 Iteration: 45400. Train_MSE: 0.014337156899273396. Test_MSE: 0.05139560624957085\n",
      "Epoch: 64 Iteration: 45500. Train_MSE: 0.008300449699163437. Test_MSE: 0.050899773836135864\n",
      "Epoch: 64 Iteration: 45600. Train_MSE: 0.005061356350779533. Test_MSE: 0.04577014222741127\n",
      "Epoch: 65 Iteration: 45700. Train_MSE: 0.04847756028175354. Test_MSE: 0.048914700746536255\n",
      "Epoch: 65 Iteration: 45800. Train_MSE: 0.04180712625384331. Test_MSE: 0.057395659387111664\n",
      "Epoch: 65 Iteration: 45900. Train_MSE: 0.0748014897108078. Test_MSE: 0.04183879494667053\n",
      "Epoch: 65 Iteration: 46000. Train_MSE: 0.0004316123959142715. Test_MSE: 0.054941240698099136\n",
      "Epoch: 65 Iteration: 46100. Train_MSE: 0.02017081342637539. Test_MSE: 0.05315067246556282\n",
      "Epoch: 65 Iteration: 46200. Train_MSE: 0.0079099852591753. Test_MSE: 0.05055113136768341\n",
      "Epoch: 65 Iteration: 46300. Train_MSE: 0.003689104923978448. Test_MSE: 0.045592475682497025\n",
      "Epoch: 66 Iteration: 46400. Train_MSE: 0.02924324758350849. Test_MSE: 0.049468304961919785\n",
      "Epoch: 66 Iteration: 46500. Train_MSE: 0.0729115903377533. Test_MSE: 0.05699923262000084\n",
      "Epoch: 66 Iteration: 46600. Train_MSE: 0.05018576607108116. Test_MSE: 0.04509984701871872\n",
      "Epoch: 66 Iteration: 46700. Train_MSE: 0.00046049075899645686. Test_MSE: 0.055001646280288696\n",
      "Epoch: 66 Iteration: 46800. Train_MSE: 0.01629629358649254. Test_MSE: 0.053224269300699234\n",
      "Epoch: 66 Iteration: 46900. Train_MSE: 0.01960473693907261. Test_MSE: 0.051250800490379333\n",
      "Epoch: 66 Iteration: 47000. Train_MSE: 0.004141253884881735. Test_MSE: 0.04571016877889633\n",
      "Epoch: 67 Iteration: 47100. Train_MSE: 0.03208307921886444. Test_MSE: 0.049386776983737946\n",
      "Epoch: 67 Iteration: 47200. Train_MSE: 0.053654175251722336. Test_MSE: 0.054690904915332794\n",
      "Epoch: 67 Iteration: 47300. Train_MSE: 0.060989391058683395. Test_MSE: 0.04769570380449295\n",
      "Epoch: 67 Iteration: 47400. Train_MSE: 0.0015020951395854354. Test_MSE: 0.05532163754105568\n",
      "Epoch: 67 Iteration: 47500. Train_MSE: 0.010919316671788692. Test_MSE: 0.05243944749236107\n",
      "Epoch: 67 Iteration: 47600. Train_MSE: 0.008015825413167477. Test_MSE: 0.05182848498225212\n",
      "Epoch: 67 Iteration: 47700. Train_MSE: 0.007300672587007284. Test_MSE: 0.04501521587371826\n",
      "Epoch: 68 Iteration: 47800. Train_MSE: 0.02454952709376812. Test_MSE: 0.05012425407767296\n",
      "Epoch: 68 Iteration: 47900. Train_MSE: 0.04893677309155464. Test_MSE: 0.05331885814666748\n",
      "Epoch: 68 Iteration: 48000. Train_MSE: 0.060810159891843796. Test_MSE: 0.05076414346694946\n",
      "Epoch: 68 Iteration: 48100. Train_MSE: 0.0014995980309322476. Test_MSE: 0.05549473315477371\n",
      "Epoch: 68 Iteration: 48200. Train_MSE: 0.007478209678083658. Test_MSE: 0.049883048981428146\n",
      "Epoch: 68 Iteration: 48300. Train_MSE: 0.004982896614819765. Test_MSE: 0.05238032713532448\n",
      "Epoch: 68 Iteration: 48400. Train_MSE: 0.005184231325984001. Test_MSE: 0.04555978998541832\n",
      "Epoch: 69 Iteration: 48500. Train_MSE: 0.026663441210985184. Test_MSE: 0.04923521727323532\n",
      "Epoch: 69 Iteration: 48600. Train_MSE: 0.05522819980978966. Test_MSE: 0.05124564841389656\n",
      "Epoch: 69 Iteration: 48700. Train_MSE: 0.07532287389039993. Test_MSE: 0.05349867418408394\n",
      "Epoch: 69 Iteration: 48800. Train_MSE: 0.0019209295278415084. Test_MSE: 0.055086780339479446\n",
      "Epoch: 69 Iteration: 48900. Train_MSE: 0.015392687171697617. Test_MSE: 0.047448765486478806\n",
      "Epoch: 69 Iteration: 49000. Train_MSE: 0.006965687498450279. Test_MSE: 0.05395398661494255\n",
      "Epoch: 69 Iteration: 49100. Train_MSE: 0.007755696773529053. Test_MSE: 0.04537847638130188\n",
      "Epoch: 70 Iteration: 49200. Train_MSE: 0.009644435718655586. Test_MSE: 0.04988773167133331\n",
      "Epoch: 70 Iteration: 49300. Train_MSE: 0.050194524228572845. Test_MSE: 0.05013967305421829\n",
      "Epoch: 70 Iteration: 49400. Train_MSE: 0.0567525178194046. Test_MSE: 0.05465933308005333\n",
      "Epoch: 70 Iteration: 49500. Train_MSE: 0.0034612733870744705. Test_MSE: 0.05486597120761871\n",
      "Epoch: 70 Iteration: 49600. Train_MSE: 0.016200177371501923. Test_MSE: 0.04535685107111931\n",
      "Epoch: 70 Iteration: 49700. Train_MSE: 0.007104433141648769. Test_MSE: 0.05492755025625229\n",
      "Epoch: 70 Iteration: 49800. Train_MSE: 0.008449056185781956. Test_MSE: 0.046086668968200684\n",
      "Epoch: 71 Iteration: 49900. Train_MSE: 0.02058938331902027. Test_MSE: 0.049988921731710434\n",
      "Epoch: 71 Iteration: 50000. Train_MSE: 0.02325088530778885. Test_MSE: 0.049661923199892044\n",
      "Epoch: 71 Iteration: 50100. Train_MSE: 0.04872852936387062. Test_MSE: 0.05509890615940094\n",
      "Epoch: 71 Iteration: 50200. Train_MSE: 0.005482899025082588. Test_MSE: 0.05475257709622383\n",
      "Epoch: 71 Iteration: 50300. Train_MSE: 0.014785557053983212. Test_MSE: 0.044090788811445236\n",
      "Epoch: 71 Iteration: 50400. Train_MSE: 0.010744507424533367. Test_MSE: 0.05518529191613197\n",
      "Epoch: 71 Iteration: 50500. Train_MSE: 0.00909786019474268. Test_MSE: 0.04673391580581665\n",
      "Epoch: 72 Iteration: 50600. Train_MSE: 0.0029248923528939486. Test_MSE: 0.05009150505065918\n",
      "Epoch: 72 Iteration: 50700. Train_MSE: 0.08655531704425812. Test_MSE: 0.04882251098752022\n",
      "Epoch: 72 Iteration: 50800. Train_MSE: 0.07401526719331741. Test_MSE: 0.053124189376831055\n",
      "Epoch: 72 Iteration: 50900. Train_MSE: 0.0064843748696148396. Test_MSE: 0.054670900106430054\n",
      "Epoch: 72 Iteration: 51000. Train_MSE: 0.016119210049510002. Test_MSE: 0.04361341521143913\n",
      "Epoch: 72 Iteration: 51100. Train_MSE: 0.006455866154283285. Test_MSE: 0.0563395619392395\n",
      "Epoch: 72 Iteration: 51200. Train_MSE: 0.007387101650238037. Test_MSE: 0.048045869916677475\n",
      "Epoch: 73 Iteration: 51300. Train_MSE: 0.01041013840585947. Test_MSE: 0.0501481369137764\n",
      "Epoch: 73 Iteration: 51400. Train_MSE: 0.014107159338891506. Test_MSE: 0.04804873839020729\n",
      "Epoch: 73 Iteration: 51500. Train_MSE: 0.03211011365056038. Test_MSE: 0.05054293945431709\n",
      "Epoch: 73 Iteration: 51600. Train_MSE: 0.003673391416668892. Test_MSE: 0.05371846258640289\n",
      "Epoch: 73 Iteration: 51700. Train_MSE: 0.0027956014964729548. Test_MSE: 0.04347512871026993\n",
      "Epoch: 73 Iteration: 51800. Train_MSE: 0.007850190624594688. Test_MSE: 0.05544747784733772\n",
      "Epoch: 73 Iteration: 51900. Train_MSE: 0.01094804611057043. Test_MSE: 0.049423687160015106\n",
      "Epoch: 74 Iteration: 52000. Train_MSE: 0.002065634587779641. Test_MSE: 0.05079972371459007\n",
      "Epoch: 74 Iteration: 52100. Train_MSE: 0.0417683944106102. Test_MSE: 0.04798820614814758\n",
      "Epoch: 74 Iteration: 52200. Train_MSE: 0.0936255007982254. Test_MSE: 0.048403166234493256\n",
      "Epoch: 74 Iteration: 52300. Train_MSE: 0.007223931141197681. Test_MSE: 0.05497447028756142\n",
      "Epoch: 74 Iteration: 52400. Train_MSE: 0.0005440698587335646. Test_MSE: 0.04370186850428581\n",
      "Epoch: 74 Iteration: 52500. Train_MSE: 0.0018627607496455312. Test_MSE: 0.055836424231529236\n",
      "Epoch: 74 Iteration: 52600. Train_MSE: 0.008305289782583714. Test_MSE: 0.05007648095488548\n",
      "Epoch: 75 Iteration: 52700. Train_MSE: 0.006346685346215963. Test_MSE: 0.051000773906707764\n",
      "Epoch: 75 Iteration: 52800. Train_MSE: 0.020146332681179047. Test_MSE: 0.04751015454530716\n",
      "Epoch: 75 Iteration: 52900. Train_MSE: 0.047856539487838745. Test_MSE: 0.04613562673330307\n",
      "Epoch: 75 Iteration: 53000. Train_MSE: 0.007073042448610067. Test_MSE: 0.05489414185285568\n",
      "Epoch: 75 Iteration: 53100. Train_MSE: 0.0014055382926017046. Test_MSE: 0.044044338166713715\n",
      "Epoch: 75 Iteration: 53200. Train_MSE: 0.0011913880007341504. Test_MSE: 0.055902354419231415\n",
      "Epoch: 75 Iteration: 53300. Train_MSE: 0.010111801326274872. Test_MSE: 0.049346357583999634\n",
      "Epoch: 76 Iteration: 53400. Train_MSE: 0.006700994446873665. Test_MSE: 0.05131777375936508\n",
      "Epoch: 76 Iteration: 53500. Train_MSE: 0.011517157778143883. Test_MSE: 0.04691692069172859\n",
      "Epoch: 76 Iteration: 53600. Train_MSE: 0.046680841594934464. Test_MSE: 0.045391377061605453\n",
      "Epoch: 76 Iteration: 53700. Train_MSE: 0.012043596245348454. Test_MSE: 0.05452685430645943\n",
      "Epoch: 76 Iteration: 53800. Train_MSE: 0.00015503472241107374. Test_MSE: 0.043739140033721924\n",
      "Epoch: 76 Iteration: 53900. Train_MSE: 0.0007972610765136778. Test_MSE: 0.05531894415616989\n",
      "Epoch: 76 Iteration: 54000. Train_MSE: 0.01083215232938528. Test_MSE: 0.04874812066555023\n",
      "Epoch: 77 Iteration: 54100. Train_MSE: 0.006295881234109402. Test_MSE: 0.05196236073970795\n",
      "Epoch: 77 Iteration: 54200. Train_MSE: 0.008020970039069653. Test_MSE: 0.04731366038322449\n",
      "Epoch: 77 Iteration: 54300. Train_MSE: 0.029925772920250893. Test_MSE: 0.04454445093870163\n",
      "Epoch: 77 Iteration: 54400. Train_MSE: 0.008903054520487785. Test_MSE: 0.05476721376180649\n",
      "Epoch: 77 Iteration: 54500. Train_MSE: 0.00014681647007819265. Test_MSE: 0.04458943381905556\n",
      "Epoch: 77 Iteration: 54600. Train_MSE: 0.0006908157956786454. Test_MSE: 0.055287525057792664\n",
      "Epoch: 77 Iteration: 54700. Train_MSE: 0.004538174252957106. Test_MSE: 0.04759116470813751\n",
      "Epoch: 78 Iteration: 54800. Train_MSE: 0.0028495353180915117. Test_MSE: 0.0522981733083725\n",
      "Epoch: 78 Iteration: 54900. Train_MSE: 0.0049356259405612946. Test_MSE: 0.04766932502388954\n",
      "Epoch: 78 Iteration: 55000. Train_MSE: 0.04127994924783707. Test_MSE: 0.04419528692960739\n",
      "Epoch: 78 Iteration: 55100. Train_MSE: 0.01039897557348013. Test_MSE: 0.054666802287101746\n",
      "Epoch: 78 Iteration: 55200. Train_MSE: 0.0002213667321484536. Test_MSE: 0.04474354162812233\n",
      "Epoch: 78 Iteration: 55300. Train_MSE: 0.00046163707156665623. Test_MSE: 0.055053967982530594\n",
      "Epoch: 78 Iteration: 55400. Train_MSE: 0.013734552077949047. Test_MSE: 0.04676457494497299\n",
      "Epoch: 79 Iteration: 55500. Train_MSE: 0.014321977272629738. Test_MSE: 0.05252714827656746\n",
      "Epoch: 79 Iteration: 55600. Train_MSE: 0.004429062828421593. Test_MSE: 0.047657862305641174\n",
      "Epoch: 79 Iteration: 55700. Train_MSE: 0.032786883413791656. Test_MSE: 0.0436437651515007\n",
      "Epoch: 79 Iteration: 55800. Train_MSE: 0.008529326878488064. Test_MSE: 0.054665032774209976\n",
      "Epoch: 79 Iteration: 55900. Train_MSE: 0.0003962818591389805. Test_MSE: 0.04441634193062782\n",
      "Epoch: 79 Iteration: 56000. Train_MSE: 0.00045855427742935717. Test_MSE: 0.054720189422369\n",
      "Epoch: 79 Iteration: 56100. Train_MSE: 0.011469588615000248. Test_MSE: 0.046023063361644745\n",
      "Epoch: 80 Iteration: 56200. Train_MSE: 0.022392811253666878. Test_MSE: 0.052622802555561066\n",
      "Epoch: 80 Iteration: 56300. Train_MSE: 0.007880710065364838. Test_MSE: 0.04801821708679199\n",
      "Epoch: 80 Iteration: 56400. Train_MSE: 0.02252177707850933. Test_MSE: 0.04328105226159096\n",
      "Epoch: 80 Iteration: 56500. Train_MSE: 0.012186887674033642. Test_MSE: 0.054466813802719116\n",
      "Epoch: 80 Iteration: 56600. Train_MSE: 0.0006049918010830879. Test_MSE: 0.04513993486762047\n",
      "Epoch: 80 Iteration: 56700. Train_MSE: 0.0005659181624650955. Test_MSE: 0.05452935770153999\n",
      "Epoch: 80 Iteration: 56800. Train_MSE: 0.00882390420883894. Test_MSE: 0.0464094839990139\n",
      "Epoch: 81 Iteration: 56900. Train_MSE: 0.01983311027288437. Test_MSE: 0.05194491520524025\n",
      "Epoch: 81 Iteration: 57000. Train_MSE: 0.003828048473224044. Test_MSE: 0.047805119305849075\n",
      "Epoch: 81 Iteration: 57100. Train_MSE: 0.008616379462182522. Test_MSE: 0.043228745460510254\n",
      "Epoch: 81 Iteration: 57200. Train_MSE: 0.009301871992647648. Test_MSE: 0.055917393416166306\n",
      "Epoch: 81 Iteration: 57300. Train_MSE: 0.0005960285780020058. Test_MSE: 0.04557253420352936\n",
      "Epoch: 81 Iteration: 57400. Train_MSE: 0.0014760030899196863. Test_MSE: 0.05397547781467438\n",
      "Epoch: 81 Iteration: 57500. Train_MSE: 0.009269708767533302. Test_MSE: 0.047047361731529236\n",
      "Epoch: 82 Iteration: 57600. Train_MSE: 0.0073341797105968. Test_MSE: 0.05111830309033394\n",
      "Epoch: 82 Iteration: 57700. Train_MSE: 0.00574128981679678. Test_MSE: 0.04842519387602806\n",
      "Epoch: 82 Iteration: 57800. Train_MSE: 0.008876491338014603. Test_MSE: 0.04358059540390968\n",
      "Epoch: 82 Iteration: 57900. Train_MSE: 0.012371220625936985. Test_MSE: 0.05649622902274132\n",
      "Epoch: 82 Iteration: 58000. Train_MSE: 0.0007617989322170615. Test_MSE: 0.04542974755167961\n",
      "Epoch: 82 Iteration: 58100. Train_MSE: 0.001888145343400538. Test_MSE: 0.05335333198308945\n",
      "Epoch: 82 Iteration: 58200. Train_MSE: 0.00515070091933012. Test_MSE: 0.04772103205323219\n",
      "Epoch: 83 Iteration: 58300. Train_MSE: 0.017493339255452156. Test_MSE: 0.04955747723579407\n",
      "Epoch: 83 Iteration: 58400. Train_MSE: 0.009446803480386734. Test_MSE: 0.04839147627353668\n",
      "Epoch: 83 Iteration: 58500. Train_MSE: 0.004330637864768505. Test_MSE: 0.043439872562885284\n",
      "Epoch: 83 Iteration: 58600. Train_MSE: 0.017235174775123596. Test_MSE: 0.05761311203241348\n",
      "Epoch: 83 Iteration: 58700. Train_MSE: 0.0010597711661830544. Test_MSE: 0.04586973413825035\n",
      "Epoch: 83 Iteration: 58800. Train_MSE: 0.0013726134784519672. Test_MSE: 0.052118267863988876\n",
      "Epoch: 83 Iteration: 58900. Train_MSE: 0.01695251651108265. Test_MSE: 0.04823092743754387\n",
      "Epoch: 84 Iteration: 59000. Train_MSE: 0.03131384029984474. Test_MSE: 0.04801486060023308\n",
      "Epoch: 84 Iteration: 59100. Train_MSE: 0.005819565616548061. Test_MSE: 0.04830312728881836\n",
      "Epoch: 84 Iteration: 59200. Train_MSE: 0.006336660590022802. Test_MSE: 0.04349694028496742\n",
      "Epoch: 84 Iteration: 59300. Train_MSE: 0.013466506265103817. Test_MSE: 0.057814061641693115\n",
      "Epoch: 84 Iteration: 59400. Train_MSE: 0.0013054906157776713. Test_MSE: 0.046122293919324875\n",
      "Epoch: 84 Iteration: 59500. Train_MSE: 0.002035250421613455. Test_MSE: 0.05071268230676651\n",
      "Epoch: 84 Iteration: 59600. Train_MSE: 0.0058450293727219105. Test_MSE: 0.048015955835580826\n",
      "Epoch: 85 Iteration: 59700. Train_MSE: 0.031580932438373566. Test_MSE: 0.04639500752091408\n",
      "Epoch: 85 Iteration: 59800. Train_MSE: 0.005441084038466215. Test_MSE: 0.048152122646570206\n",
      "Epoch: 85 Iteration: 59900. Train_MSE: 0.001888947212137282. Test_MSE: 0.043700944632291794\n",
      "Epoch: 85 Iteration: 60000. Train_MSE: 0.012316764332354069. Test_MSE: 0.05771201103925705\n",
      "Epoch: 85 Iteration: 60100. Train_MSE: 0.002156066708266735. Test_MSE: 0.04641242325305939\n",
      "Epoch: 85 Iteration: 60200. Train_MSE: 0.0021312027238309383. Test_MSE: 0.0491514727473259\n",
      "Epoch: 85 Iteration: 60300. Train_MSE: 0.004531913436949253. Test_MSE: 0.04806965962052345\n",
      "Epoch: 86 Iteration: 60400. Train_MSE: 0.056022901087999344. Test_MSE: 0.04536781087517738\n",
      "Epoch: 86 Iteration: 60500. Train_MSE: 0.009664428420364857. Test_MSE: 0.04829033836722374\n",
      "Epoch: 86 Iteration: 60600. Train_MSE: 0.008945399895310402. Test_MSE: 0.04399260878562927\n",
      "Epoch: 86 Iteration: 60700. Train_MSE: 0.019620858132839203. Test_MSE: 0.057198815047740936\n",
      "Epoch: 86 Iteration: 60800. Train_MSE: 0.0018227840773761272. Test_MSE: 0.047008123248815536\n",
      "Epoch: 86 Iteration: 60900. Train_MSE: 0.005552082788199186. Test_MSE: 0.0478004589676857\n",
      "Epoch: 86 Iteration: 61000. Train_MSE: 0.0045479219406843185. Test_MSE: 0.04829837754368782\n",
      "Epoch: 87 Iteration: 61100. Train_MSE: 0.031114615499973297. Test_MSE: 0.04381377995014191\n",
      "Epoch: 87 Iteration: 61200. Train_MSE: 0.008218602277338505. Test_MSE: 0.048041023313999176\n",
      "Epoch: 87 Iteration: 61300. Train_MSE: 0.0016389080556109548. Test_MSE: 0.04428563639521599\n",
      "Epoch: 87 Iteration: 61400. Train_MSE: 0.009089128114283085. Test_MSE: 0.05677446722984314\n",
      "Epoch: 87 Iteration: 61500. Train_MSE: 0.003240120131522417. Test_MSE: 0.04771452397108078\n",
      "Epoch: 87 Iteration: 61600. Train_MSE: 0.006169181317090988. Test_MSE: 0.046843141317367554\n",
      "Epoch: 87 Iteration: 61700. Train_MSE: 0.0022584660910069942. Test_MSE: 0.04836419224739075\n",
      "Epoch: 88 Iteration: 61800. Train_MSE: 0.051525965332984924. Test_MSE: 0.042396873235702515\n",
      "Epoch: 88 Iteration: 61900. Train_MSE: 0.02037968672811985. Test_MSE: 0.04750855267047882\n",
      "Epoch: 88 Iteration: 62000. Train_MSE: 0.002104288898408413. Test_MSE: 0.04437518119812012\n",
      "Epoch: 88 Iteration: 62100. Train_MSE: 0.0132744824513793. Test_MSE: 0.05639135092496872\n",
      "Epoch: 88 Iteration: 62200. Train_MSE: 0.0047470806166529655. Test_MSE: 0.048568274825811386\n",
      "Epoch: 88 Iteration: 62300. Train_MSE: 0.005104610696434975. Test_MSE: 0.04528927057981491\n",
      "Epoch: 88 Iteration: 62400. Train_MSE: 0.0012807567836716771. Test_MSE: 0.048635996878147125\n",
      "Epoch: 89 Iteration: 62500. Train_MSE: 0.05735424906015396. Test_MSE: 0.041109535843133926\n",
      "Epoch: 89 Iteration: 62600. Train_MSE: 0.021660160273313522. Test_MSE: 0.0471375547349453\n",
      "Epoch: 89 Iteration: 62700. Train_MSE: 0.0018345927819609642. Test_MSE: 0.044635966420173645\n",
      "Epoch: 89 Iteration: 62800. Train_MSE: 0.011099407449364662. Test_MSE: 0.05500999093055725\n",
      "Epoch: 89 Iteration: 62900. Train_MSE: 0.004222514107823372. Test_MSE: 0.04841519147157669\n",
      "Epoch: 89 Iteration: 63000. Train_MSE: 0.007925249636173248. Test_MSE: 0.043950945138931274\n",
      "Epoch: 89 Iteration: 63100. Train_MSE: 0.00029797825845889747. Test_MSE: 0.047870222479104996\n",
      "Epoch: 90 Iteration: 63200. Train_MSE: 0.08763532340526581. Test_MSE: 0.04024204611778259\n",
      "Epoch: 90 Iteration: 63300. Train_MSE: 0.025096042081713676. Test_MSE: 0.04639044776558876\n",
      "Epoch: 90 Iteration: 63400. Train_MSE: 0.012805518694221973. Test_MSE: 0.04476574808359146\n",
      "Epoch: 90 Iteration: 63500. Train_MSE: 0.008412331342697144. Test_MSE: 0.05415850877761841\n",
      "Epoch: 90 Iteration: 63600. Train_MSE: 0.00436716852709651. Test_MSE: 0.049634627997875214\n",
      "Epoch: 90 Iteration: 63700. Train_MSE: 0.008456642739474773. Test_MSE: 0.04268340393900871\n",
      "Epoch: 90 Iteration: 63800. Train_MSE: 0.0002980075660161674. Test_MSE: 0.04832993820309639\n",
      "Epoch: 91 Iteration: 63900. Train_MSE: 0.05757778510451317. Test_MSE: 0.03977269306778908\n",
      "Epoch: 91 Iteration: 64000. Train_MSE: 0.038285426795482635. Test_MSE: 0.046411629766225815\n",
      "Epoch: 91 Iteration: 64100. Train_MSE: 0.010448706336319447. Test_MSE: 0.04501057788729668\n",
      "Epoch: 91 Iteration: 64200. Train_MSE: 0.007802550680935383. Test_MSE: 0.05348274111747742\n",
      "Epoch: 91 Iteration: 64300. Train_MSE: 0.009713925421237946. Test_MSE: 0.04991839453577995\n",
      "Epoch: 91 Iteration: 64400. Train_MSE: 0.010649383999407291. Test_MSE: 0.04190204665064812\n",
      "Epoch: 91 Iteration: 64500. Train_MSE: 0.00030287628760561347. Test_MSE: 0.048168446868658066\n",
      "Epoch: 92 Iteration: 64600. Train_MSE: 0.04916951060295105. Test_MSE: 0.039692725986242294\n",
      "Epoch: 92 Iteration: 64700. Train_MSE: 0.05687660723924637. Test_MSE: 0.04540253058075905\n",
      "Epoch: 92 Iteration: 64800. Train_MSE: 0.0036825311835855246. Test_MSE: 0.04482997953891754\n",
      "Epoch: 92 Iteration: 64900. Train_MSE: 0.009048135951161385. Test_MSE: 0.05256928130984306\n",
      "Epoch: 92 Iteration: 65000. Train_MSE: 0.011462257243692875. Test_MSE: 0.05092233419418335\n",
      "Epoch: 92 Iteration: 65100. Train_MSE: 0.011669354513287544. Test_MSE: 0.04140361770987511\n",
      "Epoch: 92 Iteration: 65200. Train_MSE: 0.0005399548099376261. Test_MSE: 0.04789471998810768\n",
      "Epoch: 93 Iteration: 65300. Train_MSE: 0.04642980173230171. Test_MSE: 0.040256042033433914\n",
      "Epoch: 93 Iteration: 65400. Train_MSE: 0.025651145726442337. Test_MSE: 0.044370006769895554\n",
      "Epoch: 93 Iteration: 65500. Train_MSE: 0.01737157069146633. Test_MSE: 0.0446740984916687\n",
      "Epoch: 93 Iteration: 65600. Train_MSE: 0.006067897658795118. Test_MSE: 0.05176065117120743\n",
      "Epoch: 93 Iteration: 65700. Train_MSE: 0.016252081841230392. Test_MSE: 0.050646428018808365\n",
      "Epoch: 93 Iteration: 65800. Train_MSE: 0.012330271303653717. Test_MSE: 0.041177865117788315\n",
      "Epoch: 93 Iteration: 65900. Train_MSE: 0.000622918363660574. Test_MSE: 0.04808913543820381\n",
      "Epoch: 94 Iteration: 66000. Train_MSE: 0.04878538101911545. Test_MSE: 0.041410282254219055\n",
      "Epoch: 94 Iteration: 66100. Train_MSE: 0.03208843246102333. Test_MSE: 0.04346536472439766\n",
      "Epoch: 94 Iteration: 66200. Train_MSE: 0.026966692879796028. Test_MSE: 0.044316090643405914\n",
      "Epoch: 94 Iteration: 66300. Train_MSE: 0.0066312504932284355. Test_MSE: 0.051376305520534515\n",
      "Epoch: 94 Iteration: 66400. Train_MSE: 0.010658180341124535. Test_MSE: 0.05015387386083603\n",
      "Epoch: 94 Iteration: 66500. Train_MSE: 0.006681645289063454. Test_MSE: 0.041598472744226456\n",
      "Epoch: 94 Iteration: 66600. Train_MSE: 0.0011514895595610142. Test_MSE: 0.04810790345072746\n",
      "Epoch: 95 Iteration: 66700. Train_MSE: 0.07395448535680771. Test_MSE: 0.04330350086092949\n",
      "Epoch: 95 Iteration: 66800. Train_MSE: 0.05281126871705055. Test_MSE: 0.04239856079220772\n",
      "Epoch: 95 Iteration: 66900. Train_MSE: 0.02019556798040867. Test_MSE: 0.043515969067811966\n",
      "Epoch: 95 Iteration: 67000. Train_MSE: 0.004381487146019936. Test_MSE: 0.050686802715063095\n",
      "Epoch: 95 Iteration: 67100. Train_MSE: 0.008483140729367733. Test_MSE: 0.04994427040219307\n",
      "Epoch: 95 Iteration: 67200. Train_MSE: 0.003706206101924181. Test_MSE: 0.04172929376363754\n",
      "Epoch: 95 Iteration: 67300. Train_MSE: 0.0008497051312588155. Test_MSE: 0.04830869287252426\n",
      "Epoch: 96 Iteration: 67400. Train_MSE: 0.04793153330683708. Test_MSE: 0.044816724956035614\n",
      "Epoch: 96 Iteration: 67500. Train_MSE: 0.047859076410532. Test_MSE: 0.04164576530456543\n",
      "Epoch: 96 Iteration: 67600. Train_MSE: 0.021111227571964264. Test_MSE: 0.043263956904411316\n",
      "Epoch: 96 Iteration: 67700. Train_MSE: 0.004408618435263634. Test_MSE: 0.049428924918174744\n",
      "Epoch: 96 Iteration: 67800. Train_MSE: 0.014412295073270798. Test_MSE: 0.048428766429424286\n",
      "Epoch: 96 Iteration: 67900. Train_MSE: 0.002379171783104539. Test_MSE: 0.041691530495882034\n",
      "Epoch: 96 Iteration: 68000. Train_MSE: 0.0009551856201142073. Test_MSE: 0.04825440049171448\n",
      "Epoch: 97 Iteration: 68100. Train_MSE: 0.12572993338108063. Test_MSE: 0.04590022563934326\n",
      "Epoch: 97 Iteration: 68200. Train_MSE: 0.04634646326303482. Test_MSE: 0.04175582155585289\n",
      "Epoch: 97 Iteration: 68300. Train_MSE: 0.03033558279275894. Test_MSE: 0.042660944163799286\n",
      "Epoch: 97 Iteration: 68400. Train_MSE: 0.00396950775757432. Test_MSE: 0.04887183755636215\n",
      "Epoch: 97 Iteration: 68500. Train_MSE: 0.01022382453083992. Test_MSE: 0.047521110624074936\n",
      "Epoch: 97 Iteration: 68600. Train_MSE: 0.0007578813238069415. Test_MSE: 0.04202129691839218\n",
      "Epoch: 97 Iteration: 68700. Train_MSE: 0.0012123475316911936. Test_MSE: 0.04865076765418053\n",
      "Epoch: 98 Iteration: 68800. Train_MSE: 0.06290087848901749. Test_MSE: 0.046574123203754425\n",
      "Epoch: 98 Iteration: 68900. Train_MSE: 0.04647836089134216. Test_MSE: 0.04190792515873909\n",
      "Epoch: 98 Iteration: 69000. Train_MSE: 0.036790039390325546. Test_MSE: 0.041975684463977814\n",
      "Epoch: 98 Iteration: 69100. Train_MSE: 0.004356184042990208. Test_MSE: 0.048351481556892395\n",
      "Epoch: 98 Iteration: 69200. Train_MSE: 0.014467604458332062. Test_MSE: 0.0481572151184082\n",
      "Epoch: 98 Iteration: 69300. Train_MSE: 0.0010214962530881166. Test_MSE: 0.041930701583623886\n",
      "Epoch: 98 Iteration: 69400. Train_MSE: 0.0016136261401697993. Test_MSE: 0.04875482618808746\n",
      "Epoch: 99 Iteration: 69500. Train_MSE: 0.056947603821754456. Test_MSE: 0.04609030857682228\n",
      "Epoch: 99 Iteration: 69600. Train_MSE: 0.07186830788850784. Test_MSE: 0.04246519133448601\n",
      "Epoch: 99 Iteration: 69700. Train_MSE: 0.037400055676698685. Test_MSE: 0.041286054998636246\n",
      "Epoch: 99 Iteration: 69800. Train_MSE: 0.0007634304347448051. Test_MSE: 0.047269005328416824\n",
      "Epoch: 99 Iteration: 69900. Train_MSE: 0.015294991433620453. Test_MSE: 0.048805851489305496\n",
      "Epoch: 99 Iteration: 70000. Train_MSE: 0.00019639918173197657. Test_MSE: 0.04177766665816307\n",
      "Epoch: 99 Iteration: 70100. Train_MSE: 0.0031745200976729393. Test_MSE: 0.04885658621788025\n",
      "Epoch: 99 Iteration: 70200. Train_MSE: 0.006974249612540007. Test_MSE: 0.04717911407351494\n",
      "Epoch: 100 Iteration: 70300. Train_MSE: 0.05700075998902321. Test_MSE: 0.043406471610069275\n",
      "Epoch: 100 Iteration: 70400. Train_MSE: 0.029890885576605797. Test_MSE: 0.04065118357539177\n",
      "Epoch: 100 Iteration: 70500. Train_MSE: 0.0008556082029826939. Test_MSE: 0.046079155057668686\n",
      "Epoch: 100 Iteration: 70600. Train_MSE: 0.011684908531606197. Test_MSE: 0.0496520921587944\n",
      "Epoch: 100 Iteration: 70700. Train_MSE: 0.0006571474950760603. Test_MSE: 0.0417657233774662\n",
      "Epoch: 100 Iteration: 70800. Train_MSE: 0.003615898545831442. Test_MSE: 0.048723239451646805\n",
      "Epoch: 100 Iteration: 70900. Train_MSE: 0.014569273218512535. Test_MSE: 0.04729976877570152\n",
      "Epoch: 101 Iteration: 71000. Train_MSE: 0.07114561647176743. Test_MSE: 0.04350181296467781\n",
      "Epoch: 101 Iteration: 71100. Train_MSE: 0.05604580044746399. Test_MSE: 0.03923536464571953\n",
      "Epoch: 101 Iteration: 71200. Train_MSE: 0.0023947551380842924. Test_MSE: 0.04524897783994675\n",
      "Epoch: 101 Iteration: 71300. Train_MSE: 0.010382802225649357. Test_MSE: 0.05074179917573929\n",
      "Epoch: 101 Iteration: 71400. Train_MSE: 0.0009612311259843409. Test_MSE: 0.04206514731049538\n",
      "Epoch: 101 Iteration: 71500. Train_MSE: 0.004458282142877579. Test_MSE: 0.048583585768938065\n",
      "Epoch: 101 Iteration: 71600. Train_MSE: 0.004750698339194059. Test_MSE: 0.04725329950451851\n",
      "Epoch: 102 Iteration: 71700. Train_MSE: 0.0828753262758255. Test_MSE: 0.04484548792243004\n",
      "Epoch: 102 Iteration: 71800. Train_MSE: 0.04700010269880295. Test_MSE: 0.039015330374240875\n",
      "Epoch: 102 Iteration: 71900. Train_MSE: 0.01837245747447014. Test_MSE: 0.04465677589178085\n",
      "Epoch: 102 Iteration: 72000. Train_MSE: 0.009516682475805283. Test_MSE: 0.051643092185258865\n",
      "Epoch: 102 Iteration: 72100. Train_MSE: 0.0007747778436169028. Test_MSE: 0.04242464527487755\n",
      "Epoch: 102 Iteration: 72200. Train_MSE: 0.007770891301333904. Test_MSE: 0.04826551303267479\n",
      "Epoch: 102 Iteration: 72300. Train_MSE: 0.0034809475764632225. Test_MSE: 0.046943299472332\n",
      "Epoch: 103 Iteration: 72400. Train_MSE: 0.0452343113720417. Test_MSE: 0.04477532580494881\n",
      "Epoch: 103 Iteration: 72500. Train_MSE: 0.03860519081354141. Test_MSE: 0.03875796124339104\n",
      "Epoch: 103 Iteration: 72600. Train_MSE: 0.019310003146529198. Test_MSE: 0.04378347098827362\n",
      "Epoch: 103 Iteration: 72700. Train_MSE: 0.007268753834068775. Test_MSE: 0.05259700492024422\n",
      "Epoch: 103 Iteration: 72800. Train_MSE: 0.0008862980175763369. Test_MSE: 0.04220692813396454\n",
      "Epoch: 103 Iteration: 72900. Train_MSE: 0.007019014563411474. Test_MSE: 0.047812994569540024\n",
      "Epoch: 103 Iteration: 73000. Train_MSE: 0.003110248828306794. Test_MSE: 0.0472567118704319\n",
      "Epoch: 104 Iteration: 73100. Train_MSE: 0.040028974413871765. Test_MSE: 0.04502226412296295\n",
      "Epoch: 104 Iteration: 73200. Train_MSE: 0.09071710705757141. Test_MSE: 0.03826027363538742\n",
      "Epoch: 104 Iteration: 73300. Train_MSE: 0.04475240409374237. Test_MSE: 0.042064119130373\n",
      "Epoch: 104 Iteration: 73400. Train_MSE: 0.00413478771224618. Test_MSE: 0.0530080683529377\n",
      "Epoch: 104 Iteration: 73500. Train_MSE: 0.0022301331628113985. Test_MSE: 0.042553793638944626\n",
      "Epoch: 104 Iteration: 73600. Train_MSE: 0.0087809469550848. Test_MSE: 0.0481732003390789\n",
      "Epoch: 104 Iteration: 73700. Train_MSE: 0.005468182731419802. Test_MSE: 0.04756439849734306\n",
      "Epoch: 105 Iteration: 73800. Train_MSE: 0.043063558638095856. Test_MSE: 0.04638497903943062\n",
      "Epoch: 105 Iteration: 73900. Train_MSE: 0.10392320901155472. Test_MSE: 0.03882738575339317\n",
      "Epoch: 105 Iteration: 74000. Train_MSE: 0.022903908044099808. Test_MSE: 0.04067482799291611\n",
      "Epoch: 105 Iteration: 74100. Train_MSE: 0.0035296613350510597. Test_MSE: 0.0528801865875721\n",
      "Epoch: 105 Iteration: 74200. Train_MSE: 0.0027878121472895145. Test_MSE: 0.042786095291376114\n",
      "Epoch: 105 Iteration: 74300. Train_MSE: 0.0067195771262049675. Test_MSE: 0.04851953312754631\n",
      "Epoch: 105 Iteration: 74400. Train_MSE: 0.00023593090008944273. Test_MSE: 0.04716210812330246\n",
      "Epoch: 106 Iteration: 74500. Train_MSE: 0.05760457366704941. Test_MSE: 0.04828517511487007\n",
      "Epoch: 106 Iteration: 74600. Train_MSE: 0.048001937568187714. Test_MSE: 0.038811296224594116\n",
      "Epoch: 106 Iteration: 74700. Train_MSE: 0.025098612532019615. Test_MSE: 0.039318036288022995\n",
      "Epoch: 106 Iteration: 74800. Train_MSE: 0.00862979982048273. Test_MSE: 0.05303167551755905\n",
      "Epoch: 106 Iteration: 74900. Train_MSE: 0.0027605753857642412. Test_MSE: 0.042957838624715805\n",
      "Epoch: 106 Iteration: 75000. Train_MSE: 0.007788549177348614. Test_MSE: 0.04932454228401184\n",
      "Epoch: 106 Iteration: 75100. Train_MSE: 0.00039860300603322685. Test_MSE: 0.04719216749072075\n",
      "Epoch: 107 Iteration: 75200. Train_MSE: 0.07353836297988892. Test_MSE: 0.04949421435594559\n",
      "Epoch: 107 Iteration: 75300. Train_MSE: 0.07178863137960434. Test_MSE: 0.03986968472599983\n",
      "Epoch: 107 Iteration: 75400. Train_MSE: 0.05281739681959152. Test_MSE: 0.037603337317705154\n",
      "Epoch: 107 Iteration: 75500. Train_MSE: 0.002546386094763875. Test_MSE: 0.053532421588897705\n",
      "Epoch: 107 Iteration: 75600. Train_MSE: 0.005044915713369846. Test_MSE: 0.04214005172252655\n",
      "Epoch: 107 Iteration: 75700. Train_MSE: 0.010586397722363472. Test_MSE: 0.04983234778046608\n",
      "Epoch: 107 Iteration: 75800. Train_MSE: 0.0004858364991378039. Test_MSE: 0.047318894416093826\n",
      "Epoch: 108 Iteration: 75900. Train_MSE: 0.052511826157569885. Test_MSE: 0.05023280531167984\n",
      "Epoch: 108 Iteration: 76000. Train_MSE: 0.061250362545251846. Test_MSE: 0.04199483245611191\n",
      "Epoch: 108 Iteration: 76100. Train_MSE: 0.04764769226312637. Test_MSE: 0.037194959819316864\n",
      "Epoch: 108 Iteration: 76200. Train_MSE: 0.0020323945209383965. Test_MSE: 0.05373835936188698\n",
      "Epoch: 108 Iteration: 76300. Train_MSE: 0.008230555802583694. Test_MSE: 0.04265119507908821\n",
      "Epoch: 108 Iteration: 76400. Train_MSE: 0.006997657008469105. Test_MSE: 0.050014108419418335\n",
      "Epoch: 108 Iteration: 76500. Train_MSE: 0.000996068469248712. Test_MSE: 0.047081153839826584\n",
      "Epoch: 109 Iteration: 76600. Train_MSE: 0.07185386121273041. Test_MSE: 0.0500761941075325\n",
      "Epoch: 109 Iteration: 76700. Train_MSE: 0.05552935227751732. Test_MSE: 0.043998878449201584\n",
      "Epoch: 109 Iteration: 76800. Train_MSE: 0.058857496827840805. Test_MSE: 0.03692095726728439\n",
      "Epoch: 109 Iteration: 76900. Train_MSE: 0.001265347353182733. Test_MSE: 0.05334802344441414\n",
      "Epoch: 109 Iteration: 77000. Train_MSE: 0.008013544604182243. Test_MSE: 0.04298225790262222\n",
      "Epoch: 109 Iteration: 77100. Train_MSE: 0.010471365414559841. Test_MSE: 0.049751561135053635\n",
      "Epoch: 109 Iteration: 77200. Train_MSE: 0.0011682375334203243. Test_MSE: 0.04679781571030617\n",
      "Epoch: 110 Iteration: 77300. Train_MSE: 0.07414320111274719. Test_MSE: 0.049683135002851486\n",
      "Epoch: 110 Iteration: 77400. Train_MSE: 0.07751554250717163. Test_MSE: 0.04631240293383598\n",
      "Epoch: 110 Iteration: 77500. Train_MSE: 0.06728911399841309. Test_MSE: 0.03726327419281006\n",
      "Epoch: 110 Iteration: 77600. Train_MSE: 0.0004420217592269182. Test_MSE: 0.05343020707368851\n",
      "Epoch: 110 Iteration: 77700. Train_MSE: 0.006747780367732048. Test_MSE: 0.04346952959895134\n",
      "Epoch: 110 Iteration: 77800. Train_MSE: 0.013473208993673325. Test_MSE: 0.04992559179663658\n",
      "Epoch: 110 Iteration: 77900. Train_MSE: 0.002084113657474518. Test_MSE: 0.04683148115873337\n",
      "Epoch: 111 Iteration: 78000. Train_MSE: 0.056836217641830444. Test_MSE: 0.04899080842733383\n",
      "Epoch: 111 Iteration: 78100. Train_MSE: 0.05567321181297302. Test_MSE: 0.04863777384161949\n",
      "Epoch: 111 Iteration: 78200. Train_MSE: 0.06198082119226456. Test_MSE: 0.0377875454723835\n",
      "Epoch: 111 Iteration: 78300. Train_MSE: 0.0008939510444179177. Test_MSE: 0.05275243520736694\n",
      "Epoch: 111 Iteration: 78400. Train_MSE: 0.008641179651021957. Test_MSE: 0.04408663511276245\n",
      "Epoch: 111 Iteration: 78500. Train_MSE: 0.010569143109023571. Test_MSE: 0.04950927570462227\n",
      "Epoch: 111 Iteration: 78600. Train_MSE: 0.002266458235681057. Test_MSE: 0.04654905945062637\n",
      "Epoch: 112 Iteration: 78700. Train_MSE: 0.024843214079737663. Test_MSE: 0.04800286889076233\n",
      "Epoch: 112 Iteration: 78800. Train_MSE: 0.056945301592350006. Test_MSE: 0.051962293684482574\n",
      "Epoch: 112 Iteration: 78900. Train_MSE: 0.05627450346946716. Test_MSE: 0.038397569209337234\n",
      "Epoch: 112 Iteration: 79000. Train_MSE: 0.00021027600450906903. Test_MSE: 0.052895061671733856\n",
      "Epoch: 112 Iteration: 79100. Train_MSE: 0.011491945013403893. Test_MSE: 0.045418549329042435\n",
      "Epoch: 112 Iteration: 79200. Train_MSE: 0.007296381518244743. Test_MSE: 0.0484984815120697\n",
      "Epoch: 112 Iteration: 79300. Train_MSE: 0.0024208270478993654. Test_MSE: 0.04617898911237717\n",
      "Epoch: 113 Iteration: 79400. Train_MSE: 0.053516581654548645. Test_MSE: 0.04850919172167778\n",
      "Epoch: 113 Iteration: 79500. Train_MSE: 0.08108524233102798. Test_MSE: 0.055359698832035065\n",
      "Epoch: 113 Iteration: 79600. Train_MSE: 0.04077399894595146. Test_MSE: 0.03996666893362999\n",
      "Epoch: 113 Iteration: 79700. Train_MSE: 0.00030552351381629705. Test_MSE: 0.052980683743953705\n",
      "Epoch: 113 Iteration: 79800. Train_MSE: 0.012463637627661228. Test_MSE: 0.046540047973394394\n",
      "Epoch: 113 Iteration: 79900. Train_MSE: 0.01187076885253191. Test_MSE: 0.04788166657090187\n",
      "Epoch: 113 Iteration: 80000. Train_MSE: 0.0032138992100954056. Test_MSE: 0.04604635760188103\n",
      "Epoch: 114 Iteration: 80100. Train_MSE: 0.05442072078585625. Test_MSE: 0.04838186502456665\n",
      "Epoch: 114 Iteration: 80200. Train_MSE: 0.06986746937036514. Test_MSE: 0.055662449449300766\n",
      "Epoch: 114 Iteration: 80300. Train_MSE: 0.04106293246150017. Test_MSE: 0.04131361097097397\n",
      "Epoch: 114 Iteration: 80400. Train_MSE: 0.0002777987683657557. Test_MSE: 0.05262983962893486\n",
      "Epoch: 114 Iteration: 80500. Train_MSE: 0.012210347689688206. Test_MSE: 0.048416443169116974\n",
      "Epoch: 114 Iteration: 80600. Train_MSE: 0.008359846659004688. Test_MSE: 0.047009311616420746\n",
      "Epoch: 114 Iteration: 80700. Train_MSE: 0.004601356573402882. Test_MSE: 0.04522005468606949\n",
      "Epoch: 115 Iteration: 80800. Train_MSE: 0.04232947900891304. Test_MSE: 0.04913687705993652\n",
      "Epoch: 115 Iteration: 80900. Train_MSE: 0.045881930738687515. Test_MSE: 0.05512150377035141\n",
      "Epoch: 115 Iteration: 81000. Train_MSE: 0.07468405365943909. Test_MSE: 0.04316634684801102\n",
      "Epoch: 115 Iteration: 81100. Train_MSE: 0.0003038017894141376. Test_MSE: 0.05278969183564186\n",
      "Epoch: 115 Iteration: 81200. Train_MSE: 0.014804106205701828. Test_MSE: 0.049254484474658966\n",
      "Epoch: 115 Iteration: 81300. Train_MSE: 0.007643733639270067. Test_MSE: 0.047140028327703476\n",
      "Epoch: 115 Iteration: 81400. Train_MSE: 0.003697649808600545. Test_MSE: 0.045091841369867325\n",
      "Epoch: 116 Iteration: 81500. Train_MSE: 0.025810403749346733. Test_MSE: 0.048529695719480515\n",
      "Epoch: 116 Iteration: 81600. Train_MSE: 0.07252319157123566. Test_MSE: 0.05333983153104782\n",
      "Epoch: 116 Iteration: 81700. Train_MSE: 0.05316087231040001. Test_MSE: 0.04512310400605202\n",
      "Epoch: 116 Iteration: 81800. Train_MSE: 0.0004369923553895205. Test_MSE: 0.05285387113690376\n",
      "Epoch: 116 Iteration: 81900. Train_MSE: 0.01545262336730957. Test_MSE: 0.04942084476351738\n",
      "Epoch: 116 Iteration: 82000. Train_MSE: 0.01897290349006653. Test_MSE: 0.04743873327970505\n",
      "Epoch: 116 Iteration: 82100. Train_MSE: 0.004053598269820213. Test_MSE: 0.04460524767637253\n",
      "Epoch: 117 Iteration: 82200. Train_MSE: 0.03519146516919136. Test_MSE: 0.048415809869766235\n",
      "Epoch: 117 Iteration: 82300. Train_MSE: 0.05394899472594261. Test_MSE: 0.051583338528871536\n",
      "Epoch: 117 Iteration: 82400. Train_MSE: 0.0628395825624466. Test_MSE: 0.04743725061416626\n",
      "Epoch: 117 Iteration: 82500. Train_MSE: 0.0012900253059342504. Test_MSE: 0.05233516916632652\n",
      "Epoch: 117 Iteration: 82600. Train_MSE: 0.010320864617824554. Test_MSE: 0.049124717712402344\n",
      "Epoch: 117 Iteration: 82700. Train_MSE: 0.007317135110497475. Test_MSE: 0.048037536442279816\n",
      "Epoch: 117 Iteration: 82800. Train_MSE: 0.007216801866889. Test_MSE: 0.044164497405290604\n",
      "Epoch: 118 Iteration: 82900. Train_MSE: 0.02560904249548912. Test_MSE: 0.04842676967382431\n",
      "Epoch: 118 Iteration: 83000. Train_MSE: 0.051551274955272675. Test_MSE: 0.04967442527413368\n",
      "Epoch: 118 Iteration: 83100. Train_MSE: 0.0634026825428009. Test_MSE: 0.04917348548769951\n",
      "Epoch: 118 Iteration: 83200. Train_MSE: 0.0015206779353320599. Test_MSE: 0.05243859812617302\n",
      "Epoch: 118 Iteration: 83300. Train_MSE: 0.007682178169488907. Test_MSE: 0.047241516411304474\n",
      "Epoch: 118 Iteration: 83400. Train_MSE: 0.005245713982731104. Test_MSE: 0.0488087497651577\n",
      "Epoch: 118 Iteration: 83500. Train_MSE: 0.005445094779133797. Test_MSE: 0.04433475807309151\n",
      "Epoch: 119 Iteration: 83600. Train_MSE: 0.025383615866303444. Test_MSE: 0.04828426614403725\n",
      "Epoch: 119 Iteration: 83700. Train_MSE: 0.055596306920051575. Test_MSE: 0.0486326701939106\n",
      "Epoch: 119 Iteration: 83800. Train_MSE: 0.07391361147165298. Test_MSE: 0.051027994602918625\n",
      "Epoch: 119 Iteration: 83900. Train_MSE: 0.0018805320141837. Test_MSE: 0.05217752605676651\n",
      "Epoch: 119 Iteration: 84000. Train_MSE: 0.014689006842672825. Test_MSE: 0.04566196724772453\n",
      "Epoch: 119 Iteration: 84100. Train_MSE: 0.006504513788968325. Test_MSE: 0.04973319172859192\n",
      "Epoch: 119 Iteration: 84200. Train_MSE: 0.007528312038630247. Test_MSE: 0.04429413378238678\n",
      "Epoch: 120 Iteration: 84300. Train_MSE: 0.010298468172550201. Test_MSE: 0.048135410994291306\n",
      "Epoch: 120 Iteration: 84400. Train_MSE: 0.04320058971643448. Test_MSE: 0.04753939062356949\n",
      "Epoch: 120 Iteration: 84500. Train_MSE: 0.055056020617485046. Test_MSE: 0.05173496529459953\n",
      "Epoch: 120 Iteration: 84600. Train_MSE: 0.003476413432508707. Test_MSE: 0.052057020366191864\n",
      "Epoch: 120 Iteration: 84700. Train_MSE: 0.01489359512925148. Test_MSE: 0.04467688500881195\n",
      "Epoch: 120 Iteration: 84800. Train_MSE: 0.006719623692333698. Test_MSE: 0.05026933550834656\n",
      "Epoch: 120 Iteration: 84900. Train_MSE: 0.008234083652496338. Test_MSE: 0.04467496648430824\n",
      "Epoch: 121 Iteration: 85000. Train_MSE: 0.02298511564731598. Test_MSE: 0.0479295589029789\n",
      "Epoch: 121 Iteration: 85100. Train_MSE: 0.023932313546538353. Test_MSE: 0.04643893614411354\n",
      "Epoch: 121 Iteration: 85200. Train_MSE: 0.04614086076617241. Test_MSE: 0.05087045580148697\n",
      "Epoch: 121 Iteration: 85300. Train_MSE: 0.005330236628651619. Test_MSE: 0.05176892131567001\n",
      "Epoch: 121 Iteration: 85400. Train_MSE: 0.013371491804718971. Test_MSE: 0.04407680407166481\n",
      "Epoch: 121 Iteration: 85500. Train_MSE: 0.010279396548867226. Test_MSE: 0.05161244049668312\n",
      "Epoch: 121 Iteration: 85600. Train_MSE: 0.00911475159227848. Test_MSE: 0.044830773025751114\n",
      "Epoch: 122 Iteration: 85700. Train_MSE: 0.0031171024311333895. Test_MSE: 0.048158660531044006\n",
      "Epoch: 122 Iteration: 85800. Train_MSE: 0.07023318111896515. Test_MSE: 0.046189505606889725\n",
      "Epoch: 122 Iteration: 85900. Train_MSE: 0.0784672200679779. Test_MSE: 0.04897833988070488\n",
      "Epoch: 122 Iteration: 86000. Train_MSE: 0.0063579026609659195. Test_MSE: 0.051453106105327606\n",
      "Epoch: 122 Iteration: 86100. Train_MSE: 0.016322551295161247. Test_MSE: 0.04390643164515495\n",
      "Epoch: 122 Iteration: 86200. Train_MSE: 0.0056760567240417. Test_MSE: 0.051899656653404236\n",
      "Epoch: 122 Iteration: 86300. Train_MSE: 0.006797341629862785. Test_MSE: 0.04592066630721092\n",
      "Epoch: 123 Iteration: 86400. Train_MSE: 0.011471527628600597. Test_MSE: 0.04839180409908295\n",
      "Epoch: 123 Iteration: 86500. Train_MSE: 0.013654218055307865. Test_MSE: 0.04592839255928993\n",
      "Epoch: 123 Iteration: 86600. Train_MSE: 0.03438706323504448. Test_MSE: 0.04641411453485489\n",
      "Epoch: 123 Iteration: 86700. Train_MSE: 0.0037012652028352022. Test_MSE: 0.051784392446279526\n",
      "Epoch: 123 Iteration: 86800. Train_MSE: 0.002913100179284811. Test_MSE: 0.04372543841600418\n",
      "Epoch: 123 Iteration: 86900. Train_MSE: 0.007732747588306665. Test_MSE: 0.05220615863800049\n",
      "Epoch: 123 Iteration: 87000. Train_MSE: 0.008226839825510979. Test_MSE: 0.04629203677177429\n",
      "Epoch: 124 Iteration: 87100. Train_MSE: 0.0014453353360295296. Test_MSE: 0.04910473898053169\n",
      "Epoch: 124 Iteration: 87200. Train_MSE: 0.03836312144994736. Test_MSE: 0.04519850015640259\n",
      "Epoch: 124 Iteration: 87300. Train_MSE: 0.09625253081321716. Test_MSE: 0.044115204364061356\n",
      "Epoch: 124 Iteration: 87400. Train_MSE: 0.006587445270270109. Test_MSE: 0.051549799740314484\n",
      "Epoch: 124 Iteration: 87500. Train_MSE: 0.00036358527722768486. Test_MSE: 0.04372173920273781\n",
      "Epoch: 124 Iteration: 87600. Train_MSE: 0.0020124795846641064. Test_MSE: 0.05243944004178047\n",
      "Epoch: 124 Iteration: 87700. Train_MSE: 0.00791812315583229. Test_MSE: 0.046690087765455246\n",
      "Epoch: 125 Iteration: 87800. Train_MSE: 0.006603145506232977. Test_MSE: 0.049335792660713196\n",
      "Epoch: 125 Iteration: 87900. Train_MSE: 0.020964035764336586. Test_MSE: 0.04517708718776703\n",
      "Epoch: 125 Iteration: 88000. Train_MSE: 0.05312236398458481. Test_MSE: 0.042545441538095474\n",
      "Epoch: 125 Iteration: 88100. Train_MSE: 0.006935216020792723. Test_MSE: 0.050760772079229355\n",
      "Epoch: 125 Iteration: 88200. Train_MSE: 0.001260494696907699. Test_MSE: 0.04413269832730293\n",
      "Epoch: 125 Iteration: 88300. Train_MSE: 0.0013760279398411512. Test_MSE: 0.05225098133087158\n",
      "Epoch: 125 Iteration: 88400. Train_MSE: 0.009552296251058578. Test_MSE: 0.04637085646390915\n",
      "Epoch: 126 Iteration: 88500. Train_MSE: 0.005350642837584019. Test_MSE: 0.04992200806736946\n",
      "Epoch: 126 Iteration: 88600. Train_MSE: 0.013319210149347782. Test_MSE: 0.045132655650377274\n",
      "Epoch: 126 Iteration: 88700. Train_MSE: 0.0441751591861248. Test_MSE: 0.04222096502780914\n",
      "Epoch: 126 Iteration: 88800. Train_MSE: 0.012240733951330185. Test_MSE: 0.05133485049009323\n",
      "Epoch: 126 Iteration: 88900. Train_MSE: 0.00011178715794812888. Test_MSE: 0.04408580809831619\n",
      "Epoch: 126 Iteration: 89000. Train_MSE: 0.0009188050171360373. Test_MSE: 0.05218447744846344\n",
      "Epoch: 126 Iteration: 89100. Train_MSE: 0.011226228438317776. Test_MSE: 0.0454680398106575\n",
      "Epoch: 127 Iteration: 89200. Train_MSE: 0.006021207198500633. Test_MSE: 0.050243303179740906\n",
      "Epoch: 127 Iteration: 89300. Train_MSE: 0.0052366070449352264. Test_MSE: 0.04498850181698799\n",
      "Epoch: 127 Iteration: 89400. Train_MSE: 0.027535386383533478. Test_MSE: 0.0417974479496479\n",
      "Epoch: 127 Iteration: 89500. Train_MSE: 0.008710348978638649. Test_MSE: 0.05122673511505127\n",
      "Epoch: 127 Iteration: 89600. Train_MSE: 0.00019443343626335263. Test_MSE: 0.04421223700046539\n",
      "Epoch: 127 Iteration: 89700. Train_MSE: 0.0005914208013564348. Test_MSE: 0.05212239921092987\n",
      "Epoch: 127 Iteration: 89800. Train_MSE: 0.005401569418609142. Test_MSE: 0.04462098330259323\n",
      "Epoch: 128 Iteration: 89900. Train_MSE: 0.002608847338706255. Test_MSE: 0.0504411943256855\n",
      "Epoch: 128 Iteration: 90000. Train_MSE: 0.005005085375159979. Test_MSE: 0.044600773602724075\n",
      "Epoch: 128 Iteration: 90100. Train_MSE: 0.024321073666214943. Test_MSE: 0.04178371652960777\n",
      "Epoch: 128 Iteration: 90200. Train_MSE: 0.010235406458377838. Test_MSE: 0.05079809948801994\n",
      "Epoch: 128 Iteration: 90300. Train_MSE: 0.00028558660415001214. Test_MSE: 0.04446179047226906\n",
      "Epoch: 128 Iteration: 90400. Train_MSE: 0.0004913547891192138. Test_MSE: 0.05182690918445587\n",
      "Epoch: 128 Iteration: 90500. Train_MSE: 0.013362632133066654. Test_MSE: 0.043903205543756485\n",
      "Epoch: 129 Iteration: 90600. Train_MSE: 0.012947149574756622. Test_MSE: 0.05044478923082352\n",
      "Epoch: 129 Iteration: 90700. Train_MSE: 0.006967112887650728. Test_MSE: 0.04480820894241333\n",
      "Epoch: 129 Iteration: 90800. Train_MSE: 0.025622807443141937. Test_MSE: 0.04121750220656395\n",
      "Epoch: 129 Iteration: 90900. Train_MSE: 0.006513725966215134. Test_MSE: 0.050868142396211624\n",
      "Epoch: 129 Iteration: 91000. Train_MSE: 0.00027968804351985455. Test_MSE: 0.043933525681495667\n",
      "Epoch: 129 Iteration: 91100. Train_MSE: 0.0007896965835243464. Test_MSE: 0.052317921072244644\n",
      "Epoch: 129 Iteration: 91200. Train_MSE: 0.01057867519557476. Test_MSE: 0.0441359207034111\n",
      "Epoch: 130 Iteration: 91300. Train_MSE: 0.021432774141430855. Test_MSE: 0.05013459175825119\n",
      "Epoch: 130 Iteration: 91400. Train_MSE: 0.009590416215360165. Test_MSE: 0.044757112860679626\n",
      "Epoch: 130 Iteration: 91500. Train_MSE: 0.020918579772114754. Test_MSE: 0.04103974625468254\n",
      "Epoch: 130 Iteration: 91600. Train_MSE: 0.012266324833035469. Test_MSE: 0.051395539194345474\n",
      "Epoch: 130 Iteration: 91700. Train_MSE: 0.0007616807706654072. Test_MSE: 0.0442422591149807\n",
      "Epoch: 130 Iteration: 91800. Train_MSE: 0.0008349975687451661. Test_MSE: 0.05167122185230255\n",
      "Epoch: 130 Iteration: 91900. Train_MSE: 0.00900189857929945. Test_MSE: 0.044702112674713135\n",
      "Epoch: 131 Iteration: 92000. Train_MSE: 0.018176058307290077. Test_MSE: 0.05000992491841316\n",
      "Epoch: 131 Iteration: 92100. Train_MSE: 0.003564693033695221. Test_MSE: 0.04537036269903183\n",
      "Epoch: 131 Iteration: 92200. Train_MSE: 0.011238770559430122. Test_MSE: 0.04146241024136543\n",
      "Epoch: 131 Iteration: 92300. Train_MSE: 0.009230908006429672. Test_MSE: 0.05239991471171379\n",
      "Epoch: 131 Iteration: 92400. Train_MSE: 0.0007012998103164136. Test_MSE: 0.044172633439302444\n",
      "Epoch: 131 Iteration: 92500. Train_MSE: 0.0018762004328891635. Test_MSE: 0.051745373755693436\n",
      "Epoch: 131 Iteration: 92600. Train_MSE: 0.009189126081764698. Test_MSE: 0.04514990746974945\n",
      "Epoch: 132 Iteration: 92700. Train_MSE: 0.007188165560364723. Test_MSE: 0.049387432634830475\n",
      "Epoch: 132 Iteration: 92800. Train_MSE: 0.005655006039887667. Test_MSE: 0.04559091851115227\n",
      "Epoch: 132 Iteration: 92900. Train_MSE: 0.00892502162605524. Test_MSE: 0.041729219257831573\n",
      "Epoch: 132 Iteration: 93000. Train_MSE: 0.012580317445099354. Test_MSE: 0.0531892403960228\n",
      "Epoch: 132 Iteration: 93100. Train_MSE: 0.0010886781383305788. Test_MSE: 0.04401545226573944\n",
      "Epoch: 132 Iteration: 93200. Train_MSE: 0.002094102557748556. Test_MSE: 0.05139579623937607\n",
      "Epoch: 132 Iteration: 93300. Train_MSE: 0.004459158983081579. Test_MSE: 0.04584924131631851\n",
      "Epoch: 133 Iteration: 93400. Train_MSE: 0.017192229628562927. Test_MSE: 0.04805750772356987\n",
      "Epoch: 133 Iteration: 93500. Train_MSE: 0.009794133715331554. Test_MSE: 0.04591212421655655\n",
      "Epoch: 133 Iteration: 93600. Train_MSE: 0.004092851188033819. Test_MSE: 0.04176891967654228\n",
      "Epoch: 133 Iteration: 93700. Train_MSE: 0.017244433984160423. Test_MSE: 0.05396104231476784\n",
      "Epoch: 133 Iteration: 93800. Train_MSE: 0.0008351530414074659. Test_MSE: 0.04438819736242294\n",
      "Epoch: 133 Iteration: 93900. Train_MSE: 0.0011271766852587461. Test_MSE: 0.05066625401377678\n",
      "Epoch: 133 Iteration: 94000. Train_MSE: 0.017249369993805885. Test_MSE: 0.046047795563936234\n",
      "Epoch: 134 Iteration: 94100. Train_MSE: 0.03222004324197769. Test_MSE: 0.04664795473217964\n",
      "Epoch: 134 Iteration: 94200. Train_MSE: 0.005763996858149767. Test_MSE: 0.045984938740730286\n",
      "Epoch: 134 Iteration: 94300. Train_MSE: 0.005835545249283314. Test_MSE: 0.041914984583854675\n",
      "Epoch: 134 Iteration: 94400. Train_MSE: 0.013605786487460136. Test_MSE: 0.05382974073290825\n",
      "Epoch: 134 Iteration: 94500. Train_MSE: 0.0013300322461873293. Test_MSE: 0.0445135161280632\n",
      "Epoch: 134 Iteration: 94600. Train_MSE: 0.001955189276486635. Test_MSE: 0.04894840344786644\n",
      "Epoch: 134 Iteration: 94700. Train_MSE: 0.005794953089207411. Test_MSE: 0.04689330980181694\n",
      "Epoch: 135 Iteration: 94800. Train_MSE: 0.032117024064064026. Test_MSE: 0.04526133090257645\n",
      "Epoch: 135 Iteration: 94900. Train_MSE: 0.005004263482987881. Test_MSE: 0.045954760164022446\n",
      "Epoch: 135 Iteration: 95000. Train_MSE: 0.0019309784984216094. Test_MSE: 0.04200756177306175\n",
      "Epoch: 135 Iteration: 95100. Train_MSE: 0.01200693566352129. Test_MSE: 0.053642407059669495\n",
      "Epoch: 135 Iteration: 95200. Train_MSE: 0.0019657970406115055. Test_MSE: 0.045265913009643555\n",
      "Epoch: 135 Iteration: 95300. Train_MSE: 0.0017847156850621104. Test_MSE: 0.047864094376564026\n",
      "Epoch: 135 Iteration: 95400. Train_MSE: 0.004027466755360365. Test_MSE: 0.04652145504951477\n",
      "Epoch: 136 Iteration: 95500. Train_MSE: 0.05825256183743477. Test_MSE: 0.04390774667263031\n",
      "Epoch: 136 Iteration: 95600. Train_MSE: 0.00949825718998909. Test_MSE: 0.0457206666469574\n",
      "Epoch: 136 Iteration: 95700. Train_MSE: 0.010911542922258377. Test_MSE: 0.04237977787852287\n",
      "Epoch: 136 Iteration: 95800. Train_MSE: 0.018846480175852776. Test_MSE: 0.05331171303987503\n",
      "Epoch: 136 Iteration: 95900. Train_MSE: 0.0019816672429442406. Test_MSE: 0.04551832750439644\n",
      "Epoch: 136 Iteration: 96000. Train_MSE: 0.00464067654684186. Test_MSE: 0.04717998206615448\n",
      "Epoch: 136 Iteration: 96100. Train_MSE: 0.0051513672806322575. Test_MSE: 0.04644884541630745\n",
      "Epoch: 137 Iteration: 96200. Train_MSE: 0.031444624066352844. Test_MSE: 0.04275631159543991\n",
      "Epoch: 137 Iteration: 96300. Train_MSE: 0.007666670251637697. Test_MSE: 0.045727070420980453\n",
      "Epoch: 137 Iteration: 96400. Train_MSE: 0.0015314369229599833. Test_MSE: 0.04240407049655914\n",
      "Epoch: 137 Iteration: 96500. Train_MSE: 0.008993091061711311. Test_MSE: 0.05197136849164963\n",
      "Epoch: 137 Iteration: 96600. Train_MSE: 0.0029581054113805294. Test_MSE: 0.04580512270331383\n",
      "Epoch: 137 Iteration: 96700. Train_MSE: 0.005309273488819599. Test_MSE: 0.045952439308166504\n",
      "Epoch: 137 Iteration: 96800. Train_MSE: 0.0020433636382222176. Test_MSE: 0.04691708832979202\n",
      "Epoch: 138 Iteration: 96900. Train_MSE: 0.050266362726688385. Test_MSE: 0.0420989915728569\n",
      "Epoch: 138 Iteration: 97000. Train_MSE: 0.019531702622771263. Test_MSE: 0.04588859900832176\n",
      "Epoch: 138 Iteration: 97100. Train_MSE: 0.001957646105438471. Test_MSE: 0.04294389486312866\n",
      "Epoch: 138 Iteration: 97200. Train_MSE: 0.013539828360080719. Test_MSE: 0.05176165699958801\n",
      "Epoch: 138 Iteration: 97300. Train_MSE: 0.004638318903744221. Test_MSE: 0.0462162122130394\n",
      "Epoch: 138 Iteration: 97400. Train_MSE: 0.0047961752861738205. Test_MSE: 0.04450446367263794\n",
      "Epoch: 138 Iteration: 97500. Train_MSE: 0.001486850786022842. Test_MSE: 0.046814218163490295\n",
      "Epoch: 139 Iteration: 97600. Train_MSE: 0.05617276206612587. Test_MSE: 0.04079243913292885\n",
      "Epoch: 139 Iteration: 97700. Train_MSE: 0.021443627774715424. Test_MSE: 0.04531162604689598\n",
      "Epoch: 139 Iteration: 97800. Train_MSE: 0.0017683784244582057. Test_MSE: 0.04289751499891281\n",
      "Epoch: 139 Iteration: 97900. Train_MSE: 0.010987523943185806. Test_MSE: 0.05130952224135399\n",
      "Epoch: 139 Iteration: 98000. Train_MSE: 0.004036471713334322. Test_MSE: 0.046405546367168427\n",
      "Epoch: 139 Iteration: 98100. Train_MSE: 0.006970365531742573. Test_MSE: 0.0440492108464241\n",
      "Epoch: 139 Iteration: 98200. Train_MSE: 0.00023963120474945754. Test_MSE: 0.04684913158416748\n",
      "Epoch: 140 Iteration: 98300. Train_MSE: 0.08773908019065857. Test_MSE: 0.0397140309214592\n",
      "Epoch: 140 Iteration: 98400. Train_MSE: 0.02549000270664692. Test_MSE: 0.045049998909235\n",
      "Epoch: 140 Iteration: 98500. Train_MSE: 0.01320305373519659. Test_MSE: 0.042761385440826416\n",
      "Epoch: 140 Iteration: 98600. Train_MSE: 0.008390063419938087. Test_MSE: 0.050251927226781845\n",
      "Epoch: 140 Iteration: 98700. Train_MSE: 0.004056850448250771. Test_MSE: 0.046670619398355484\n",
      "Epoch: 140 Iteration: 98800. Train_MSE: 0.007851270027458668. Test_MSE: 0.04290139302611351\n",
      "Epoch: 140 Iteration: 98900. Train_MSE: 0.0003415399114601314. Test_MSE: 0.04658464342355728\n",
      "Epoch: 141 Iteration: 99000. Train_MSE: 0.05677668750286102. Test_MSE: 0.03970948979258537\n",
      "Epoch: 141 Iteration: 99100. Train_MSE: 0.0391593836247921. Test_MSE: 0.04495397210121155\n",
      "Epoch: 141 Iteration: 99200. Train_MSE: 0.011181221343576908. Test_MSE: 0.0429903082549572\n",
      "Epoch: 141 Iteration: 99300. Train_MSE: 0.00877644494175911. Test_MSE: 0.0503619946539402\n",
      "Epoch: 141 Iteration: 99400. Train_MSE: 0.007838738150894642. Test_MSE: 0.047212373465299606\n",
      "Epoch: 141 Iteration: 99500. Train_MSE: 0.009247738867998123. Test_MSE: 0.041733913123607635\n",
      "Epoch: 141 Iteration: 99600. Train_MSE: 0.0007107833516784012. Test_MSE: 0.04689507558941841\n",
      "Epoch: 142 Iteration: 99700. Train_MSE: 0.047592151910066605. Test_MSE: 0.039613138884305954\n",
      "Epoch: 142 Iteration: 99800. Train_MSE: 0.05611570179462433. Test_MSE: 0.04420415684580803\n",
      "Epoch: 142 Iteration: 99900. Train_MSE: 0.003698015818372369. Test_MSE: 0.04280734434723854\n",
      "Epoch: 142 Iteration: 100000. Train_MSE: 0.00878598727285862. Test_MSE: 0.04972073808312416\n",
      "Epoch: 142 Iteration: 100100. Train_MSE: 0.010441834107041359. Test_MSE: 0.04781410098075867\n",
      "Epoch: 142 Iteration: 100200. Train_MSE: 0.011714883148670197. Test_MSE: 0.041578494012355804\n",
      "Epoch: 142 Iteration: 100300. Train_MSE: 0.000460526323877275. Test_MSE: 0.04691050574183464\n",
      "Epoch: 143 Iteration: 100400. Train_MSE: 0.04797988012433052. Test_MSE: 0.039871323853731155\n",
      "Epoch: 143 Iteration: 100500. Train_MSE: 0.025806836783885956. Test_MSE: 0.04357563331723213\n",
      "Epoch: 143 Iteration: 100600. Train_MSE: 0.016978610306978226. Test_MSE: 0.04253949224948883\n",
      "Epoch: 143 Iteration: 100700. Train_MSE: 0.005990172736346722. Test_MSE: 0.04900854453444481\n",
      "Epoch: 143 Iteration: 100800. Train_MSE: 0.016249340027570724. Test_MSE: 0.04749458655714989\n",
      "Epoch: 143 Iteration: 100900. Train_MSE: 0.013852639123797417. Test_MSE: 0.042083848267793655\n",
      "Epoch: 143 Iteration: 101000. Train_MSE: 0.0004349927185103297. Test_MSE: 0.04692371189594269\n",
      "Epoch: 144 Iteration: 101100. Train_MSE: 0.04897572472691536. Test_MSE: 0.040973372757434845\n",
      "Epoch: 144 Iteration: 101200. Train_MSE: 0.03165791183710098. Test_MSE: 0.04263884946703911\n",
      "Epoch: 144 Iteration: 101300. Train_MSE: 0.02829659730195999. Test_MSE: 0.04224967211484909\n",
      "Epoch: 144 Iteration: 101400. Train_MSE: 0.006920356769114733. Test_MSE: 0.0480085089802742\n",
      "Epoch: 144 Iteration: 101500. Train_MSE: 0.011243436485528946. Test_MSE: 0.047617729753255844\n",
      "Epoch: 144 Iteration: 101600. Train_MSE: 0.0057942247949540615. Test_MSE: 0.04134712368249893\n",
      "Epoch: 144 Iteration: 101700. Train_MSE: 0.0009347213199362159. Test_MSE: 0.0468422956764698\n",
      "Epoch: 145 Iteration: 101800. Train_MSE: 0.07407250255346298. Test_MSE: 0.04286679998040199\n",
      "Epoch: 145 Iteration: 101900. Train_MSE: 0.05099315568804741. Test_MSE: 0.041981566697359085\n",
      "Epoch: 145 Iteration: 102000. Train_MSE: 0.01990470103919506. Test_MSE: 0.04180149361491203\n",
      "Epoch: 145 Iteration: 102100. Train_MSE: 0.004363393411040306. Test_MSE: 0.04756763204932213\n",
      "Epoch: 145 Iteration: 102200. Train_MSE: 0.00895080715417862. Test_MSE: 0.04697816073894501\n",
      "Epoch: 145 Iteration: 102300. Train_MSE: 0.003751134965568781. Test_MSE: 0.04163273423910141\n",
      "Epoch: 145 Iteration: 102400. Train_MSE: 0.0008871899335645139. Test_MSE: 0.046788062900304794\n",
      "Epoch: 146 Iteration: 102500. Train_MSE: 0.047540150582790375. Test_MSE: 0.04456387832760811\n",
      "Epoch: 146 Iteration: 102600. Train_MSE: 0.046047791838645935. Test_MSE: 0.04175936430692673\n",
      "Epoch: 146 Iteration: 102700. Train_MSE: 0.0210195854306221. Test_MSE: 0.04174099490046501\n",
      "Epoch: 146 Iteration: 102800. Train_MSE: 0.004365994594991207. Test_MSE: 0.04697804152965546\n",
      "Epoch: 146 Iteration: 102900. Train_MSE: 0.01400273758918047. Test_MSE: 0.04567120969295502\n",
      "Epoch: 146 Iteration: 103000. Train_MSE: 0.002794319996610284. Test_MSE: 0.0425516739487648\n",
      "Epoch: 146 Iteration: 103100. Train_MSE: 0.001067834091372788. Test_MSE: 0.04720659926533699\n",
      "Epoch: 147 Iteration: 103200. Train_MSE: 0.12874479591846466. Test_MSE: 0.04560288041830063\n",
      "Epoch: 147 Iteration: 103300. Train_MSE: 0.04598306491971016. Test_MSE: 0.04165121912956238\n",
      "Epoch: 147 Iteration: 103400. Train_MSE: 0.029352853074669838. Test_MSE: 0.041294269263744354\n",
      "Epoch: 147 Iteration: 103500. Train_MSE: 0.003619353286921978. Test_MSE: 0.04633421450853348\n",
      "Epoch: 147 Iteration: 103600. Train_MSE: 0.00988265872001648. Test_MSE: 0.04556044191122055\n",
      "Epoch: 147 Iteration: 103700. Train_MSE: 0.0015849943738430738. Test_MSE: 0.0419514998793602\n",
      "Epoch: 147 Iteration: 103800. Train_MSE: 0.001483769970946014. Test_MSE: 0.047053150832653046\n",
      "Epoch: 148 Iteration: 103900. Train_MSE: 0.06189218536019325. Test_MSE: 0.045975349843502045\n",
      "Epoch: 148 Iteration: 104000. Train_MSE: 0.04547231271862984. Test_MSE: 0.041742708534002304\n",
      "Epoch: 148 Iteration: 104100. Train_MSE: 0.03635323420166969. Test_MSE: 0.04064636304974556\n",
      "Epoch: 148 Iteration: 104200. Train_MSE: 0.004141347017139196. Test_MSE: 0.04541979730129242\n",
      "Epoch: 148 Iteration: 104300. Train_MSE: 0.014938902109861374. Test_MSE: 0.045514024794101715\n",
      "Epoch: 148 Iteration: 104400. Train_MSE: 0.001009440398775041. Test_MSE: 0.042076848447322845\n",
      "Epoch: 148 Iteration: 104500. Train_MSE: 0.0015379495453089476. Test_MSE: 0.04681937396526337\n",
      "Epoch: 149 Iteration: 104600. Train_MSE: 0.057658787816762924. Test_MSE: 0.04595113545656204\n",
      "Epoch: 149 Iteration: 104700. Train_MSE: 0.07199154049158096. Test_MSE: 0.04285160079598427\n",
      "Epoch: 149 Iteration: 104800. Train_MSE: 0.037764277309179306. Test_MSE: 0.040091171860694885\n",
      "Epoch: 149 Iteration: 104900. Train_MSE: 0.0007800632156431675. Test_MSE: 0.0452323853969574\n",
      "Epoch: 149 Iteration: 105000. Train_MSE: 0.014737932942807674. Test_MSE: 0.046645622700452805\n",
      "Epoch: 149 Iteration: 105100. Train_MSE: 0.0004905489622615278. Test_MSE: 0.042181193828582764\n",
      "Epoch: 149 Iteration: 105200. Train_MSE: 0.0032650900539010763. Test_MSE: 0.04738098010420799\n",
      "Epoch: 149 Iteration: 105300. Train_MSE: 0.006079464685171843. Test_MSE: 0.046242885291576385\n",
      "Epoch: 150 Iteration: 105400. Train_MSE: 0.05643382668495178. Test_MSE: 0.04319332167506218\n",
      "Epoch: 150 Iteration: 105500. Train_MSE: 0.029346276074647903. Test_MSE: 0.039404552429914474\n",
      "Epoch: 150 Iteration: 105600. Train_MSE: 0.0010635637445375323. Test_MSE: 0.044443801045417786\n",
      "Epoch: 150 Iteration: 105700. Train_MSE: 0.011212929151952267. Test_MSE: 0.04733917862176895\n",
      "Epoch: 150 Iteration: 105800. Train_MSE: 0.0005818481440655887. Test_MSE: 0.04228401556611061\n",
      "Epoch: 150 Iteration: 105900. Train_MSE: 0.0037045329809188843. Test_MSE: 0.04732150956988335\n",
      "Epoch: 150 Iteration: 106000. Train_MSE: 0.01398540660738945. Test_MSE: 0.04627390578389168\n",
      "Epoch: 151 Iteration: 106100. Train_MSE: 0.07054207473993301. Test_MSE: 0.04356366768479347\n",
      "Epoch: 151 Iteration: 106200. Train_MSE: 0.05509290099143982. Test_MSE: 0.03900540992617607\n",
      "Epoch: 151 Iteration: 106300. Train_MSE: 0.0027417936362326145. Test_MSE: 0.043589409440755844\n",
      "Epoch: 151 Iteration: 106400. Train_MSE: 0.010311531834304333. Test_MSE: 0.048476263880729675\n",
      "Epoch: 151 Iteration: 106500. Train_MSE: 0.000925508385989815. Test_MSE: 0.0422939769923687\n",
      "Epoch: 151 Iteration: 106600. Train_MSE: 0.004594525322318077. Test_MSE: 0.04689021781086922\n",
      "Epoch: 151 Iteration: 106700. Train_MSE: 0.005003003869205713. Test_MSE: 0.046667054295539856\n",
      "Epoch: 152 Iteration: 106800. Train_MSE: 0.08395379781723022. Test_MSE: 0.043681465089321136\n",
      "Epoch: 152 Iteration: 106900. Train_MSE: 0.044807735830545425. Test_MSE: 0.038747627288103104\n",
      "Epoch: 152 Iteration: 107000. Train_MSE: 0.01929187774658203. Test_MSE: 0.04275195673108101\n",
      "Epoch: 152 Iteration: 107100. Train_MSE: 0.00893324799835682. Test_MSE: 0.04947958514094353\n",
      "Epoch: 152 Iteration: 107200. Train_MSE: 0.0010001291520893574. Test_MSE: 0.04257350042462349\n",
      "Epoch: 152 Iteration: 107300. Train_MSE: 0.007756355218589306. Test_MSE: 0.0469045527279377\n",
      "Epoch: 152 Iteration: 107400. Train_MSE: 0.0031895837746560574. Test_MSE: 0.046618107706308365\n",
      "Epoch: 153 Iteration: 107500. Train_MSE: 0.0478048101067543. Test_MSE: 0.044147927314043045\n",
      "Epoch: 153 Iteration: 107600. Train_MSE: 0.03769180178642273. Test_MSE: 0.03840503841638565\n",
      "Epoch: 153 Iteration: 107700. Train_MSE: 0.01947566494345665. Test_MSE: 0.042119625955820084\n",
      "Epoch: 153 Iteration: 107800. Train_MSE: 0.0072839464992284775. Test_MSE: 0.050126731395721436\n",
      "Epoch: 153 Iteration: 107900. Train_MSE: 0.0010152214672416449. Test_MSE: 0.04246172681450844\n",
      "Epoch: 153 Iteration: 108000. Train_MSE: 0.006850948557257652. Test_MSE: 0.046859972178936005\n",
      "Epoch: 153 Iteration: 108100. Train_MSE: 0.0029339033644646406. Test_MSE: 0.04696011543273926\n",
      "Epoch: 154 Iteration: 108200. Train_MSE: 0.04047714173793793. Test_MSE: 0.04424598440527916\n",
      "Epoch: 154 Iteration: 108300. Train_MSE: 0.0916677936911583. Test_MSE: 0.03857452794909477\n",
      "Epoch: 154 Iteration: 108400. Train_MSE: 0.04545530304312706. Test_MSE: 0.040884241461753845\n",
      "Epoch: 154 Iteration: 108500. Train_MSE: 0.004161512479186058. Test_MSE: 0.05140722170472145\n",
      "Epoch: 154 Iteration: 108600. Train_MSE: 0.001837038667872548. Test_MSE: 0.042260654270648956\n",
      "Epoch: 154 Iteration: 108700. Train_MSE: 0.008473703637719154. Test_MSE: 0.047054942697286606\n",
      "Epoch: 154 Iteration: 108800. Train_MSE: 0.005571229849010706. Test_MSE: 0.04682385176420212\n",
      "Epoch: 155 Iteration: 108900. Train_MSE: 0.041749369353055954. Test_MSE: 0.04552796110510826\n",
      "Epoch: 155 Iteration: 109000. Train_MSE: 0.10286080092191696. Test_MSE: 0.03922277316451073\n",
      "Epoch: 155 Iteration: 109100. Train_MSE: 0.022705333307385445. Test_MSE: 0.03973911702632904\n",
      "Epoch: 155 Iteration: 109200. Train_MSE: 0.0037452224642038345. Test_MSE: 0.051352452486753464\n",
      "Epoch: 155 Iteration: 109300. Train_MSE: 0.0025961461942642927. Test_MSE: 0.04247604310512543\n",
      "Epoch: 155 Iteration: 109400. Train_MSE: 0.00666863564401865. Test_MSE: 0.0477156788110733\n",
      "Epoch: 155 Iteration: 109500. Train_MSE: 0.0004220081609673798. Test_MSE: 0.046539679169654846\n",
      "Epoch: 156 Iteration: 109600. Train_MSE: 0.05372121185064316. Test_MSE: 0.047088898718357086\n",
      "Epoch: 156 Iteration: 109700. Train_MSE: 0.044894639402627945. Test_MSE: 0.03979099541902542\n",
      "Epoch: 156 Iteration: 109800. Train_MSE: 0.02598840929567814. Test_MSE: 0.03841327130794525\n",
      "Epoch: 156 Iteration: 109900. Train_MSE: 0.008506836369633675. Test_MSE: 0.05114775896072388\n",
      "Epoch: 156 Iteration: 110000. Train_MSE: 0.002903719898313284. Test_MSE: 0.0423409603536129\n",
      "Epoch: 156 Iteration: 110100. Train_MSE: 0.007858620025217533. Test_MSE: 0.048223454505205154\n",
      "Epoch: 156 Iteration: 110200. Train_MSE: 0.0006299001979641616. Test_MSE: 0.04699042811989784\n",
      "Epoch: 157 Iteration: 110300. Train_MSE: 0.07314138859510422. Test_MSE: 0.04906989634037018\n",
      "Epoch: 157 Iteration: 110400. Train_MSE: 0.07237475365400314. Test_MSE: 0.040921371430158615\n",
      "Epoch: 157 Iteration: 110500. Train_MSE: 0.052489012479782104. Test_MSE: 0.03723633661866188\n",
      "Epoch: 157 Iteration: 110600. Train_MSE: 0.0024455590173602104. Test_MSE: 0.0516279861330986\n",
      "Epoch: 157 Iteration: 110700. Train_MSE: 0.004778084345161915. Test_MSE: 0.04258907958865166\n",
      "Epoch: 157 Iteration: 110800. Train_MSE: 0.010525219142436981. Test_MSE: 0.048406049609184265\n",
      "Epoch: 157 Iteration: 110900. Train_MSE: 0.0009249422000721097. Test_MSE: 0.046780988574028015\n",
      "Epoch: 158 Iteration: 111000. Train_MSE: 0.052737198770046234. Test_MSE: 0.04998449981212616\n",
      "Epoch: 158 Iteration: 111100. Train_MSE: 0.06315642595291138. Test_MSE: 0.042629674077034\n",
      "Epoch: 158 Iteration: 111200. Train_MSE: 0.04791912063956261. Test_MSE: 0.0366816408932209\n",
      "Epoch: 158 Iteration: 111300. Train_MSE: 0.0020906610880047083. Test_MSE: 0.05152970552444458\n",
      "Epoch: 158 Iteration: 111400. Train_MSE: 0.008670809678733349. Test_MSE: 0.0424194410443306\n",
      "Epoch: 158 Iteration: 111500. Train_MSE: 0.007202808745205402. Test_MSE: 0.04841165617108345\n",
      "Epoch: 158 Iteration: 111600. Train_MSE: 0.0008901249384507537. Test_MSE: 0.04683142527937889\n",
      "Epoch: 159 Iteration: 111700. Train_MSE: 0.07174669951200485. Test_MSE: 0.04978090897202492\n",
      "Epoch: 159 Iteration: 111800. Train_MSE: 0.056116677820682526. Test_MSE: 0.04416976496577263\n",
      "Epoch: 159 Iteration: 111900. Train_MSE: 0.06025855243206024. Test_MSE: 0.036862049251794815\n",
      "Epoch: 159 Iteration: 112000. Train_MSE: 0.0012037125416100025. Test_MSE: 0.05132386460900307\n",
      "Epoch: 159 Iteration: 112100. Train_MSE: 0.008420542813837528. Test_MSE: 0.04282175749540329\n",
      "Epoch: 159 Iteration: 112200. Train_MSE: 0.010545237921178341. Test_MSE: 0.048708561807870865\n",
      "Epoch: 159 Iteration: 112300. Train_MSE: 0.001034927787259221. Test_MSE: 0.04633864015340805\n",
      "Epoch: 160 Iteration: 112400. Train_MSE: 0.07303602993488312. Test_MSE: 0.04954654723405838\n",
      "Epoch: 160 Iteration: 112500. Train_MSE: 0.07571914792060852. Test_MSE: 0.04648234695196152\n",
      "Epoch: 160 Iteration: 112600. Train_MSE: 0.06694915890693665. Test_MSE: 0.03730921819806099\n",
      "Epoch: 160 Iteration: 112700. Train_MSE: 0.0004889697884209454. Test_MSE: 0.05104658752679825\n",
      "Epoch: 160 Iteration: 112800. Train_MSE: 0.006819672416895628. Test_MSE: 0.04331551492214203\n",
      "Epoch: 160 Iteration: 112900. Train_MSE: 0.013216611929237843. Test_MSE: 0.04818755015730858\n",
      "Epoch: 160 Iteration: 113000. Train_MSE: 0.0018601688789203763. Test_MSE: 0.046441931277513504\n",
      "Epoch: 161 Iteration: 113100. Train_MSE: 0.05690748617053032. Test_MSE: 0.04923637956380844\n",
      "Epoch: 161 Iteration: 113200. Train_MSE: 0.05557574704289436. Test_MSE: 0.04881904274225235\n",
      "Epoch: 161 Iteration: 113300. Train_MSE: 0.06152232736349106. Test_MSE: 0.03795294836163521\n",
      "Epoch: 161 Iteration: 113400. Train_MSE: 0.0005376331391744316. Test_MSE: 0.05135447531938553\n",
      "Epoch: 161 Iteration: 113500. Train_MSE: 0.008670229464769363. Test_MSE: 0.04394661262631416\n",
      "Epoch: 161 Iteration: 113600. Train_MSE: 0.010467099025845528. Test_MSE: 0.047592103481292725\n",
      "Epoch: 161 Iteration: 113700. Train_MSE: 0.0023286365903913975. Test_MSE: 0.04562787339091301\n",
      "Epoch: 162 Iteration: 113800. Train_MSE: 0.026120442897081375. Test_MSE: 0.048826664686203\n",
      "Epoch: 162 Iteration: 113900. Train_MSE: 0.05319088324904442. Test_MSE: 0.051209110766649246\n",
      "Epoch: 162 Iteration: 114000. Train_MSE: 0.055766161531209946. Test_MSE: 0.03856373950839043\n",
      "Epoch: 162 Iteration: 114100. Train_MSE: 0.0003484426415525377. Test_MSE: 0.05092080682516098\n",
      "Epoch: 162 Iteration: 114200. Train_MSE: 0.01133963093161583. Test_MSE: 0.04510797560214996\n",
      "Epoch: 162 Iteration: 114300. Train_MSE: 0.007055072579532862. Test_MSE: 0.04663814604282379\n",
      "Epoch: 162 Iteration: 114400. Train_MSE: 0.0024871467612683773. Test_MSE: 0.045546092092990875\n",
      "Epoch: 163 Iteration: 114500. Train_MSE: 0.05160735920071602. Test_MSE: 0.048936523497104645\n",
      "Epoch: 163 Iteration: 114600. Train_MSE: 0.077796570956707. Test_MSE: 0.05348534509539604\n",
      "Epoch: 163 Iteration: 114700. Train_MSE: 0.04094995558261871. Test_MSE: 0.03984178602695465\n",
      "Epoch: 163 Iteration: 114800. Train_MSE: 0.0005236460128799081. Test_MSE: 0.05076228082180023\n",
      "Epoch: 163 Iteration: 114900. Train_MSE: 0.011990321800112724. Test_MSE: 0.04574136808514595\n",
      "Epoch: 163 Iteration: 115000. Train_MSE: 0.011512422934174538. Test_MSE: 0.04648755118250847\n",
      "Epoch: 163 Iteration: 115100. Train_MSE: 0.0027500642463564873. Test_MSE: 0.04516507685184479\n",
      "Epoch: 164 Iteration: 115200. Train_MSE: 0.05176525563001633. Test_MSE: 0.04847683757543564\n",
      "Epoch: 164 Iteration: 115300. Train_MSE: 0.06785622239112854. Test_MSE: 0.05441960319876671\n",
      "Epoch: 164 Iteration: 115400. Train_MSE: 0.04063840210437775. Test_MSE: 0.04153253138065338\n",
      "Epoch: 164 Iteration: 115500. Train_MSE: 0.00019538257038220763. Test_MSE: 0.05075185000896454\n",
      "Epoch: 164 Iteration: 115600. Train_MSE: 0.012449214234948158. Test_MSE: 0.04796181246638298\n",
      "Epoch: 164 Iteration: 115700. Train_MSE: 0.00862033199518919. Test_MSE: 0.04594385251402855\n",
      "Epoch: 164 Iteration: 115800. Train_MSE: 0.004435379523783922. Test_MSE: 0.04481145739555359\n",
      "Epoch: 165 Iteration: 115900. Train_MSE: 0.04015045613050461. Test_MSE: 0.048481058329343796\n",
      "Epoch: 165 Iteration: 116000. Train_MSE: 0.04600723832845688. Test_MSE: 0.05375474691390991\n",
      "Epoch: 165 Iteration: 116100. Train_MSE: 0.07485868781805038. Test_MSE: 0.04308197274804115\n",
      "Epoch: 165 Iteration: 116200. Train_MSE: 0.00038928401772864163. Test_MSE: 0.051057033240795135\n",
      "Epoch: 165 Iteration: 116300. Train_MSE: 0.014344047755002975. Test_MSE: 0.04852411895990372\n",
      "Epoch: 165 Iteration: 116400. Train_MSE: 0.007540688384324312. Test_MSE: 0.046300385147333145\n",
      "Epoch: 165 Iteration: 116500. Train_MSE: 0.0039563607424497604. Test_MSE: 0.045128077268600464\n",
      "Epoch: 166 Iteration: 116600. Train_MSE: 0.02527349628508091. Test_MSE: 0.04816177487373352\n",
      "Epoch: 166 Iteration: 116700. Train_MSE: 0.07329317182302475. Test_MSE: 0.05202990025281906\n",
      "Epoch: 166 Iteration: 116800. Train_MSE: 0.05165927857160568. Test_MSE: 0.04495886713266373\n",
      "Epoch: 166 Iteration: 116900. Train_MSE: 0.0004262002476025373. Test_MSE: 0.0510958731174469\n",
      "Epoch: 166 Iteration: 117000. Train_MSE: 0.015418737195432186. Test_MSE: 0.04880830645561218\n",
      "Epoch: 166 Iteration: 117100. Train_MSE: 0.019556811079382896. Test_MSE: 0.04705755040049553\n",
      "Epoch: 166 Iteration: 117200. Train_MSE: 0.003946322947740555. Test_MSE: 0.044714149087667465\n",
      "Epoch: 167 Iteration: 117300. Train_MSE: 0.035216547548770905. Test_MSE: 0.048371970653533936\n",
      "Epoch: 167 Iteration: 117400. Train_MSE: 0.05356890708208084. Test_MSE: 0.050377920269966125\n",
      "Epoch: 167 Iteration: 117500. Train_MSE: 0.06279661506414413. Test_MSE: 0.04709971323609352\n",
      "Epoch: 167 Iteration: 117600. Train_MSE: 0.0014281865442171693. Test_MSE: 0.05076228454709053\n",
      "Epoch: 167 Iteration: 117700. Train_MSE: 0.009877180680632591. Test_MSE: 0.047846052795648575\n",
      "Epoch: 167 Iteration: 117800. Train_MSE: 0.007593450136482716. Test_MSE: 0.04763957858085632\n",
      "Epoch: 167 Iteration: 117900. Train_MSE: 0.007057698909193277. Test_MSE: 0.043919045478105545\n",
      "Epoch: 168 Iteration: 118000. Train_MSE: 0.02262229472398758. Test_MSE: 0.04831328243017197\n",
      "Epoch: 168 Iteration: 118100. Train_MSE: 0.04929739981889725. Test_MSE: 0.04897074028849602\n",
      "Epoch: 168 Iteration: 118200. Train_MSE: 0.060269009321928024. Test_MSE: 0.04839123412966728\n",
      "Epoch: 168 Iteration: 118300. Train_MSE: 0.0014871221501380205. Test_MSE: 0.050905000418424606\n",
      "Epoch: 168 Iteration: 118400. Train_MSE: 0.008020782843232155. Test_MSE: 0.046372052282094955\n",
      "Epoch: 168 Iteration: 118500. Train_MSE: 0.005332071799784899. Test_MSE: 0.047966230660676956\n",
      "Epoch: 168 Iteration: 118600. Train_MSE: 0.005528176203370094. Test_MSE: 0.0440959669649601\n",
      "Epoch: 169 Iteration: 118700. Train_MSE: 0.02909131534397602. Test_MSE: 0.047995343804359436\n",
      "Epoch: 169 Iteration: 118800. Train_MSE: 0.055158477276563644. Test_MSE: 0.048079539090394974\n",
      "Epoch: 169 Iteration: 118900. Train_MSE: 0.07332824915647507. Test_MSE: 0.04954519122838974\n",
      "Epoch: 169 Iteration: 119000. Train_MSE: 0.0017808112315833569. Test_MSE: 0.05064468830823898\n",
      "Epoch: 169 Iteration: 119100. Train_MSE: 0.014133954420685768. Test_MSE: 0.04503679275512695\n",
      "Epoch: 169 Iteration: 119200. Train_MSE: 0.00629915576428175. Test_MSE: 0.04896000772714615\n",
      "Epoch: 169 Iteration: 119300. Train_MSE: 0.007481457199901342. Test_MSE: 0.043625444173812866\n",
      "Epoch: 170 Iteration: 119400. Train_MSE: 0.007025494705885649. Test_MSE: 0.047735296189785004\n",
      "Epoch: 170 Iteration: 119500. Train_MSE: 0.03901960328221321. Test_MSE: 0.04715363308787346\n",
      "Epoch: 170 Iteration: 119600. Train_MSE: 0.05436989665031433. Test_MSE: 0.04952320083975792\n",
      "Epoch: 170 Iteration: 119700. Train_MSE: 0.003297545714303851. Test_MSE: 0.050646860152482986\n",
      "Epoch: 170 Iteration: 119800. Train_MSE: 0.014697405509650707. Test_MSE: 0.04381576552987099\n",
      "Epoch: 170 Iteration: 119900. Train_MSE: 0.0065765343606472015. Test_MSE: 0.049853261560201645\n",
      "Epoch: 170 Iteration: 120000. Train_MSE: 0.008474008180201054. Test_MSE: 0.043974678963422775\n",
      "Epoch: 171 Iteration: 120100. Train_MSE: 0.024336833506822586. Test_MSE: 0.0478934682905674\n",
      "Epoch: 171 Iteration: 120200. Train_MSE: 0.023974770680069923. Test_MSE: 0.046435508877038956\n",
      "Epoch: 171 Iteration: 120300. Train_MSE: 0.04514444246888161. Test_MSE: 0.04929149150848389\n",
      "Epoch: 171 Iteration: 120400. Train_MSE: 0.005196784157305956. Test_MSE: 0.04994833096861839\n",
      "Epoch: 171 Iteration: 120500. Train_MSE: 0.013121264986693859. Test_MSE: 0.04316636174917221\n",
      "Epoch: 171 Iteration: 120600. Train_MSE: 0.010341240093111992. Test_MSE: 0.05074133351445198\n",
      "Epoch: 171 Iteration: 120700. Train_MSE: 0.009168732911348343. Test_MSE: 0.044164564460515976\n",
      "Epoch: 172 Iteration: 120800. Train_MSE: 0.00289526698179543. Test_MSE: 0.04796290770173073\n",
      "Epoch: 172 Iteration: 120900. Train_MSE: 0.06099677085876465. Test_MSE: 0.04576822370290756\n",
      "Epoch: 172 Iteration: 121000. Train_MSE: 0.08080043643712997. Test_MSE: 0.047399211674928665\n",
      "Epoch: 172 Iteration: 121100. Train_MSE: 0.005965458229184151. Test_MSE: 0.04979114234447479\n",
      "Epoch: 172 Iteration: 121200. Train_MSE: 0.016435988247394562. Test_MSE: 0.04337366297841072\n",
      "Epoch: 172 Iteration: 121300. Train_MSE: 0.005849338602274656. Test_MSE: 0.05128718167543411\n",
      "Epoch: 172 Iteration: 121400. Train_MSE: 0.006957559380680323. Test_MSE: 0.0449371337890625\n",
      "Epoch: 173 Iteration: 121500. Train_MSE: 0.010439377278089523. Test_MSE: 0.04815281927585602\n",
      "Epoch: 173 Iteration: 121600. Train_MSE: 0.014171915128827095. Test_MSE: 0.045513641089200974\n",
      "Epoch: 173 Iteration: 121700. Train_MSE: 0.03588526323437691. Test_MSE: 0.04478628933429718\n",
      "Epoch: 173 Iteration: 121800. Train_MSE: 0.0038510041777044535. Test_MSE: 0.04971906915307045\n",
      "Epoch: 173 Iteration: 121900. Train_MSE: 0.0031506652012467384. Test_MSE: 0.04316706955432892\n",
      "Epoch: 173 Iteration: 122000. Train_MSE: 0.0076184649951756. Test_MSE: 0.05147407203912735\n",
      "Epoch: 173 Iteration: 122100. Train_MSE: 0.007742017507553101. Test_MSE: 0.045314837247133255\n",
      "Epoch: 174 Iteration: 122200. Train_MSE: 0.0012530680978670716. Test_MSE: 0.048439931124448776\n",
      "Epoch: 174 Iteration: 122300. Train_MSE: 0.03691261261701584. Test_MSE: 0.04507393762469292\n",
      "Epoch: 174 Iteration: 122400. Train_MSE: 0.09698671102523804. Test_MSE: 0.04286174476146698\n",
      "Epoch: 174 Iteration: 122500. Train_MSE: 0.006333975121378899. Test_MSE: 0.049969080835580826\n",
      "Epoch: 174 Iteration: 122600. Train_MSE: 5.12819315190427e-05. Test_MSE: 0.04360448569059372\n",
      "Epoch: 174 Iteration: 122700. Train_MSE: 0.00198147795163095. Test_MSE: 0.05160847306251526\n",
      "Epoch: 174 Iteration: 122800. Train_MSE: 0.007870535366237164. Test_MSE: 0.04549148678779602\n",
      "Epoch: 175 Iteration: 122900. Train_MSE: 0.006652479059994221. Test_MSE: 0.048851244151592255\n",
      "Epoch: 175 Iteration: 123000. Train_MSE: 0.02132258005440235. Test_MSE: 0.044451259076595306\n",
      "Epoch: 175 Iteration: 123100. Train_MSE: 0.0550386868417263. Test_MSE: 0.04165330529212952\n",
      "Epoch: 175 Iteration: 123200. Train_MSE: 0.006985472049564123. Test_MSE: 0.049661409109830856\n",
      "Epoch: 175 Iteration: 123300. Train_MSE: 0.0012547981459647417. Test_MSE: 0.04293878749012947\n",
      "Epoch: 175 Iteration: 123400. Train_MSE: 0.0013995836488902569. Test_MSE: 0.05097566545009613\n",
      "Epoch: 175 Iteration: 123500. Train_MSE: 0.00929270125925541. Test_MSE: 0.044650714844465256\n",
      "Epoch: 176 Iteration: 123600. Train_MSE: 0.004765297286212444. Test_MSE: 0.049032051116228104\n",
      "Epoch: 176 Iteration: 123700. Train_MSE: 0.011369500309228897. Test_MSE: 0.04429580643773079\n",
      "Epoch: 176 Iteration: 123800. Train_MSE: 0.04658040031790733. Test_MSE: 0.041252877563238144\n",
      "Epoch: 176 Iteration: 123900. Train_MSE: 0.011890708468854427. Test_MSE: 0.04991829767823219\n",
      "Epoch: 176 Iteration: 124000. Train_MSE: 0.00025843543699011207. Test_MSE: 0.04337381199002266\n",
      "Epoch: 176 Iteration: 124100. Train_MSE: 0.0012737670913338661. Test_MSE: 0.05132220312952995\n",
      "Epoch: 176 Iteration: 124200. Train_MSE: 0.011377444490790367. Test_MSE: 0.04415940120816231\n",
      "Epoch: 177 Iteration: 124300. Train_MSE: 0.005769661627709866. Test_MSE: 0.04948044940829277\n",
      "Epoch: 177 Iteration: 124400. Train_MSE: 0.005632634274661541. Test_MSE: 0.044433411210775375\n",
      "Epoch: 177 Iteration: 124500. Train_MSE: 0.026505902409553528. Test_MSE: 0.04133571311831474\n",
      "Epoch: 177 Iteration: 124600. Train_MSE: 0.008776318281888962. Test_MSE: 0.04986417293548584\n",
      "Epoch: 177 Iteration: 124700. Train_MSE: 0.00017972270143218338. Test_MSE: 0.04298519715666771\n",
      "Epoch: 177 Iteration: 124800. Train_MSE: 0.0009293351322412491. Test_MSE: 0.051486872136592865\n",
      "Epoch: 177 Iteration: 124900. Train_MSE: 0.005537146702408791. Test_MSE: 0.043354447931051254\n",
      "Epoch: 178 Iteration: 125000. Train_MSE: 0.0027825983706861734. Test_MSE: 0.049850452691316605\n",
      "Epoch: 178 Iteration: 125100. Train_MSE: 0.004941433668136597. Test_MSE: 0.04434247314929962\n",
      "Epoch: 178 Iteration: 125200. Train_MSE: 0.023424627259373665. Test_MSE: 0.04149327799677849\n",
      "Epoch: 178 Iteration: 125300. Train_MSE: 0.010342882946133614. Test_MSE: 0.049552254378795624\n",
      "Epoch: 178 Iteration: 125400. Train_MSE: 0.0001980039814952761. Test_MSE: 0.043469615280628204\n",
      "Epoch: 178 Iteration: 125500. Train_MSE: 0.0006001995643600821. Test_MSE: 0.051287390291690826\n",
      "Epoch: 178 Iteration: 125600. Train_MSE: 0.012902983464300632. Test_MSE: 0.043268702924251556\n",
      "Epoch: 179 Iteration: 125700. Train_MSE: 0.013099920004606247. Test_MSE: 0.05006328597664833\n",
      "Epoch: 179 Iteration: 125800. Train_MSE: 0.0074556381441652775. Test_MSE: 0.044354163110256195\n",
      "Epoch: 179 Iteration: 125900. Train_MSE: 0.023756641894578934. Test_MSE: 0.04127663001418114\n",
      "Epoch: 179 Iteration: 126000. Train_MSE: 0.006379460915923119. Test_MSE: 0.05012965574860573\n",
      "Epoch: 179 Iteration: 126100. Train_MSE: 0.0005534354131668806. Test_MSE: 0.04338322579860687\n",
      "Epoch: 179 Iteration: 126200. Train_MSE: 0.0005022362456656992. Test_MSE: 0.051435258239507675\n",
      "Epoch: 179 Iteration: 126300. Train_MSE: 0.010106678120791912. Test_MSE: 0.043345093727111816\n",
      "Epoch: 180 Iteration: 126400. Train_MSE: 0.021083448082208633. Test_MSE: 0.049390558153390884\n",
      "Epoch: 180 Iteration: 126500. Train_MSE: 0.009965861216187477. Test_MSE: 0.044263288378715515\n",
      "Epoch: 180 Iteration: 126600. Train_MSE: 0.022709012031555176. Test_MSE: 0.04088122397661209\n",
      "Epoch: 180 Iteration: 126700. Train_MSE: 0.012283249758183956. Test_MSE: 0.05003626272082329\n",
      "Epoch: 180 Iteration: 126800. Train_MSE: 0.0006842520670033991. Test_MSE: 0.0432855524122715\n",
      "Epoch: 180 Iteration: 126900. Train_MSE: 0.0008008141885511577. Test_MSE: 0.051586542278528214\n",
      "Epoch: 180 Iteration: 127000. Train_MSE: 0.008632807992398739. Test_MSE: 0.04391774162650108\n",
      "Epoch: 181 Iteration: 127100. Train_MSE: 0.017144665122032166. Test_MSE: 0.04940817877650261\n",
      "Epoch: 181 Iteration: 127200. Train_MSE: 0.003853397909551859. Test_MSE: 0.04487774521112442\n",
      "Epoch: 181 Iteration: 127300. Train_MSE: 0.012654426507651806. Test_MSE: 0.041236668825149536\n",
      "Epoch: 181 Iteration: 127400. Train_MSE: 0.009081379510462284. Test_MSE: 0.050682105123996735\n",
      "Epoch: 181 Iteration: 127500. Train_MSE: 0.0006129401735961437. Test_MSE: 0.043640948832035065\n",
      "Epoch: 181 Iteration: 127600. Train_MSE: 0.001862237579189241. Test_MSE: 0.051233671605587006\n",
      "Epoch: 181 Iteration: 127700. Train_MSE: 0.00955983530730009. Test_MSE: 0.044440966099500656\n",
      "Epoch: 182 Iteration: 127800. Train_MSE: 0.007265868131071329. Test_MSE: 0.04840594157576561\n",
      "Epoch: 182 Iteration: 127900. Train_MSE: 0.005758530460298061. Test_MSE: 0.04484405368566513\n",
      "Epoch: 182 Iteration: 128000. Train_MSE: 0.008729875087738037. Test_MSE: 0.041279155761003494\n",
      "Epoch: 182 Iteration: 128100. Train_MSE: 0.012761090882122517. Test_MSE: 0.05106713995337486\n",
      "Epoch: 182 Iteration: 128200. Train_MSE: 0.0009986053919419646. Test_MSE: 0.04370341822504997\n",
      "Epoch: 182 Iteration: 128300. Train_MSE: 0.0018499917350709438. Test_MSE: 0.05087430402636528\n",
      "Epoch: 182 Iteration: 128400. Train_MSE: 0.00432490324601531. Test_MSE: 0.045143041759729385\n",
      "Epoch: 183 Iteration: 128500. Train_MSE: 0.017062343657016754. Test_MSE: 0.04711317643523216\n",
      "Epoch: 183 Iteration: 128600. Train_MSE: 0.009817796759307384. Test_MSE: 0.044754743576049805\n",
      "Epoch: 183 Iteration: 128700. Train_MSE: 0.0035525569692254066. Test_MSE: 0.04117419570684433\n",
      "Epoch: 183 Iteration: 128800. Train_MSE: 0.01647423952817917. Test_MSE: 0.05148892104625702\n",
      "Epoch: 183 Iteration: 128900. Train_MSE: 0.0008338679908774793. Test_MSE: 0.0438353531062603\n",
      "Epoch: 183 Iteration: 129000. Train_MSE: 0.0011006236309185624. Test_MSE: 0.05032140761613846\n",
      "Epoch: 183 Iteration: 129100. Train_MSE: 0.01763658970594406. Test_MSE: 0.04561746492981911\n",
      "Epoch: 184 Iteration: 129200. Train_MSE: 0.032202161848545074. Test_MSE: 0.046068619936704636\n",
      "Epoch: 184 Iteration: 129300. Train_MSE: 0.005515167023986578. Test_MSE: 0.044892191886901855\n",
      "Epoch: 184 Iteration: 129400. Train_MSE: 0.005733212921768427. Test_MSE: 0.04133288562297821\n",
      "Epoch: 184 Iteration: 129500. Train_MSE: 0.013693158514797688. Test_MSE: 0.051229022443294525\n",
      "Epoch: 184 Iteration: 129600. Train_MSE: 0.0012766350992023945. Test_MSE: 0.04384981468319893\n",
      "Epoch: 184 Iteration: 129700. Train_MSE: 0.0018898779526352882. Test_MSE: 0.04891584441065788\n",
      "Epoch: 184 Iteration: 129800. Train_MSE: 0.0058761597611010075. Test_MSE: 0.04604540765285492\n",
      "Epoch: 185 Iteration: 129900. Train_MSE: 0.03188132494688034. Test_MSE: 0.04491244629025459\n",
      "Epoch: 185 Iteration: 130000. Train_MSE: 0.004897193983197212. Test_MSE: 0.04499660059809685\n",
      "Epoch: 185 Iteration: 130100. Train_MSE: 0.0023685344494879246. Test_MSE: 0.04173179343342781\n",
      "Epoch: 185 Iteration: 130200. Train_MSE: 0.011778896674513817. Test_MSE: 0.05088815465569496\n",
      "Epoch: 185 Iteration: 130300. Train_MSE: 0.0019327381160110235. Test_MSE: 0.04428001120686531\n",
      "Epoch: 185 Iteration: 130400. Train_MSE: 0.001653290819376707. Test_MSE: 0.047871168702840805\n",
      "Epoch: 185 Iteration: 130500. Train_MSE: 0.004101104568690062. Test_MSE: 0.046090222895145416\n",
      "Epoch: 186 Iteration: 130600. Train_MSE: 0.05558158457279205. Test_MSE: 0.04348505288362503\n",
      "Epoch: 186 Iteration: 130700. Train_MSE: 0.00954399723559618. Test_MSE: 0.04488147050142288\n",
      "Epoch: 186 Iteration: 130800. Train_MSE: 0.00847224798053503. Test_MSE: 0.04193802550435066\n",
      "Epoch: 186 Iteration: 130900. Train_MSE: 0.01887628808617592. Test_MSE: 0.050409648567438126\n",
      "Epoch: 186 Iteration: 131000. Train_MSE: 0.0017052581533789635. Test_MSE: 0.04472796618938446\n",
      "Epoch: 186 Iteration: 131100. Train_MSE: 0.0045625935308635235. Test_MSE: 0.046399664133787155\n",
      "Epoch: 186 Iteration: 131200. Train_MSE: 0.0051072281785309315. Test_MSE: 0.04621231183409691\n",
      "Epoch: 187 Iteration: 131300. Train_MSE: 0.030987801030278206. Test_MSE: 0.04204655438661575\n",
      "Epoch: 187 Iteration: 131400. Train_MSE: 0.008080273866653442. Test_MSE: 0.044676728546619415\n",
      "Epoch: 187 Iteration: 131500. Train_MSE: 0.0014733433490619063. Test_MSE: 0.04175405949354172\n",
      "Epoch: 187 Iteration: 131600. Train_MSE: 0.0089465556666255. Test_MSE: 0.04970475286245346\n",
      "Epoch: 187 Iteration: 131700. Train_MSE: 0.0031949582044035196. Test_MSE: 0.045277245342731476\n",
      "Epoch: 187 Iteration: 131800. Train_MSE: 0.005395278800278902. Test_MSE: 0.04515286907553673\n",
      "Epoch: 187 Iteration: 131900. Train_MSE: 0.001978929154574871. Test_MSE: 0.04619690030813217\n",
      "Epoch: 188 Iteration: 132000. Train_MSE: 0.04931076616048813. Test_MSE: 0.04153253883123398\n",
      "Epoch: 188 Iteration: 132100. Train_MSE: 0.018974265083670616. Test_MSE: 0.04484729468822479\n",
      "Epoch: 188 Iteration: 132200. Train_MSE: 0.0019882468041032553. Test_MSE: 0.04215693846344948\n",
      "Epoch: 188 Iteration: 132300. Train_MSE: 0.013666192069649696. Test_MSE: 0.04930613562464714\n",
      "Epoch: 188 Iteration: 132400. Train_MSE: 0.0043398370034992695. Test_MSE: 0.045499011874198914\n",
      "Epoch: 188 Iteration: 132500. Train_MSE: 0.00465480936691165. Test_MSE: 0.04460655897855759\n",
      "Epoch: 188 Iteration: 132600. Train_MSE: 0.001635891036130488. Test_MSE: 0.04654054716229439\n",
      "Epoch: 189 Iteration: 132700. Train_MSE: 0.05587046593427658. Test_MSE: 0.040606871247291565\n",
      "Epoch: 189 Iteration: 132800. Train_MSE: 0.021498823538422585. Test_MSE: 0.04435325041413307\n",
      "Epoch: 189 Iteration: 132900. Train_MSE: 0.0021187495440244675. Test_MSE: 0.04231555387377739\n",
      "Epoch: 189 Iteration: 133000. Train_MSE: 0.010502682998776436. Test_MSE: 0.04872310161590576\n",
      "Epoch: 189 Iteration: 133100. Train_MSE: 0.004125429783016443. Test_MSE: 0.04555495083332062\n",
      "Epoch: 189 Iteration: 133200. Train_MSE: 0.006894351914525032. Test_MSE: 0.04360242187976837\n",
      "Epoch: 189 Iteration: 133300. Train_MSE: 0.00016967604460660368. Test_MSE: 0.046361666172742844\n",
      "Epoch: 190 Iteration: 133400. Train_MSE: 0.08739776909351349. Test_MSE: 0.04001002013683319\n",
      "Epoch: 190 Iteration: 133500. Train_MSE: 0.02558857761323452. Test_MSE: 0.044315483421087265\n",
      "Epoch: 190 Iteration: 133600. Train_MSE: 0.012821347452700138. Test_MSE: 0.04228397086262703\n",
      "Epoch: 190 Iteration: 133700. Train_MSE: 0.008341187611222267. Test_MSE: 0.04875004291534424\n",
      "Epoch: 190 Iteration: 133800. Train_MSE: 0.004163531120866537. Test_MSE: 0.04578651860356331\n",
      "Epoch: 190 Iteration: 133900. Train_MSE: 0.007899697870016098. Test_MSE: 0.04248170182108879\n",
      "Epoch: 190 Iteration: 134000. Train_MSE: 0.0005839553195983171. Test_MSE: 0.04636052995920181\n",
      "Epoch: 191 Iteration: 134100. Train_MSE: 0.05595210939645767. Test_MSE: 0.03962477296590805\n",
      "Epoch: 191 Iteration: 134200. Train_MSE: 0.03886470943689346. Test_MSE: 0.043953217566013336\n",
      "Epoch: 191 Iteration: 134300. Train_MSE: 0.011287549510598183. Test_MSE: 0.04233204200863838\n",
      "Epoch: 191 Iteration: 134400. Train_MSE: 0.008511143736541271. Test_MSE: 0.04865949973464012\n",
      "Epoch: 191 Iteration: 134500. Train_MSE: 0.0075869131833314896. Test_MSE: 0.04603615775704384\n",
      "Epoch: 191 Iteration: 134600. Train_MSE: 0.008269074372947216. Test_MSE: 0.04203668236732483\n",
      "Epoch: 191 Iteration: 134700. Train_MSE: 0.0005586536135524511. Test_MSE: 0.046369727700948715\n",
      "Epoch: 192 Iteration: 134800. Train_MSE: 0.047485560178756714. Test_MSE: 0.03969402611255646\n",
      "Epoch: 192 Iteration: 134900. Train_MSE: 0.05547529086470604. Test_MSE: 0.04350336268544197\n",
      "Epoch: 192 Iteration: 135000. Train_MSE: 0.0034263913985341787. Test_MSE: 0.04223262146115303\n",
      "Epoch: 192 Iteration: 135100. Train_MSE: 0.008699541911482811. Test_MSE: 0.04820908233523369\n",
      "Epoch: 192 Iteration: 135200. Train_MSE: 0.010194902308285236. Test_MSE: 0.04638342559337616\n",
      "Epoch: 192 Iteration: 135300. Train_MSE: 0.011440230533480644. Test_MSE: 0.041431084275245667\n",
      "Epoch: 192 Iteration: 135400. Train_MSE: 0.0005789663409814239. Test_MSE: 0.04643593356013298\n",
      "Epoch: 193 Iteration: 135500. Train_MSE: 0.0472504124045372. Test_MSE: 0.04010704904794693\n",
      "Epoch: 193 Iteration: 135600. Train_MSE: 0.025873133912682533. Test_MSE: 0.04290333390235901\n",
      "Epoch: 193 Iteration: 135700. Train_MSE: 0.017221922054886818. Test_MSE: 0.04211540147662163\n",
      "Epoch: 193 Iteration: 135800. Train_MSE: 0.005968738347291946. Test_MSE: 0.047437842935323715\n",
      "Epoch: 193 Iteration: 135900. Train_MSE: 0.01613936387002468. Test_MSE: 0.04666789993643761\n",
      "Epoch: 193 Iteration: 136000. Train_MSE: 0.014082743786275387. Test_MSE: 0.04191526025533676\n",
      "Epoch: 193 Iteration: 136100. Train_MSE: 0.0005453723133541644. Test_MSE: 0.046277690678834915\n",
      "Epoch: 194 Iteration: 136200. Train_MSE: 0.04866106063127518. Test_MSE: 0.041047435253858566\n",
      "Epoch: 194 Iteration: 136300. Train_MSE: 0.031495556235313416. Test_MSE: 0.04233992472290993\n",
      "Epoch: 194 Iteration: 136400. Train_MSE: 0.02805321291089058. Test_MSE: 0.04214407503604889\n",
      "Epoch: 194 Iteration: 136500. Train_MSE: 0.006539361085742712. Test_MSE: 0.04717141389846802\n",
      "Epoch: 194 Iteration: 136600. Train_MSE: 0.011371609754860401. Test_MSE: 0.04635436087846756\n",
      "Epoch: 194 Iteration: 136700. Train_MSE: 0.005705435760319233. Test_MSE: 0.04244573786854744\n",
      "Epoch: 194 Iteration: 136800. Train_MSE: 0.000916466407943517. Test_MSE: 0.04616060107946396\n",
      "Epoch: 195 Iteration: 136900. Train_MSE: 0.07178270071744919. Test_MSE: 0.04288307577371597\n",
      "Epoch: 195 Iteration: 137000. Train_MSE: 0.05164673924446106. Test_MSE: 0.04192236065864563\n",
      "Epoch: 195 Iteration: 137100. Train_MSE: 0.019834838807582855. Test_MSE: 0.041645899415016174\n",
      "Epoch: 195 Iteration: 137200. Train_MSE: 0.004037720151245594. Test_MSE: 0.046420011669397354\n",
      "Epoch: 195 Iteration: 137300. Train_MSE: 0.008680150844156742. Test_MSE: 0.045929063111543655\n",
      "Epoch: 195 Iteration: 137400. Train_MSE: 0.003454160876572132. Test_MSE: 0.04222753271460533\n",
      "Epoch: 195 Iteration: 137500. Train_MSE: 0.0008578330744057894. Test_MSE: 0.046076755970716476\n",
      "Epoch: 196 Iteration: 137600. Train_MSE: 0.04795164242386818. Test_MSE: 0.044092994183301926\n",
      "Epoch: 196 Iteration: 137700. Train_MSE: 0.04643411189317703. Test_MSE: 0.041344642639160156\n",
      "Epoch: 196 Iteration: 137800. Train_MSE: 0.021108152344822884. Test_MSE: 0.04110962525010109\n",
      "Epoch: 196 Iteration: 137900. Train_MSE: 0.005219629034399986. Test_MSE: 0.04578227177262306\n",
      "Epoch: 196 Iteration: 138000. Train_MSE: 0.0134292496368289. Test_MSE: 0.04494825005531311\n",
      "Epoch: 196 Iteration: 138100. Train_MSE: 0.0029528397135436535. Test_MSE: 0.042588263750076294\n",
      "Epoch: 196 Iteration: 138200. Train_MSE: 0.0009195518214255571. Test_MSE: 0.04634161666035652\n",
      "Epoch: 197 Iteration: 138300. Train_MSE: 0.1287311166524887. Test_MSE: 0.04536278545856476\n",
      "Epoch: 197 Iteration: 138400. Train_MSE: 0.045678943395614624. Test_MSE: 0.041495468467473984\n",
      "Epoch: 197 Iteration: 138500. Train_MSE: 0.029135694727301598. Test_MSE: 0.0410294272005558\n",
      "Epoch: 197 Iteration: 138600. Train_MSE: 0.0033276600297540426. Test_MSE: 0.04536430537700653\n",
      "Epoch: 197 Iteration: 138700. Train_MSE: 0.010489034466445446. Test_MSE: 0.04434807598590851\n",
      "Epoch: 197 Iteration: 138800. Train_MSE: 0.0011570693459361792. Test_MSE: 0.042630281299352646\n",
      "Epoch: 197 Iteration: 138900. Train_MSE: 0.0012743695406243205. Test_MSE: 0.0464092455804348\n",
      "Epoch: 198 Iteration: 139000. Train_MSE: 0.06481736153364182. Test_MSE: 0.04549941048026085\n",
      "Epoch: 198 Iteration: 139100. Train_MSE: 0.04585849866271019. Test_MSE: 0.041982829570770264\n",
      "Epoch: 198 Iteration: 139200. Train_MSE: 0.036264628171920776. Test_MSE: 0.04087876155972481\n",
      "Epoch: 198 Iteration: 139300. Train_MSE: 0.0036341536324471235. Test_MSE: 0.044839803129434586\n",
      "Epoch: 198 Iteration: 139400. Train_MSE: 0.015060347504913807. Test_MSE: 0.044634751975536346\n",
      "Epoch: 198 Iteration: 139500. Train_MSE: 0.0010411643888801336. Test_MSE: 0.04201987013220787\n",
      "Epoch: 198 Iteration: 139600. Train_MSE: 0.0015395022928714752. Test_MSE: 0.04629926010966301\n",
      "Epoch: 199 Iteration: 139700. Train_MSE: 0.059186339378356934. Test_MSE: 0.04550090804696083\n",
      "Epoch: 199 Iteration: 139800. Train_MSE: 0.07235771417617798. Test_MSE: 0.04266297072172165\n",
      "Epoch: 199 Iteration: 139900. Train_MSE: 0.03680936247110367. Test_MSE: 0.04031604155898094\n",
      "Epoch: 199 Iteration: 140000. Train_MSE: 0.0009432159131392837. Test_MSE: 0.04417791962623596\n",
      "Epoch: 199 Iteration: 140100. Train_MSE: 0.014342956244945526. Test_MSE: 0.045334119349718094\n",
      "Epoch: 199 Iteration: 140200. Train_MSE: 0.00025290303165093064. Test_MSE: 0.0420868843793869\n",
      "Epoch: 199 Iteration: 140300. Train_MSE: 0.0032089203596115112. Test_MSE: 0.046561114490032196\n",
      "Epoch: 199 Iteration: 140400. Train_MSE: 0.005756099708378315. Test_MSE: 0.04584796354174614\n",
      "Epoch: 200 Iteration: 140500. Train_MSE: 0.056595735251903534. Test_MSE: 0.042805761098861694\n",
      "Epoch: 200 Iteration: 140600. Train_MSE: 0.029273532330989838. Test_MSE: 0.0392751507461071\n",
      "Epoch: 200 Iteration: 140700. Train_MSE: 0.0018291521118953824. Test_MSE: 0.043683528900146484\n",
      "Epoch: 200 Iteration: 140800. Train_MSE: 0.010841822251677513. Test_MSE: 0.04599344730377197\n",
      "Epoch: 200 Iteration: 140900. Train_MSE: 0.00033168087247759104. Test_MSE: 0.04180416092276573\n",
      "Epoch: 200 Iteration: 141000. Train_MSE: 0.0037055283319205046. Test_MSE: 0.046567194163799286\n",
      "Epoch: 200 Iteration: 141100. Train_MSE: 0.013748441822826862. Test_MSE: 0.046045802533626556\n",
      "Epoch: 201 Iteration: 141200. Train_MSE: 0.07033637166023254. Test_MSE: 0.04319480061531067\n",
      "Epoch: 201 Iteration: 141300. Train_MSE: 0.05524192377924919. Test_MSE: 0.038905151188373566\n",
      "Epoch: 201 Iteration: 141400. Train_MSE: 0.0026433663442730904. Test_MSE: 0.042931076139211655\n",
      "Epoch: 201 Iteration: 141500. Train_MSE: 0.010130099020898342. Test_MSE: 0.04696990177035332\n",
      "Epoch: 201 Iteration: 141600. Train_MSE: 0.0009364213910885155. Test_MSE: 0.0419318787753582\n",
      "Epoch: 201 Iteration: 141700. Train_MSE: 0.004560885485261679. Test_MSE: 0.04645044729113579\n",
      "Epoch: 201 Iteration: 141800. Train_MSE: 0.005045722704380751. Test_MSE: 0.046353645622730255\n",
      "Epoch: 202 Iteration: 141900. Train_MSE: 0.08384019881486893. Test_MSE: 0.043227821588516235\n",
      "Epoch: 202 Iteration: 142000. Train_MSE: 0.04431026428937912. Test_MSE: 0.03869592770934105\n",
      "Epoch: 202 Iteration: 142100. Train_MSE: 0.019680356606841087. Test_MSE: 0.04211549833416939\n",
      "Epoch: 202 Iteration: 142200. Train_MSE: 0.00845981203019619. Test_MSE: 0.04776584357023239\n",
      "Epoch: 202 Iteration: 142300. Train_MSE: 0.0010153347393497825. Test_MSE: 0.0419723279774189\n",
      "Epoch: 202 Iteration: 142400. Train_MSE: 0.007710531819611788. Test_MSE: 0.04656599089503288\n",
      "Epoch: 202 Iteration: 142500. Train_MSE: 0.00302714086137712. Test_MSE: 0.046196918934583664\n",
      "Epoch: 203 Iteration: 142600. Train_MSE: 0.04833102226257324. Test_MSE: 0.043001942336559296\n",
      "Epoch: 203 Iteration: 142700. Train_MSE: 0.03791637346148491. Test_MSE: 0.03821186348795891\n",
      "Epoch: 203 Iteration: 142800. Train_MSE: 0.019321894273161888. Test_MSE: 0.04076356440782547\n",
      "Epoch: 203 Iteration: 142900. Train_MSE: 0.0074012307450175285. Test_MSE: 0.04880543425679207\n",
      "Epoch: 203 Iteration: 143000. Train_MSE: 0.0009582678321748972. Test_MSE: 0.04203319177031517\n",
      "Epoch: 203 Iteration: 143100. Train_MSE: 0.0067067574709653854. Test_MSE: 0.04682071506977081\n",
      "Epoch: 203 Iteration: 143200. Train_MSE: 0.0028067966923117638. Test_MSE: 0.04655659943819046\n",
      "Epoch: 204 Iteration: 143300. Train_MSE: 0.039731234312057495. Test_MSE: 0.043697163462638855\n",
      "Epoch: 204 Iteration: 143400. Train_MSE: 0.0916140004992485. Test_MSE: 0.03838561475276947\n",
      "Epoch: 204 Iteration: 143500. Train_MSE: 0.045197758823633194. Test_MSE: 0.0400712750852108\n",
      "Epoch: 204 Iteration: 143600. Train_MSE: 0.0040052481926977634. Test_MSE: 0.04904120787978172\n",
      "Epoch: 204 Iteration: 143700. Train_MSE: 0.0017746463418006897. Test_MSE: 0.04175155609846115\n",
      "Epoch: 204 Iteration: 143800. Train_MSE: 0.008222034201025963. Test_MSE: 0.04697287455201149\n",
      "Epoch: 204 Iteration: 143900. Train_MSE: 0.0055394540540874004. Test_MSE: 0.04645740985870361\n",
      "Epoch: 205 Iteration: 144000. Train_MSE: 0.04328179731965065. Test_MSE: 0.04453285411000252\n",
      "Epoch: 205 Iteration: 144100. Train_MSE: 0.10223495215177536. Test_MSE: 0.038303472101688385\n",
      "Epoch: 205 Iteration: 144200. Train_MSE: 0.023413822054862976. Test_MSE: 0.03893677890300751\n",
      "Epoch: 205 Iteration: 144300. Train_MSE: 0.00354575552046299. Test_MSE: 0.049299463629722595\n",
      "Epoch: 205 Iteration: 144400. Train_MSE: 0.0025310018099844456. Test_MSE: 0.04210478439927101\n",
      "Epoch: 205 Iteration: 144500. Train_MSE: 0.006744980812072754. Test_MSE: 0.047578491270542145\n",
      "Epoch: 205 Iteration: 144600. Train_MSE: 0.0002940155391115695. Test_MSE: 0.046559348702430725\n",
      "Epoch: 206 Iteration: 144700. Train_MSE: 0.05303988605737686. Test_MSE: 0.046621643006801605\n",
      "Epoch: 206 Iteration: 144800. Train_MSE: 0.04427400603890419. Test_MSE: 0.03972508758306503\n",
      "Epoch: 206 Iteration: 144900. Train_MSE: 0.026750395074486732. Test_MSE: 0.03774268925189972\n",
      "Epoch: 206 Iteration: 145000. Train_MSE: 0.008394063450396061. Test_MSE: 0.04975903779268265\n",
      "Epoch: 206 Iteration: 145100. Train_MSE: 0.0029349469114094973. Test_MSE: 0.04191264137625694\n",
      "Epoch: 206 Iteration: 145200. Train_MSE: 0.008240698836743832. Test_MSE: 0.04827015474438667\n",
      "Epoch: 206 Iteration: 145300. Train_MSE: 0.0002991784131154418. Test_MSE: 0.04690287262201309\n",
      "Epoch: 207 Iteration: 145400. Train_MSE: 0.07576362788677216. Test_MSE: 0.04908686503767967\n",
      "Epoch: 207 Iteration: 145500. Train_MSE: 0.07211270183324814. Test_MSE: 0.04118006303906441\n",
      "Epoch: 207 Iteration: 145600. Train_MSE: 0.0523107685148716. Test_MSE: 0.037026625126600266\n",
      "Epoch: 207 Iteration: 145700. Train_MSE: 0.0024106521159410477. Test_MSE: 0.0504884198307991\n",
      "Epoch: 207 Iteration: 145800. Train_MSE: 0.004846589639782906. Test_MSE: 0.042215898633003235\n",
      "Epoch: 207 Iteration: 145900. Train_MSE: 0.010519786737859249. Test_MSE: 0.04804690182209015\n",
      "Epoch: 207 Iteration: 146000. Train_MSE: 0.0004318754654377699. Test_MSE: 0.04676453396677971\n",
      "Epoch: 208 Iteration: 146100. Train_MSE: 0.05299767106771469. Test_MSE: 0.04960931837558746\n",
      "Epoch: 208 Iteration: 146200. Train_MSE: 0.062493566423654556. Test_MSE: 0.04267527908086777\n",
      "Epoch: 208 Iteration: 146300. Train_MSE: 0.04808546602725983. Test_MSE: 0.036259256303310394\n",
      "Epoch: 208 Iteration: 146400. Train_MSE: 0.0017487541772425175. Test_MSE: 0.050331637263298035\n",
      "Epoch: 208 Iteration: 146500. Train_MSE: 0.008272607810795307. Test_MSE: 0.0421106331050396\n",
      "Epoch: 208 Iteration: 146600. Train_MSE: 0.007350217550992966. Test_MSE: 0.047700297087430954\n",
      "Epoch: 208 Iteration: 146700. Train_MSE: 0.00118496164213866. Test_MSE: 0.046075489372015\n",
      "Epoch: 209 Iteration: 146800. Train_MSE: 0.07159966230392456. Test_MSE: 0.049174387007951736\n",
      "Epoch: 209 Iteration: 146900. Train_MSE: 0.05581541359424591. Test_MSE: 0.044276490807533264\n",
      "Epoch: 209 Iteration: 147000. Train_MSE: 0.05875643342733383. Test_MSE: 0.036645904183387756\n",
      "Epoch: 209 Iteration: 147100. Train_MSE: 0.0012529114028438926. Test_MSE: 0.05010678246617317\n",
      "Epoch: 209 Iteration: 147200. Train_MSE: 0.008075985126197338. Test_MSE: 0.04215990751981735\n",
      "Epoch: 209 Iteration: 147300. Train_MSE: 0.010874615050852299. Test_MSE: 0.0474252887070179\n",
      "Epoch: 209 Iteration: 147400. Train_MSE: 0.000920624122954905. Test_MSE: 0.04641697555780411\n",
      "Epoch: 210 Iteration: 147500. Train_MSE: 0.0725712701678276. Test_MSE: 0.0486651286482811\n",
      "Epoch: 210 Iteration: 147600. Train_MSE: 0.07525207847356796. Test_MSE: 0.0467836856842041\n",
      "Epoch: 210 Iteration: 147700. Train_MSE: 0.06710907816886902. Test_MSE: 0.03730424866080284\n",
      "Epoch: 210 Iteration: 147800. Train_MSE: 0.00039677665336057544. Test_MSE: 0.04989143833518028\n",
      "Epoch: 210 Iteration: 147900. Train_MSE: 0.00694856233894825. Test_MSE: 0.04259553179144859\n",
      "Epoch: 210 Iteration: 148000. Train_MSE: 0.013563944026827812. Test_MSE: 0.04708719626069069\n",
      "Epoch: 210 Iteration: 148100. Train_MSE: 0.0019372792448848486. Test_MSE: 0.04623037204146385\n",
      "Epoch: 211 Iteration: 148200. Train_MSE: 0.056192684918642044. Test_MSE: 0.048511117696762085\n",
      "Epoch: 211 Iteration: 148300. Train_MSE: 0.05693221092224121. Test_MSE: 0.04921115189790726\n",
      "Epoch: 211 Iteration: 148400. Train_MSE: 0.06114013120532036. Test_MSE: 0.037849728018045425\n",
      "Epoch: 211 Iteration: 148500. Train_MSE: 0.0007087058038450778. Test_MSE: 0.05019848793745041\n",
      "Epoch: 211 Iteration: 148600. Train_MSE: 0.008486723527312279. Test_MSE: 0.04343367740511894\n",
      "Epoch: 211 Iteration: 148700. Train_MSE: 0.010405812412500381. Test_MSE: 0.04678836837410927\n",
      "Epoch: 211 Iteration: 148800. Train_MSE: 0.0022631939500570297. Test_MSE: 0.04616282880306244\n",
      "Epoch: 212 Iteration: 148900. Train_MSE: 0.025749191641807556. Test_MSE: 0.048431653529405594\n",
      "Epoch: 212 Iteration: 149000. Train_MSE: 0.051532864570617676. Test_MSE: 0.051959458738565445\n",
      "Epoch: 212 Iteration: 149100. Train_MSE: 0.05638125538825989. Test_MSE: 0.03886784613132477\n",
      "Epoch: 212 Iteration: 149200. Train_MSE: 0.0002261882327729836. Test_MSE: 0.049851931631565094\n",
      "Epoch: 212 Iteration: 149300. Train_MSE: 0.011163580231368542. Test_MSE: 0.044639091938734055\n",
      "Epoch: 212 Iteration: 149400. Train_MSE: 0.006978877354413271. Test_MSE: 0.04569157212972641\n",
      "Epoch: 212 Iteration: 149500. Train_MSE: 0.002354556228965521. Test_MSE: 0.04591645672917366\n",
      "Epoch: 213 Iteration: 149600. Train_MSE: 0.05330890044569969. Test_MSE: 0.048041731119155884\n",
      "Epoch: 213 Iteration: 149700. Train_MSE: 0.07710681855678558. Test_MSE: 0.05474718660116196\n",
      "Epoch: 213 Iteration: 149800. Train_MSE: 0.041109174489974976. Test_MSE: 0.04025178402662277\n",
      "Epoch: 213 Iteration: 149900. Train_MSE: 0.000567519455216825. Test_MSE: 0.05015852674841881\n",
      "Epoch: 213 Iteration: 150000. Train_MSE: 0.012205490842461586. Test_MSE: 0.046081945300102234\n",
      "Epoch: 213 Iteration: 150100. Train_MSE: 0.011566712521016598. Test_MSE: 0.045536015182733536\n",
      "Epoch: 213 Iteration: 150200. Train_MSE: 0.0028264024294912815. Test_MSE: 0.0453609973192215\n",
      "Epoch: 214 Iteration: 150300. Train_MSE: 0.051006823778152466. Test_MSE: 0.04795044660568237\n",
      "Epoch: 214 Iteration: 150400. Train_MSE: 0.06838681548833847. Test_MSE: 0.055185504257678986\n",
      "Epoch: 214 Iteration: 150500. Train_MSE: 0.04112294688820839. Test_MSE: 0.04175938293337822\n",
      "Epoch: 214 Iteration: 150600. Train_MSE: 0.0002435400092508644. Test_MSE: 0.0504130944609642\n",
      "Epoch: 214 Iteration: 150700. Train_MSE: 0.012106657959520817. Test_MSE: 0.046833205968141556\n",
      "Epoch: 214 Iteration: 150800. Train_MSE: 0.008643992245197296. Test_MSE: 0.04572192579507828\n",
      "Epoch: 214 Iteration: 150900. Train_MSE: 0.004163746256381273. Test_MSE: 0.04510531574487686\n",
      "Epoch: 215 Iteration: 151000. Train_MSE: 0.03995560482144356. Test_MSE: 0.048199839890003204\n",
      "Epoch: 215 Iteration: 151100. Train_MSE: 0.04528171569108963. Test_MSE: 0.054910607635974884\n",
      "Epoch: 215 Iteration: 151200. Train_MSE: 0.07504761219024658. Test_MSE: 0.04352197051048279\n",
      "Epoch: 215 Iteration: 151300. Train_MSE: 0.0004300229193177074. Test_MSE: 0.0503317266702652\n",
      "Epoch: 215 Iteration: 151400. Train_MSE: 0.012545659206807613. Test_MSE: 0.04723876342177391\n",
      "Epoch: 215 Iteration: 151500. Train_MSE: 0.007399224676191807. Test_MSE: 0.04582240805029869\n",
      "Epoch: 215 Iteration: 151600. Train_MSE: 0.003787381574511528. Test_MSE: 0.04503127932548523\n",
      "Epoch: 216 Iteration: 151700. Train_MSE: 0.02430790662765503. Test_MSE: 0.04810888320207596\n",
      "Epoch: 216 Iteration: 151800. Train_MSE: 0.07368529587984085. Test_MSE: 0.05338795855641365\n",
      "Epoch: 216 Iteration: 151900. Train_MSE: 0.05089304596185684. Test_MSE: 0.0455467589199543\n",
      "Epoch: 216 Iteration: 152000. Train_MSE: 0.0005653119878843427. Test_MSE: 0.05050000920891762\n",
      "Epoch: 216 Iteration: 152100. Train_MSE: 0.015416303649544716. Test_MSE: 0.04824718087911606\n",
      "Epoch: 216 Iteration: 152200. Train_MSE: 0.018877176567912102. Test_MSE: 0.04645692929625511\n",
      "Epoch: 216 Iteration: 152300. Train_MSE: 0.003897108370438218. Test_MSE: 0.04493951424956322\n",
      "Epoch: 217 Iteration: 152400. Train_MSE: 0.03486485779285431. Test_MSE: 0.04776593670248985\n",
      "Epoch: 217 Iteration: 152500. Train_MSE: 0.05388909950852394. Test_MSE: 0.0516209602355957\n",
      "Epoch: 217 Iteration: 152600. Train_MSE: 0.06368730217218399. Test_MSE: 0.04737376049160957\n",
      "Epoch: 217 Iteration: 152700. Train_MSE: 0.0013909238623455167. Test_MSE: 0.05027511715888977\n",
      "Epoch: 217 Iteration: 152800. Train_MSE: 0.00981359463185072. Test_MSE: 0.04732634872198105\n",
      "Epoch: 217 Iteration: 152900. Train_MSE: 0.007601763121783733. Test_MSE: 0.04724733904004097\n",
      "Epoch: 217 Iteration: 153000. Train_MSE: 0.006958157289773226. Test_MSE: 0.044060494750738144\n",
      "Epoch: 218 Iteration: 153100. Train_MSE: 0.02237646095454693. Test_MSE: 0.04861999675631523\n",
      "Epoch: 218 Iteration: 153200. Train_MSE: 0.048639439046382904. Test_MSE: 0.0499427355825901\n",
      "Epoch: 218 Iteration: 153300. Train_MSE: 0.05927173048257828. Test_MSE: 0.04904821887612343\n",
      "Epoch: 218 Iteration: 153400. Train_MSE: 0.001481640967540443. Test_MSE: 0.0499834343791008\n",
      "Epoch: 218 Iteration: 153500. Train_MSE: 0.008143815211951733. Test_MSE: 0.04608479514718056\n",
      "Epoch: 218 Iteration: 153600. Train_MSE: 0.00559717183932662. Test_MSE: 0.04780053347349167\n",
      "Epoch: 218 Iteration: 153700. Train_MSE: 0.005447831004858017. Test_MSE: 0.044064704328775406\n",
      "Epoch: 219 Iteration: 153800. Train_MSE: 0.02852471172809601. Test_MSE: 0.048281196504831314\n",
      "Epoch: 219 Iteration: 153900. Train_MSE: 0.05539146438241005. Test_MSE: 0.049009229987859726\n",
      "Epoch: 219 Iteration: 154000. Train_MSE: 0.07359995692968369. Test_MSE: 0.049887411296367645\n",
      "Epoch: 219 Iteration: 154100. Train_MSE: 0.0019367474596947432. Test_MSE: 0.04974918067455292\n",
      "Epoch: 219 Iteration: 154200. Train_MSE: 0.014249061234295368. Test_MSE: 0.044351354241371155\n",
      "Epoch: 219 Iteration: 154300. Train_MSE: 0.006332988850772381. Test_MSE: 0.04900546371936798\n",
      "Epoch: 219 Iteration: 154400. Train_MSE: 0.007480480708181858. Test_MSE: 0.04426473751664162\n",
      "Epoch: 220 Iteration: 154500. Train_MSE: 0.008859539404511452. Test_MSE: 0.04776081442832947\n",
      "Epoch: 220 Iteration: 154600. Train_MSE: 0.042920541018247604. Test_MSE: 0.04782729595899582\n",
      "Epoch: 220 Iteration: 154700. Train_MSE: 0.05427921190857887. Test_MSE: 0.04972998797893524\n",
      "Epoch: 220 Iteration: 154800. Train_MSE: 0.0032837691251188517. Test_MSE: 0.04990525543689728\n",
      "Epoch: 220 Iteration: 154900. Train_MSE: 0.01479447353631258. Test_MSE: 0.043501753360033035\n",
      "Epoch: 220 Iteration: 155000. Train_MSE: 0.006402301136404276. Test_MSE: 0.05004962161183357\n",
      "Epoch: 220 Iteration: 155100. Train_MSE: 0.008535542525351048. Test_MSE: 0.043944939970970154\n",
      "Epoch: 221 Iteration: 155200. Train_MSE: 0.024155249819159508. Test_MSE: 0.04829048365354538\n",
      "Epoch: 221 Iteration: 155300. Train_MSE: 0.023784400895237923. Test_MSE: 0.04714253544807434\n",
      "Epoch: 221 Iteration: 155400. Train_MSE: 0.04443272575736046. Test_MSE: 0.04890253767371178\n",
      "Epoch: 221 Iteration: 155500. Train_MSE: 0.005042367149144411. Test_MSE: 0.04933782294392586\n",
      "Epoch: 221 Iteration: 155600. Train_MSE: 0.012381713837385178. Test_MSE: 0.043158963322639465\n",
      "Epoch: 221 Iteration: 155700. Train_MSE: 0.01019319798797369. Test_MSE: 0.050196826457977295\n",
      "Epoch: 221 Iteration: 155800. Train_MSE: 0.009112495929002762. Test_MSE: 0.04393372684717178\n",
      "Epoch: 222 Iteration: 155900. Train_MSE: 0.002750989282503724. Test_MSE: 0.04830494150519371\n",
      "Epoch: 222 Iteration: 156000. Train_MSE: 0.06684435904026031. Test_MSE: 0.046246130019426346\n",
      "Epoch: 222 Iteration: 156100. Train_MSE: 0.08137395232915878. Test_MSE: 0.04726201668381691\n",
      "Epoch: 222 Iteration: 156200. Train_MSE: 0.005758164916187525. Test_MSE: 0.04903796315193176\n",
      "Epoch: 222 Iteration: 156300. Train_MSE: 0.01634448952972889. Test_MSE: 0.042889662086963654\n",
      "Epoch: 222 Iteration: 156400. Train_MSE: 0.005689161829650402. Test_MSE: 0.05115371569991112\n",
      "Epoch: 222 Iteration: 156500. Train_MSE: 0.007011522073298693. Test_MSE: 0.044594597071409225\n",
      "Epoch: 223 Iteration: 156600. Train_MSE: 0.010694034397602081. Test_MSE: 0.048203106969594955\n",
      "Epoch: 223 Iteration: 156700. Train_MSE: 0.013831079937517643. Test_MSE: 0.04571285843849182\n",
      "Epoch: 223 Iteration: 156800. Train_MSE: 0.035723041743040085. Test_MSE: 0.04483815282583237\n",
      "Epoch: 223 Iteration: 156900. Train_MSE: 0.003931383602321148. Test_MSE: 0.04882862791419029\n",
      "Epoch: 223 Iteration: 157000. Train_MSE: 0.0031700318213552237. Test_MSE: 0.043123066425323486\n",
      "Epoch: 223 Iteration: 157100. Train_MSE: 0.007538879290223122. Test_MSE: 0.05096215382218361\n",
      "Epoch: 223 Iteration: 157200. Train_MSE: 0.00772543391212821. Test_MSE: 0.0452914834022522\n",
      "Epoch: 224 Iteration: 157300. Train_MSE: 0.0018057478591799736. Test_MSE: 0.04886326938867569\n",
      "Epoch: 224 Iteration: 157400. Train_MSE: 0.041284095495939255. Test_MSE: 0.04517655074596405\n",
      "Epoch: 224 Iteration: 157500. Train_MSE: 0.0965813621878624. Test_MSE: 0.04309891536831856\n",
      "Epoch: 224 Iteration: 157600. Train_MSE: 0.006345308851450682. Test_MSE: 0.049102623015642166\n",
      "Epoch: 224 Iteration: 157700. Train_MSE: 0.00010332610690966249. Test_MSE: 0.04341078922152519\n",
      "Epoch: 224 Iteration: 157800. Train_MSE: 0.001981766428798437. Test_MSE: 0.05173298344016075\n",
      "Epoch: 224 Iteration: 157900. Train_MSE: 0.007924958132207394. Test_MSE: 0.04528161138296127\n",
      "Epoch: 225 Iteration: 158000. Train_MSE: 0.006657076068222523. Test_MSE: 0.049217790365219116\n",
      "Epoch: 225 Iteration: 158100. Train_MSE: 0.02455124817788601. Test_MSE: 0.044810544699430466\n",
      "Epoch: 225 Iteration: 158200. Train_MSE: 0.05546189844608307. Test_MSE: 0.041862115263938904\n",
      "Epoch: 225 Iteration: 158300. Train_MSE: 0.007072470150887966. Test_MSE: 0.04905536025762558\n",
      "Epoch: 225 Iteration: 158400. Train_MSE: 0.0013391493121162057. Test_MSE: 0.04323912784457207\n",
      "Epoch: 225 Iteration: 158500. Train_MSE: 0.0016791437519714236. Test_MSE: 0.05145382508635521\n",
      "Epoch: 225 Iteration: 158600. Train_MSE: 0.009355826303362846. Test_MSE: 0.044850464910268784\n",
      "Epoch: 226 Iteration: 158700. Train_MSE: 0.004394685383886099. Test_MSE: 0.050021711736917496\n",
      "Epoch: 226 Iteration: 158800. Train_MSE: 0.010199202224612236. Test_MSE: 0.04481951892375946\n",
      "Epoch: 226 Iteration: 158900. Train_MSE: 0.04417240992188454. Test_MSE: 0.04199427738785744\n",
      "Epoch: 226 Iteration: 159000. Train_MSE: 0.011903566308319569. Test_MSE: 0.04885637387633324\n",
      "Epoch: 226 Iteration: 159100. Train_MSE: 0.00031249664607457817. Test_MSE: 0.04331158846616745\n",
      "Epoch: 226 Iteration: 159200. Train_MSE: 0.0008190901717171073. Test_MSE: 0.0507357120513916\n",
      "Epoch: 226 Iteration: 159300. Train_MSE: 0.011416202411055565. Test_MSE: 0.043988168239593506\n",
      "Epoch: 227 Iteration: 159400. Train_MSE: 0.0059247384779155254. Test_MSE: 0.05000854656100273\n",
      "Epoch: 227 Iteration: 159500. Train_MSE: 0.006216664798557758. Test_MSE: 0.04465564712882042\n",
      "Epoch: 227 Iteration: 159600. Train_MSE: 0.025054827332496643. Test_MSE: 0.041788410395383835\n",
      "Epoch: 227 Iteration: 159700. Train_MSE: 0.008937123231589794. Test_MSE: 0.049618273973464966\n",
      "Epoch: 227 Iteration: 159800. Train_MSE: 7.693309453316033e-05. Test_MSE: 0.04297618567943573\n",
      "Epoch: 227 Iteration: 159900. Train_MSE: 0.0007571460446342826. Test_MSE: 0.05136052146553993\n",
      "Epoch: 227 Iteration: 160000. Train_MSE: 0.005652225576341152. Test_MSE: 0.04359371215105057\n",
      "Epoch: 228 Iteration: 160100. Train_MSE: 0.0030760352965444326. Test_MSE: 0.05027114227414131\n",
      "Epoch: 228 Iteration: 160200. Train_MSE: 0.004822015296667814. Test_MSE: 0.04424426704645157\n",
      "Epoch: 228 Iteration: 160300. Train_MSE: 0.020428752526640892. Test_MSE: 0.04222223162651062\n",
      "Epoch: 228 Iteration: 160400. Train_MSE: 0.010526320897042751. Test_MSE: 0.04962090775370598\n",
      "Epoch: 228 Iteration: 160500. Train_MSE: 0.00034066359512507915. Test_MSE: 0.04300585761666298\n",
      "Epoch: 228 Iteration: 160600. Train_MSE: 0.0004297882260289043. Test_MSE: 0.051523853093385696\n",
      "Epoch: 228 Iteration: 160700. Train_MSE: 0.012680978514254093. Test_MSE: 0.042991675436496735\n",
      "Epoch: 229 Iteration: 160800. Train_MSE: 0.012853085994720459. Test_MSE: 0.05039681866765022\n",
      "Epoch: 229 Iteration: 160900. Train_MSE: 0.0069822631776332855. Test_MSE: 0.04442325234413147\n",
      "Epoch: 229 Iteration: 161000. Train_MSE: 0.02108636312186718. Test_MSE: 0.04156797006726265\n",
      "Epoch: 229 Iteration: 161100. Train_MSE: 0.0061548687517642975. Test_MSE: 0.04950479045510292\n",
      "Epoch: 229 Iteration: 161200. Train_MSE: 0.0004938130732625723. Test_MSE: 0.0432642437517643\n",
      "Epoch: 229 Iteration: 161300. Train_MSE: 0.00048559752758592367. Test_MSE: 0.051599375903606415\n",
      "Epoch: 229 Iteration: 161400. Train_MSE: 0.009790445677936077. Test_MSE: 0.043376848101615906\n",
      "Epoch: 230 Iteration: 161500. Train_MSE: 0.020351804792881012. Test_MSE: 0.050146348774433136\n",
      "Epoch: 230 Iteration: 161600. Train_MSE: 0.010143863968551159. Test_MSE: 0.04455066844820976\n",
      "Epoch: 230 Iteration: 161700. Train_MSE: 0.023060359060764313. Test_MSE: 0.04129965230822563\n",
      "Epoch: 230 Iteration: 161800. Train_MSE: 0.012686347588896751. Test_MSE: 0.0498029850423336\n",
      "Epoch: 230 Iteration: 161900. Train_MSE: 0.00081248814240098. Test_MSE: 0.04279768094420433\n",
      "Epoch: 230 Iteration: 162000. Train_MSE: 0.000731425650883466. Test_MSE: 0.05164758116006851\n",
      "Epoch: 230 Iteration: 162100. Train_MSE: 0.008868968114256859. Test_MSE: 0.04374368488788605\n",
      "Epoch: 231 Iteration: 162200. Train_MSE: 0.017275219783186913. Test_MSE: 0.05014495551586151\n",
      "Epoch: 231 Iteration: 162300. Train_MSE: 0.0038816884625703096. Test_MSE: 0.044872596859931946\n",
      "Epoch: 231 Iteration: 162400. Train_MSE: 0.011449294164776802. Test_MSE: 0.04162265732884407\n",
      "Epoch: 231 Iteration: 162500. Train_MSE: 0.00927537027746439. Test_MSE: 0.05049128457903862\n",
      "Epoch: 231 Iteration: 162600. Train_MSE: 0.0008891277830116451. Test_MSE: 0.04355122148990631\n",
      "Epoch: 231 Iteration: 162700. Train_MSE: 0.0016847881488502026. Test_MSE: 0.05125272274017334\n",
      "Epoch: 231 Iteration: 162800. Train_MSE: 0.00941518321633339. Test_MSE: 0.04437680169939995\n",
      "Epoch: 232 Iteration: 162900. Train_MSE: 0.0072516570799052715. Test_MSE: 0.0491306446492672\n",
      "Epoch: 232 Iteration: 163000. Train_MSE: 0.005495502147823572. Test_MSE: 0.04500364512205124\n",
      "Epoch: 232 Iteration: 163100. Train_MSE: 0.008893569931387901. Test_MSE: 0.04173055291175842\n",
      "Epoch: 232 Iteration: 163200. Train_MSE: 0.012868238613009453. Test_MSE: 0.05061524733901024\n",
      "Epoch: 232 Iteration: 163300. Train_MSE: 0.001057345769368112. Test_MSE: 0.04358658194541931\n",
      "Epoch: 232 Iteration: 163400. Train_MSE: 0.0017994247609749436. Test_MSE: 0.051310472190380096\n",
      "Epoch: 232 Iteration: 163500. Train_MSE: 0.0042508868500590324. Test_MSE: 0.045068711042404175\n",
      "Epoch: 233 Iteration: 163600. Train_MSE: 0.01697378233075142. Test_MSE: 0.04847034811973572\n",
      "Epoch: 233 Iteration: 163700. Train_MSE: 0.009441941976547241. Test_MSE: 0.045313287526369095\n",
      "Epoch: 233 Iteration: 163800. Train_MSE: 0.003251025453209877. Test_MSE: 0.042158953845500946\n",
      "Epoch: 233 Iteration: 163900. Train_MSE: 0.01628374308347702. Test_MSE: 0.05128438025712967\n",
      "Epoch: 233 Iteration: 164000. Train_MSE: 0.0007714324165135622. Test_MSE: 0.04380606487393379\n",
      "Epoch: 233 Iteration: 164100. Train_MSE: 0.0011502348352223635. Test_MSE: 0.05072496086359024\n",
      "Epoch: 233 Iteration: 164200. Train_MSE: 0.017618773505091667. Test_MSE: 0.045517921447753906\n",
      "Epoch: 234 Iteration: 164300. Train_MSE: 0.03270984813570976. Test_MSE: 0.04655744135379791\n",
      "Epoch: 234 Iteration: 164400. Train_MSE: 0.005646335892379284. Test_MSE: 0.045289136469364166\n",
      "Epoch: 234 Iteration: 164500. Train_MSE: 0.00645016971975565. Test_MSE: 0.041883595287799835\n",
      "Epoch: 234 Iteration: 164600. Train_MSE: 0.0134605523198843. Test_MSE: 0.05136612430214882\n",
      "Epoch: 234 Iteration: 164700. Train_MSE: 0.0011966935126110911. Test_MSE: 0.04382874444127083\n",
      "Epoch: 234 Iteration: 164800. Train_MSE: 0.0019376862328499556. Test_MSE: 0.04947328940033913\n",
      "Epoch: 234 Iteration: 164900. Train_MSE: 0.0057203625328838825. Test_MSE: 0.04590357467532158\n",
      "Epoch: 235 Iteration: 165000. Train_MSE: 0.031729813665151596. Test_MSE: 0.04568660259246826\n",
      "Epoch: 235 Iteration: 165100. Train_MSE: 0.005091328173875809. Test_MSE: 0.045301396399736404\n",
      "Epoch: 235 Iteration: 165200. Train_MSE: 0.0018901325529441237. Test_MSE: 0.04202234372496605\n",
      "Epoch: 235 Iteration: 165300. Train_MSE: 0.012493559159338474. Test_MSE: 0.0510704405605793\n",
      "Epoch: 235 Iteration: 165400. Train_MSE: 0.002032044343650341. Test_MSE: 0.04413992911577225\n",
      "Epoch: 235 Iteration: 165500. Train_MSE: 0.0020163250155746937. Test_MSE: 0.04818805679678917\n",
      "Epoch: 235 Iteration: 165600. Train_MSE: 0.004004396963864565. Test_MSE: 0.04620644077658653\n",
      "Epoch: 236 Iteration: 165700. Train_MSE: 0.05425617843866348. Test_MSE: 0.04423320293426514\n",
      "Epoch: 236 Iteration: 165800. Train_MSE: 0.009549091570079327. Test_MSE: 0.0453522652387619\n",
      "Epoch: 236 Iteration: 165900. Train_MSE: 0.0031972164288163185. Test_MSE: 0.04222952574491501\n",
      "Epoch: 236 Iteration: 166000. Train_MSE: 0.01907513290643692. Test_MSE: 0.04979192465543747\n",
      "Epoch: 236 Iteration: 166100. Train_MSE: 0.0017936479998752475. Test_MSE: 0.04459197819232941\n",
      "Epoch: 236 Iteration: 166200. Train_MSE: 0.004701714962720871. Test_MSE: 0.04629916325211525\n",
      "Epoch: 236 Iteration: 166300. Train_MSE: 0.005084344185888767. Test_MSE: 0.04631735384464264\n",
      "Epoch: 237 Iteration: 166400. Train_MSE: 0.030609140172600746. Test_MSE: 0.04308747500181198\n",
      "Epoch: 237 Iteration: 166500. Train_MSE: 0.00816887617111206. Test_MSE: 0.04532116651535034\n",
      "Epoch: 237 Iteration: 166600. Train_MSE: 0.0014323777286335826. Test_MSE: 0.04259170591831207\n",
      "Epoch: 237 Iteration: 166700. Train_MSE: 0.009038569405674934. Test_MSE: 0.04986982420086861\n",
      "Epoch: 237 Iteration: 166800. Train_MSE: 0.003018392715603113. Test_MSE: 0.04503066837787628\n",
      "Epoch: 237 Iteration: 166900. Train_MSE: 0.0047517498023808. Test_MSE: 0.04611508175730705\n",
      "Epoch: 237 Iteration: 167000. Train_MSE: 0.001948140561580658. Test_MSE: 0.046557698398828506\n",
      "Epoch: 238 Iteration: 167100. Train_MSE: 0.0492313876748085. Test_MSE: 0.042167551815509796\n",
      "Epoch: 238 Iteration: 167200. Train_MSE: 0.01903465948998928. Test_MSE: 0.044988080859184265\n",
      "Epoch: 238 Iteration: 167300. Train_MSE: 0.00221934518776834. Test_MSE: 0.04269082471728325\n",
      "Epoch: 238 Iteration: 167400. Train_MSE: 0.013526860624551773. Test_MSE: 0.04883258789777756\n",
      "Epoch: 238 Iteration: 167500. Train_MSE: 0.004439863841980696. Test_MSE: 0.04602072015404701\n",
      "Epoch: 238 Iteration: 167600. Train_MSE: 0.004909616895020008. Test_MSE: 0.04446851834654808\n",
      "Epoch: 238 Iteration: 167700. Train_MSE: 0.0017017120262607932. Test_MSE: 0.04653450474143028\n",
      "Epoch: 239 Iteration: 167800. Train_MSE: 0.05568306893110275. Test_MSE: 0.04140912741422653\n",
      "Epoch: 239 Iteration: 167900. Train_MSE: 0.021680593490600586. Test_MSE: 0.04513101279735565\n",
      "Epoch: 239 Iteration: 168000. Train_MSE: 0.0016040382906794548. Test_MSE: 0.04295205697417259\n",
      "Epoch: 239 Iteration: 168100. Train_MSE: 0.01060702558606863. Test_MSE: 0.04850315675139427\n",
      "Epoch: 239 Iteration: 168200. Train_MSE: 0.0043380302377045155. Test_MSE: 0.046124450862407684\n",
      "Epoch: 239 Iteration: 168300. Train_MSE: 0.006819908041507006. Test_MSE: 0.043611470609903336\n",
      "Epoch: 239 Iteration: 168400. Train_MSE: 0.00019272226199973375. Test_MSE: 0.04632982984185219\n",
      "Epoch: 240 Iteration: 168500. Train_MSE: 0.08723717927932739. Test_MSE: 0.040701646357774734\n",
      "Epoch: 240 Iteration: 168600. Train_MSE: 0.02580880932509899. Test_MSE: 0.04505510628223419\n",
      "Epoch: 240 Iteration: 168700. Train_MSE: 0.012487312778830528. Test_MSE: 0.04293815791606903\n",
      "Epoch: 240 Iteration: 168800. Train_MSE: 0.00833862740546465. Test_MSE: 0.0486382395029068\n",
      "Epoch: 240 Iteration: 168900. Train_MSE: 0.004139475058764219. Test_MSE: 0.046074219048023224\n",
      "Epoch: 240 Iteration: 169000. Train_MSE: 0.008300640620291233. Test_MSE: 0.042932212352752686\n",
      "Epoch: 240 Iteration: 169100. Train_MSE: 0.0005663479678332806. Test_MSE: 0.046489641070365906\n",
      "Epoch: 241 Iteration: 169200. Train_MSE: 0.056204862892627716. Test_MSE: 0.04015130177140236\n",
      "Epoch: 241 Iteration: 169300. Train_MSE: 0.03840120881795883. Test_MSE: 0.04419158026576042\n",
      "Epoch: 241 Iteration: 169400. Train_MSE: 0.011538687162101269. Test_MSE: 0.04303468018770218\n",
      "Epoch: 241 Iteration: 169500. Train_MSE: 0.008289409801363945. Test_MSE: 0.048724278807640076\n",
      "Epoch: 241 Iteration: 169600. Train_MSE: 0.007359917741268873. Test_MSE: 0.04642178863286972\n",
      "Epoch: 241 Iteration: 169700. Train_MSE: 0.008024926297366619. Test_MSE: 0.04251222684979439\n",
      "Epoch: 241 Iteration: 169800. Train_MSE: 0.0003931339888367802. Test_MSE: 0.046112630516290665\n",
      "Epoch: 242 Iteration: 169900. Train_MSE: 0.04815162718296051. Test_MSE: 0.040295086801052094\n",
      "Epoch: 242 Iteration: 170000. Train_MSE: 0.05489293113350868. Test_MSE: 0.04418490454554558\n",
      "Epoch: 242 Iteration: 170100. Train_MSE: 0.003469324205070734. Test_MSE: 0.043137092143297195\n",
      "Epoch: 242 Iteration: 170200. Train_MSE: 0.008588357828557491. Test_MSE: 0.04834432899951935\n",
      "Epoch: 242 Iteration: 170300. Train_MSE: 0.010100297629833221. Test_MSE: 0.046316713094711304\n",
      "Epoch: 242 Iteration: 170400. Train_MSE: 0.011379523202776909. Test_MSE: 0.04185673967003822\n",
      "Epoch: 242 Iteration: 170500. Train_MSE: 0.00039726970135234296. Test_MSE: 0.04622150957584381\n",
      "Epoch: 243 Iteration: 170600. Train_MSE: 0.046802062541246414. Test_MSE: 0.04052093252539635\n",
      "Epoch: 243 Iteration: 170700. Train_MSE: 0.02580064721405506. Test_MSE: 0.04342690855264664\n",
      "Epoch: 243 Iteration: 170800. Train_MSE: 0.01748645305633545. Test_MSE: 0.043127696961164474\n",
      "Epoch: 243 Iteration: 170900. Train_MSE: 0.005625125020742416. Test_MSE: 0.04752349108457565\n",
      "Epoch: 243 Iteration: 171000. Train_MSE: 0.016345834359526634. Test_MSE: 0.046565208584070206\n",
      "Epoch: 243 Iteration: 171100. Train_MSE: 0.014113757759332657. Test_MSE: 0.04244714230298996\n",
      "Epoch: 243 Iteration: 171200. Train_MSE: 0.0005692027043551207. Test_MSE: 0.0461043082177639\n",
      "Epoch: 244 Iteration: 171300. Train_MSE: 0.0482519157230854. Test_MSE: 0.04131195694208145\n",
      "Epoch: 244 Iteration: 171400. Train_MSE: 0.031299956142902374. Test_MSE: 0.04266783595085144\n",
      "Epoch: 244 Iteration: 171500. Train_MSE: 0.028075627982616425. Test_MSE: 0.04271337389945984\n",
      "Epoch: 244 Iteration: 171600. Train_MSE: 0.006576516665518284. Test_MSE: 0.04710100218653679\n",
      "Epoch: 244 Iteration: 171700. Train_MSE: 0.011562280356884003. Test_MSE: 0.04662333428859711\n",
      "Epoch: 244 Iteration: 171800. Train_MSE: 0.005328203551471233. Test_MSE: 0.04193652421236038\n",
      "Epoch: 244 Iteration: 171900. Train_MSE: 0.0007867985405027866. Test_MSE: 0.046223852783441544\n",
      "Epoch: 245 Iteration: 172000. Train_MSE: 0.07024125754833221. Test_MSE: 0.04326855018734932\n",
      "Epoch: 245 Iteration: 172100. Train_MSE: 0.051117729395627975. Test_MSE: 0.041902925819158554\n",
      "Epoch: 245 Iteration: 172200. Train_MSE: 0.01947793923318386. Test_MSE: 0.042172621935606\n",
      "Epoch: 245 Iteration: 172300. Train_MSE: 0.004385461565107107. Test_MSE: 0.04638112336397171\n",
      "Epoch: 245 Iteration: 172400. Train_MSE: 0.008857771754264832. Test_MSE: 0.04610064625740051\n",
      "Epoch: 245 Iteration: 172500. Train_MSE: 0.003355595748871565. Test_MSE: 0.042433638125658035\n",
      "Epoch: 245 Iteration: 172600. Train_MSE: 0.0009144808282144368. Test_MSE: 0.04622872173786163\n",
      "Epoch: 246 Iteration: 172700. Train_MSE: 0.047482818365097046. Test_MSE: 0.04464947059750557\n",
      "Epoch: 246 Iteration: 172800. Train_MSE: 0.04651820287108421. Test_MSE: 0.04134028032422066\n",
      "Epoch: 246 Iteration: 172900. Train_MSE: 0.020791850984096527. Test_MSE: 0.04201345890760422\n",
      "Epoch: 246 Iteration: 173000. Train_MSE: 0.004939498845487833. Test_MSE: 0.045846741646528244\n",
      "Epoch: 246 Iteration: 173100. Train_MSE: 0.01331073883920908. Test_MSE: 0.04481370374560356\n",
      "Epoch: 246 Iteration: 173200. Train_MSE: 0.002850079908967018. Test_MSE: 0.04256044328212738\n",
      "Epoch: 246 Iteration: 173300. Train_MSE: 0.0009377740207128227. Test_MSE: 0.046400029212236404\n",
      "Epoch: 247 Iteration: 173400. Train_MSE: 0.12681707739830017. Test_MSE: 0.045415982604026794\n",
      "Epoch: 247 Iteration: 173500. Train_MSE: 0.0453023798763752. Test_MSE: 0.041517652571201324\n",
      "Epoch: 247 Iteration: 173600. Train_MSE: 0.02901897393167019. Test_MSE: 0.0414728969335556\n",
      "Epoch: 247 Iteration: 173700. Train_MSE: 0.003354595275595784. Test_MSE: 0.04504724219441414\n",
      "Epoch: 247 Iteration: 173800. Train_MSE: 0.010295560583472252. Test_MSE: 0.04447844997048378\n",
      "Epoch: 247 Iteration: 173900. Train_MSE: 0.0008632211247459054. Test_MSE: 0.04237212985754013\n",
      "Epoch: 247 Iteration: 174000. Train_MSE: 0.001365759875625372. Test_MSE: 0.046401962637901306\n",
      "Epoch: 248 Iteration: 174100. Train_MSE: 0.06546629220247269. Test_MSE: 0.04561234638094902\n",
      "Epoch: 248 Iteration: 174200. Train_MSE: 0.0459434948861599. Test_MSE: 0.04177991673350334\n",
      "Epoch: 248 Iteration: 174300. Train_MSE: 0.036183912307024. Test_MSE: 0.04142807424068451\n",
      "Epoch: 248 Iteration: 174400. Train_MSE: 0.003462090389803052. Test_MSE: 0.044775962829589844\n",
      "Epoch: 248 Iteration: 174500. Train_MSE: 0.015145745128393173. Test_MSE: 0.04477695748209953\n",
      "Epoch: 248 Iteration: 174600. Train_MSE: 0.0010932419681921601. Test_MSE: 0.04221180081367493\n",
      "Epoch: 248 Iteration: 174700. Train_MSE: 0.0015538393054157495. Test_MSE: 0.0467129647731781\n",
      "Epoch: 249 Iteration: 174800. Train_MSE: 0.06001059710979462. Test_MSE: 0.04564979299902916\n",
      "Epoch: 249 Iteration: 174900. Train_MSE: 0.07255148887634277. Test_MSE: 0.042952485382556915\n",
      "Epoch: 249 Iteration: 175000. Train_MSE: 0.0357540100812912. Test_MSE: 0.04069449007511139\n",
      "Epoch: 249 Iteration: 175100. Train_MSE: 0.0007428295793943107. Test_MSE: 0.0441686175763607\n",
      "Epoch: 249 Iteration: 175200. Train_MSE: 0.014454087242484093. Test_MSE: 0.045426640659570694\n",
      "Epoch: 249 Iteration: 175300. Train_MSE: 0.0006252428283914924. Test_MSE: 0.042468298226594925\n",
      "Epoch: 249 Iteration: 175400. Train_MSE: 0.0032015941105782986. Test_MSE: 0.04679020494222641\n",
      "Epoch: 249 Iteration: 175500. Train_MSE: 0.0061344606801867485. Test_MSE: 0.04612186178565025\n",
      "Epoch: 250 Iteration: 175600. Train_MSE: 0.0569051131606102. Test_MSE: 0.043337900191545486\n",
      "Epoch: 250 Iteration: 175700. Train_MSE: 0.02927943877875805. Test_MSE: 0.03981725126504898\n",
      "Epoch: 250 Iteration: 175800. Train_MSE: 0.0015464333118870854. Test_MSE: 0.04351304471492767\n",
      "Epoch: 250 Iteration: 175900. Train_MSE: 0.010894587263464928. Test_MSE: 0.046056654304265976\n",
      "Epoch: 250 Iteration: 176000. Train_MSE: 0.00045028439490124583. Test_MSE: 0.04245844855904579\n",
      "Epoch: 250 Iteration: 176100. Train_MSE: 0.003595955902710557. Test_MSE: 0.04701460525393486\n",
      "Epoch: 250 Iteration: 176200. Train_MSE: 0.013761370442807674. Test_MSE: 0.04665560647845268\n",
      "Epoch: 251 Iteration: 176300. Train_MSE: 0.07039841264486313. Test_MSE: 0.043561093509197235\n",
      "Epoch: 251 Iteration: 176400. Train_MSE: 0.05498436093330383. Test_MSE: 0.03952508792281151\n",
      "Epoch: 251 Iteration: 176500. Train_MSE: 0.0029000130016356707. Test_MSE: 0.04296896979212761\n",
      "Epoch: 251 Iteration: 176600. Train_MSE: 0.010336623527109623. Test_MSE: 0.04724767431616783\n",
      "Epoch: 251 Iteration: 176700. Train_MSE: 0.0010426432127133012. Test_MSE: 0.0421927347779274\n",
      "Epoch: 251 Iteration: 176800. Train_MSE: 0.004702312406152487. Test_MSE: 0.04725116491317749\n",
      "Epoch: 251 Iteration: 176900. Train_MSE: 0.00507761724293232. Test_MSE: 0.046770744025707245\n",
      "Epoch: 252 Iteration: 177000. Train_MSE: 0.08387985825538635. Test_MSE: 0.043679624795913696\n",
      "Epoch: 252 Iteration: 177100. Train_MSE: 0.043789688497781754. Test_MSE: 0.038778092712163925\n",
      "Epoch: 252 Iteration: 177200. Train_MSE: 0.01988881267607212. Test_MSE: 0.042003288865089417\n",
      "Epoch: 252 Iteration: 177300. Train_MSE: 0.008556719869375229. Test_MSE: 0.0485050305724144\n",
      "Epoch: 252 Iteration: 177400. Train_MSE: 0.0010307390475645661. Test_MSE: 0.043043702840805054\n",
      "Epoch: 252 Iteration: 177500. Train_MSE: 0.007634956855326891. Test_MSE: 0.047024499624967575\n",
      "Epoch: 252 Iteration: 177600. Train_MSE: 0.00305756158195436. Test_MSE: 0.046688780188560486\n",
      "Epoch: 253 Iteration: 177700. Train_MSE: 0.047585975378751755. Test_MSE: 0.0438171848654747\n",
      "Epoch: 253 Iteration: 177800. Train_MSE: 0.038200296461582184. Test_MSE: 0.039079420268535614\n",
      "Epoch: 253 Iteration: 177900. Train_MSE: 0.01943828910589218. Test_MSE: 0.04137043282389641\n",
      "Epoch: 253 Iteration: 178000. Train_MSE: 0.007520813494920731. Test_MSE: 0.049181193113327026\n",
      "Epoch: 253 Iteration: 178100. Train_MSE: 0.0009407380712218583. Test_MSE: 0.042268041521310806\n",
      "Epoch: 253 Iteration: 178200. Train_MSE: 0.0067078894935548306. Test_MSE: 0.04728243872523308\n",
      "Epoch: 253 Iteration: 178300. Train_MSE: 0.002812078921124339. Test_MSE: 0.04693787917494774\n",
      "Epoch: 254 Iteration: 178400. Train_MSE: 0.040195826441049576. Test_MSE: 0.04415995627641678\n",
      "Epoch: 254 Iteration: 178500. Train_MSE: 0.09255018830299377. Test_MSE: 0.03884858265519142\n",
      "Epoch: 254 Iteration: 178600. Train_MSE: 0.04521012678742409. Test_MSE: 0.04012320935726166\n",
      "Epoch: 254 Iteration: 178700. Train_MSE: 0.003917364869266748. Test_MSE: 0.04962175339460373\n",
      "Epoch: 254 Iteration: 178800. Train_MSE: 0.0015834288205951452. Test_MSE: 0.04246606305241585\n",
      "Epoch: 254 Iteration: 178900. Train_MSE: 0.008419493213295937. Test_MSE: 0.047593265771865845\n",
      "Epoch: 254 Iteration: 179000. Train_MSE: 0.005469013936817646. Test_MSE: 0.04666457697749138\n",
      "Epoch: 255 Iteration: 179100. Train_MSE: 0.04103613272309303. Test_MSE: 0.04533001035451889\n",
      "Epoch: 255 Iteration: 179200. Train_MSE: 0.10143249481916428. Test_MSE: 0.038835037499666214\n",
      "Epoch: 255 Iteration: 179300. Train_MSE: 0.02392650581896305. Test_MSE: 0.03916759416460991\n",
      "Epoch: 255 Iteration: 179400. Train_MSE: 0.0037276996299624443. Test_MSE: 0.04986168444156647\n",
      "Epoch: 255 Iteration: 179500. Train_MSE: 0.0024008306208997965. Test_MSE: 0.042234569787979126\n",
      "Epoch: 255 Iteration: 179600. Train_MSE: 0.006767380051314831. Test_MSE: 0.04815278202295303\n",
      "Epoch: 255 Iteration: 179700. Train_MSE: 0.00032636860851198435. Test_MSE: 0.047023821622133255\n",
      "Epoch: 256 Iteration: 179800. Train_MSE: 0.052536047995090485. Test_MSE: 0.04732401296496391\n",
      "Epoch: 256 Iteration: 179900. Train_MSE: 0.04524913802742958. Test_MSE: 0.03973435238003731\n",
      "Epoch: 256 Iteration: 180000. Train_MSE: 0.027277180925011635. Test_MSE: 0.03825681656599045\n",
      "Epoch: 256 Iteration: 180100. Train_MSE: 0.008452055975794792. Test_MSE: 0.05008522793650627\n",
      "Epoch: 256 Iteration: 180200. Train_MSE: 0.0028122426010668278. Test_MSE: 0.04290780425071716\n",
      "Epoch: 256 Iteration: 180300. Train_MSE: 0.008145843632519245. Test_MSE: 0.04822608083486557\n",
      "Epoch: 256 Iteration: 180400. Train_MSE: 0.00036823085974901915. Test_MSE: 0.04684223607182503\n",
      "Epoch: 257 Iteration: 180500. Train_MSE: 0.07339563965797424. Test_MSE: 0.04935089498758316\n",
      "Epoch: 257 Iteration: 180600. Train_MSE: 0.07186798006296158. Test_MSE: 0.041003189980983734\n",
      "Epoch: 257 Iteration: 180700. Train_MSE: 0.0520632229745388. Test_MSE: 0.03710547834634781\n",
      "Epoch: 257 Iteration: 180800. Train_MSE: 0.0024403894785791636. Test_MSE: 0.05071812868118286\n",
      "Epoch: 257 Iteration: 180900. Train_MSE: 0.004786372650414705. Test_MSE: 0.042360663414001465\n",
      "Epoch: 257 Iteration: 181000. Train_MSE: 0.01057745423167944. Test_MSE: 0.04813593998551369\n",
      "Epoch: 257 Iteration: 181100. Train_MSE: 0.0005418813088908792. Test_MSE: 0.04654859006404877\n",
      "Epoch: 258 Iteration: 181200. Train_MSE: 0.05265333503484726. Test_MSE: 0.05010788142681122\n",
      "Epoch: 258 Iteration: 181300. Train_MSE: 0.06258546561002731. Test_MSE: 0.04340997710824013\n",
      "Epoch: 258 Iteration: 181400. Train_MSE: 0.04840915650129318. Test_MSE: 0.03700605034828186\n",
      "Epoch: 258 Iteration: 181500. Train_MSE: 0.002022466855123639. Test_MSE: 0.05052287131547928\n",
      "Epoch: 258 Iteration: 181600. Train_MSE: 0.007993761450052261. Test_MSE: 0.04234444722533226\n",
      "Epoch: 258 Iteration: 181700. Train_MSE: 0.0074632721953094006. Test_MSE: 0.04805877059698105\n",
      "Epoch: 258 Iteration: 181800. Train_MSE: 0.0010698680998757482. Test_MSE: 0.046940192580223083\n",
      "Epoch: 259 Iteration: 181900. Train_MSE: 0.07141570746898651. Test_MSE: 0.049687404185533524\n",
      "Epoch: 259 Iteration: 182000. Train_MSE: 0.05610243231058121. Test_MSE: 0.044761914759874344\n",
      "Epoch: 259 Iteration: 182100. Train_MSE: 0.05800764635205269. Test_MSE: 0.036622487008571625\n",
      "Epoch: 259 Iteration: 182200. Train_MSE: 0.001138149993494153. Test_MSE: 0.050655681639909744\n",
      "Epoch: 259 Iteration: 182300. Train_MSE: 0.007890979759395123. Test_MSE: 0.042552802711725235\n",
      "Epoch: 259 Iteration: 182400. Train_MSE: 0.011128358542919159. Test_MSE: 0.04713848978281021\n",
      "Epoch: 259 Iteration: 182500. Train_MSE: 0.001225561834871769. Test_MSE: 0.04638173058629036\n",
      "Epoch: 260 Iteration: 182600. Train_MSE: 0.071803018450737. Test_MSE: 0.049961891025304794\n",
      "Epoch: 260 Iteration: 182700. Train_MSE: 0.07363077253103256. Test_MSE: 0.04761150851845741\n",
      "Epoch: 260 Iteration: 182800. Train_MSE: 0.066886767745018. Test_MSE: 0.03749746084213257\n",
      "Epoch: 260 Iteration: 182900. Train_MSE: 0.00033809535671025515. Test_MSE: 0.050461601465940475\n",
      "Epoch: 260 Iteration: 183000. Train_MSE: 0.0068563250824809074. Test_MSE: 0.04328768327832222\n",
      "Epoch: 260 Iteration: 183100. Train_MSE: 0.013676661998033524. Test_MSE: 0.04688197001814842\n",
      "Epoch: 260 Iteration: 183200. Train_MSE: 0.002188396407291293. Test_MSE: 0.04643920436501503\n",
      "Epoch: 261 Iteration: 183300. Train_MSE: 0.05608564242720604. Test_MSE: 0.04920824617147446\n",
      "Epoch: 261 Iteration: 183400. Train_MSE: 0.05724472552537918. Test_MSE: 0.050129976123571396\n",
      "Epoch: 261 Iteration: 183500. Train_MSE: 0.061696019023656845. Test_MSE: 0.03839370608329773\n",
      "Epoch: 261 Iteration: 183600. Train_MSE: 0.0005062383133918047. Test_MSE: 0.05080581083893776\n",
      "Epoch: 261 Iteration: 183700. Train_MSE: 0.00829875934869051. Test_MSE: 0.04412417858839035\n",
      "Epoch: 261 Iteration: 183800. Train_MSE: 0.010492567904293537. Test_MSE: 0.046855878084897995\n",
      "Epoch: 261 Iteration: 183900. Train_MSE: 0.0022530658170580864. Test_MSE: 0.046562567353248596\n",
      "Epoch: 262 Iteration: 184000. Train_MSE: 0.026044733822345734. Test_MSE: 0.048920370638370514\n",
      "Epoch: 262 Iteration: 184100. Train_MSE: 0.05025063082575798. Test_MSE: 0.052580561488866806\n",
      "Epoch: 262 Iteration: 184200. Train_MSE: 0.056227635592222214. Test_MSE: 0.039153438061475754\n",
      "Epoch: 262 Iteration: 184300. Train_MSE: 0.0002043767599388957. Test_MSE: 0.05058271065354347\n",
      "Epoch: 262 Iteration: 184400. Train_MSE: 0.011098120361566544. Test_MSE: 0.04487570747733116\n",
      "Epoch: 262 Iteration: 184500. Train_MSE: 0.007187364157289267. Test_MSE: 0.04645311459898949\n",
      "Epoch: 262 Iteration: 184600. Train_MSE: 0.002192030195146799. Test_MSE: 0.04613949730992317\n",
      "Epoch: 263 Iteration: 184700. Train_MSE: 0.05210929736495018. Test_MSE: 0.049410585314035416\n",
      "Epoch: 263 Iteration: 184800. Train_MSE: 0.0772077813744545. Test_MSE: 0.055583130568265915\n",
      "Epoch: 263 Iteration: 184900. Train_MSE: 0.04137510806322098. Test_MSE: 0.040820296853780746\n",
      "Epoch: 263 Iteration: 185000. Train_MSE: 0.0003163125365972519. Test_MSE: 0.05131173133850098\n",
      "Epoch: 263 Iteration: 185100. Train_MSE: 0.01194344274699688. Test_MSE: 0.046600379049777985\n",
      "Epoch: 263 Iteration: 185200. Train_MSE: 0.011352837085723877. Test_MSE: 0.045473869889974594\n",
      "Epoch: 263 Iteration: 185300. Train_MSE: 0.002859016414731741. Test_MSE: 0.045504115521907806\n",
      "Epoch: 264 Iteration: 185400. Train_MSE: 0.05014197900891304. Test_MSE: 0.04907830432057381\n",
      "Epoch: 264 Iteration: 185500. Train_MSE: 0.067914217710495. Test_MSE: 0.05582335963845253\n",
      "Epoch: 264 Iteration: 185600. Train_MSE: 0.0407964326441288. Test_MSE: 0.0425574965775013\n",
      "Epoch: 264 Iteration: 185700. Train_MSE: 0.00028014203417114913. Test_MSE: 0.05050521343946457\n",
      "Epoch: 264 Iteration: 185800. Train_MSE: 0.012301167473196983. Test_MSE: 0.04775266721844673\n",
      "Epoch: 264 Iteration: 185900. Train_MSE: 0.008828394114971161. Test_MSE: 0.045681193470954895\n",
      "Epoch: 264 Iteration: 186000. Train_MSE: 0.004313185811042786. Test_MSE: 0.04517868161201477\n",
      "Epoch: 265 Iteration: 186100. Train_MSE: 0.03874731808900833. Test_MSE: 0.049232106655836105\n",
      "Epoch: 265 Iteration: 186200. Train_MSE: 0.045318301767110825. Test_MSE: 0.055081807076931\n",
      "Epoch: 265 Iteration: 186300. Train_MSE: 0.07419553399085999. Test_MSE: 0.04395531117916107\n",
      "Epoch: 265 Iteration: 186400. Train_MSE: 0.0003369582409504801. Test_MSE: 0.050765346735715866\n",
      "Epoch: 265 Iteration: 186500. Train_MSE: 0.012554232031106949. Test_MSE: 0.048082415014505386\n",
      "Epoch: 265 Iteration: 186600. Train_MSE: 0.007215132936835289. Test_MSE: 0.04636174440383911\n",
      "Epoch: 265 Iteration: 186700. Train_MSE: 0.003703370690345764. Test_MSE: 0.0452096201479435\n",
      "Epoch: 266 Iteration: 186800. Train_MSE: 0.02336486056447029. Test_MSE: 0.04881328344345093\n",
      "Epoch: 266 Iteration: 186900. Train_MSE: 0.07374703884124756. Test_MSE: 0.05355765298008919\n",
      "Epoch: 266 Iteration: 187000. Train_MSE: 0.04948888719081879. Test_MSE: 0.04595499113202095\n",
      "Epoch: 266 Iteration: 187100. Train_MSE: 0.0003739752573892474. Test_MSE: 0.05065542459487915\n",
      "Epoch: 266 Iteration: 187200. Train_MSE: 0.015416840091347694. Test_MSE: 0.04834219813346863\n",
      "Epoch: 266 Iteration: 187300. Train_MSE: 0.01889997534453869. Test_MSE: 0.04693741351366043\n",
      "Epoch: 266 Iteration: 187400. Train_MSE: 0.003961616661399603. Test_MSE: 0.04506370425224304\n",
      "Epoch: 267 Iteration: 187500. Train_MSE: 0.03453271463513374. Test_MSE: 0.048710115253925323\n",
      "Epoch: 267 Iteration: 187600. Train_MSE: 0.05406307056546211. Test_MSE: 0.05196583271026611\n",
      "Epoch: 267 Iteration: 187700. Train_MSE: 0.06384836882352829. Test_MSE: 0.047812141478061676\n",
      "Epoch: 267 Iteration: 187800. Train_MSE: 0.0015563640045002103. Test_MSE: 0.051017798483371735\n",
      "Epoch: 267 Iteration: 187900. Train_MSE: 0.009554428979754448. Test_MSE: 0.04790772870182991\n",
      "Epoch: 267 Iteration: 188000. Train_MSE: 0.007706342730671167. Test_MSE: 0.047484319657087326\n",
      "Epoch: 267 Iteration: 188100. Train_MSE: 0.006822108756750822. Test_MSE: 0.04462527483701706\n",
      "Epoch: 268 Iteration: 188200. Train_MSE: 0.019719498232007027. Test_MSE: 0.048782575875520706\n",
      "Epoch: 268 Iteration: 188300. Train_MSE: 0.049217481166124344. Test_MSE: 0.049775637686252594\n",
      "Epoch: 268 Iteration: 188400. Train_MSE: 0.05742590129375458. Test_MSE: 0.0494086928665638\n",
      "Epoch: 268 Iteration: 188500. Train_MSE: 0.0014436576748266816. Test_MSE: 0.049941934645175934\n",
      "Epoch: 268 Iteration: 188600. Train_MSE: 0.008277895860373974. Test_MSE: 0.04608876258134842\n",
      "Epoch: 268 Iteration: 188700. Train_MSE: 0.005520399659872055. Test_MSE: 0.048190467059612274\n",
      "Epoch: 268 Iteration: 188800. Train_MSE: 0.0054894061759114265. Test_MSE: 0.04436168074607849\n",
      "Epoch: 269 Iteration: 188900. Train_MSE: 0.03140553832054138. Test_MSE: 0.04851769283413887\n",
      "Epoch: 269 Iteration: 189000. Train_MSE: 0.055226609110832214. Test_MSE: 0.04874085262417793\n",
      "Epoch: 269 Iteration: 189100. Train_MSE: 0.0736285001039505. Test_MSE: 0.05036957561969757\n",
      "Epoch: 269 Iteration: 189200. Train_MSE: 0.001905296347104013. Test_MSE: 0.04995783790946007\n",
      "Epoch: 269 Iteration: 189300. Train_MSE: 0.014394345693290234. Test_MSE: 0.0444476455450058\n",
      "Epoch: 269 Iteration: 189400. Train_MSE: 0.006366587243974209. Test_MSE: 0.04887238144874573\n",
      "Epoch: 269 Iteration: 189500. Train_MSE: 0.007323483005166054. Test_MSE: 0.04393881931900978\n",
      "Epoch: 270 Iteration: 189600. Train_MSE: 0.0072054252959787846. Test_MSE: 0.04874115437269211\n",
      "Epoch: 270 Iteration: 189700. Train_MSE: 0.041962966322898865. Test_MSE: 0.048078447580337524\n",
      "Epoch: 270 Iteration: 189800. Train_MSE: 0.054332103580236435. Test_MSE: 0.05037442594766617\n",
      "Epoch: 270 Iteration: 189900. Train_MSE: 0.0032120614778250456. Test_MSE: 0.0502840131521225\n",
      "Epoch: 270 Iteration: 190000. Train_MSE: 0.014633305370807648. Test_MSE: 0.043738026171922684\n",
      "Epoch: 270 Iteration: 190100. Train_MSE: 0.00642817560583353. Test_MSE: 0.04987353831529617\n",
      "Epoch: 270 Iteration: 190200. Train_MSE: 0.00865976046770811. Test_MSE: 0.044239018112421036\n",
      "Epoch: 271 Iteration: 190300. Train_MSE: 0.02504641003906727. Test_MSE: 0.04815392941236496\n",
      "Epoch: 271 Iteration: 190400. Train_MSE: 0.02395368181169033. Test_MSE: 0.046897176653146744\n",
      "Epoch: 271 Iteration: 190500. Train_MSE: 0.04460952430963516. Test_MSE: 0.04923718050122261\n",
      "Epoch: 271 Iteration: 190600. Train_MSE: 0.0049880794249475. Test_MSE: 0.04958725720643997\n",
      "Epoch: 271 Iteration: 190700. Train_MSE: 0.012246530503034592. Test_MSE: 0.04323992133140564\n",
      "Epoch: 271 Iteration: 190800. Train_MSE: 0.01017661765217781. Test_MSE: 0.0502636693418026\n",
      "Epoch: 271 Iteration: 190900. Train_MSE: 0.009176954627037048. Test_MSE: 0.04411265626549721\n",
      "Epoch: 272 Iteration: 191000. Train_MSE: 0.0027351132594048977. Test_MSE: 0.04854905232787132\n",
      "Epoch: 272 Iteration: 191100. Train_MSE: 0.06162149831652641. Test_MSE: 0.046168770641088486\n",
      "Epoch: 272 Iteration: 191200. Train_MSE: 0.08160488307476044. Test_MSE: 0.047647979110479355\n",
      "Epoch: 272 Iteration: 191300. Train_MSE: 0.005694559775292873. Test_MSE: 0.049531806260347366\n",
      "Epoch: 272 Iteration: 191400. Train_MSE: 0.016325566917657852. Test_MSE: 0.042939193546772\n",
      "Epoch: 272 Iteration: 191500. Train_MSE: 0.005608844570815563. Test_MSE: 0.0512971505522728\n",
      "Epoch: 272 Iteration: 191600. Train_MSE: 0.006984932813793421. Test_MSE: 0.04480837285518646\n",
      "Epoch: 273 Iteration: 191700. Train_MSE: 0.010559299029409885. Test_MSE: 0.0486544668674469\n",
      "Epoch: 273 Iteration: 191800. Train_MSE: 0.014187401160597801. Test_MSE: 0.04574388265609741\n",
      "Epoch: 273 Iteration: 191900. Train_MSE: 0.03597128391265869. Test_MSE: 0.04488256573677063\n",
      "Epoch: 273 Iteration: 192000. Train_MSE: 0.00383119098842144. Test_MSE: 0.04927641153335571\n",
      "Epoch: 273 Iteration: 192100. Train_MSE: 0.0033102501183748245. Test_MSE: 0.04300921410322189\n",
      "Epoch: 273 Iteration: 192200. Train_MSE: 0.007469616364687681. Test_MSE: 0.05170878395438194\n",
      "Epoch: 273 Iteration: 192300. Train_MSE: 0.007015271577984095. Test_MSE: 0.04504252225160599\n",
      "Epoch: 274 Iteration: 192400. Train_MSE: 0.0013549980940297246. Test_MSE: 0.04864124581217766\n",
      "Epoch: 274 Iteration: 192500. Train_MSE: 0.04331578314304352. Test_MSE: 0.045071788132190704\n",
      "Epoch: 274 Iteration: 192600. Train_MSE: 0.09687654674053192. Test_MSE: 0.04287073761224747\n",
      "Epoch: 274 Iteration: 192700. Train_MSE: 0.0062798322178423405. Test_MSE: 0.04913521930575371\n",
      "Epoch: 274 Iteration: 192800. Train_MSE: 0.00010897835454670712. Test_MSE: 0.042822450399398804\n",
      "Epoch: 274 Iteration: 192900. Train_MSE: 0.0020242079626768827. Test_MSE: 0.05180790275335312\n",
      "Epoch: 274 Iteration: 193000. Train_MSE: 0.008018161170184612. Test_MSE: 0.045129138976335526\n",
      "Epoch: 275 Iteration: 193100. Train_MSE: 0.006846700794994831. Test_MSE: 0.049129460006952286\n",
      "Epoch: 275 Iteration: 193200. Train_MSE: 0.025188235566020012. Test_MSE: 0.044619783759117126\n",
      "Epoch: 275 Iteration: 193300. Train_MSE: 0.05625348165631294. Test_MSE: 0.04162440821528435\n",
      "Epoch: 275 Iteration: 193400. Train_MSE: 0.006986779160797596. Test_MSE: 0.04923652112483978\n",
      "Epoch: 275 Iteration: 193500. Train_MSE: 0.0013942436780780554. Test_MSE: 0.042669475078582764\n",
      "Epoch: 275 Iteration: 193600. Train_MSE: 0.001743128290399909. Test_MSE: 0.05103098228573799\n",
      "Epoch: 275 Iteration: 193700. Train_MSE: 0.009414713829755783. Test_MSE: 0.04459116980433464\n",
      "Epoch: 276 Iteration: 193800. Train_MSE: 0.0040116626769304276. Test_MSE: 0.049715057015419006\n",
      "Epoch: 276 Iteration: 193900. Train_MSE: 0.00940838921815157. Test_MSE: 0.04466824233531952\n",
      "Epoch: 276 Iteration: 194000. Train_MSE: 0.04601588100194931. Test_MSE: 0.04187164828181267\n",
      "Epoch: 276 Iteration: 194100. Train_MSE: 0.011845668777823448. Test_MSE: 0.04928642138838768\n",
      "Epoch: 276 Iteration: 194200. Train_MSE: 0.00013881752965971828. Test_MSE: 0.04326636716723442\n",
      "Epoch: 276 Iteration: 194300. Train_MSE: 0.0007283753366209567. Test_MSE: 0.05083495378494263\n",
      "Epoch: 276 Iteration: 194400. Train_MSE: 0.011447731405496597. Test_MSE: 0.0437895692884922\n",
      "Epoch: 277 Iteration: 194500. Train_MSE: 0.005923803895711899. Test_MSE: 0.05021769553422928\n",
      "Epoch: 277 Iteration: 194600. Train_MSE: 0.005663835443556309. Test_MSE: 0.044625550508499146\n",
      "Epoch: 277 Iteration: 194700. Train_MSE: 0.023824887350201607. Test_MSE: 0.04196823015809059\n",
      "Epoch: 277 Iteration: 194800. Train_MSE: 0.008899345062673092. Test_MSE: 0.050111882388591766\n",
      "Epoch: 277 Iteration: 194900. Train_MSE: 0.00030258207698352635. Test_MSE: 0.042772773653268814\n",
      "Epoch: 277 Iteration: 195000. Train_MSE: 0.0005661100149154663. Test_MSE: 0.052000951021909714\n",
      "Epoch: 277 Iteration: 195100. Train_MSE: 0.0058360653929412365. Test_MSE: 0.043264683336019516\n",
      "Epoch: 278 Iteration: 195200. Train_MSE: 0.002769296756014228. Test_MSE: 0.05034291371703148\n",
      "Epoch: 278 Iteration: 195300. Train_MSE: 0.004770621657371521. Test_MSE: 0.04464958235621452\n",
      "Epoch: 278 Iteration: 195400. Train_MSE: 0.024140646681189537. Test_MSE: 0.041757743805646896\n",
      "Epoch: 278 Iteration: 195500. Train_MSE: 0.01060906145721674. Test_MSE: 0.05013652890920639\n",
      "Epoch: 278 Iteration: 195600. Train_MSE: 0.000806447584182024. Test_MSE: 0.04307010397315025\n",
      "Epoch: 278 Iteration: 195700. Train_MSE: 0.0005486941081471741. Test_MSE: 0.05247141048312187\n",
      "Epoch: 278 Iteration: 195800. Train_MSE: 0.012613236904144287. Test_MSE: 0.0429210402071476\n",
      "Epoch: 279 Iteration: 195900. Train_MSE: 0.012939677573740482. Test_MSE: 0.05058685317635536\n",
      "Epoch: 279 Iteration: 196000. Train_MSE: 0.006990095600485802. Test_MSE: 0.04438900575041771\n",
      "Epoch: 279 Iteration: 196100. Train_MSE: 0.02071678638458252. Test_MSE: 0.0416652150452137\n",
      "Epoch: 279 Iteration: 196200. Train_MSE: 0.0062118773348629475. Test_MSE: 0.04966861754655838\n",
      "Epoch: 279 Iteration: 196300. Train_MSE: 0.0003094774147029966. Test_MSE: 0.04338230565190315\n",
      "Epoch: 279 Iteration: 196400. Train_MSE: 0.000610595743637532. Test_MSE: 0.0512266680598259\n",
      "Epoch: 279 Iteration: 196500. Train_MSE: 0.009723071940243244. Test_MSE: 0.04344091936945915\n",
      "Epoch: 280 Iteration: 196600. Train_MSE: 0.020080305635929108. Test_MSE: 0.050459276884794235\n",
      "Epoch: 280 Iteration: 196700. Train_MSE: 0.010212231427431107. Test_MSE: 0.044608354568481445\n",
      "Epoch: 280 Iteration: 196800. Train_MSE: 0.024160971865057945. Test_MSE: 0.041679371148347855\n",
      "Epoch: 280 Iteration: 196900. Train_MSE: 0.01252945140004158. Test_MSE: 0.049839943647384644\n",
      "Epoch: 280 Iteration: 197000. Train_MSE: 0.0007293077651411295. Test_MSE: 0.04378118738532066\n",
      "Epoch: 280 Iteration: 197100. Train_MSE: 0.0008591634104959667. Test_MSE: 0.051431700587272644\n",
      "Epoch: 280 Iteration: 197200. Train_MSE: 0.009237665683031082. Test_MSE: 0.04377951845526695\n",
      "Epoch: 281 Iteration: 197300. Train_MSE: 0.016976764425635338. Test_MSE: 0.050031792372465134\n",
      "Epoch: 281 Iteration: 197400. Train_MSE: 0.0038138735108077526. Test_MSE: 0.04469631239771843\n",
      "Epoch: 281 Iteration: 197500. Train_MSE: 0.012678057886660099. Test_MSE: 0.04162880405783653\n",
      "Epoch: 281 Iteration: 197600. Train_MSE: 0.009558295831084251. Test_MSE: 0.0504942387342453\n",
      "Epoch: 281 Iteration: 197700. Train_MSE: 0.0006700217491015792. Test_MSE: 0.04309074580669403\n",
      "Epoch: 281 Iteration: 197800. Train_MSE: 0.0015747997676953673. Test_MSE: 0.05098961293697357\n",
      "Epoch: 281 Iteration: 197900. Train_MSE: 0.009654342196881771. Test_MSE: 0.04446125030517578\n",
      "Epoch: 282 Iteration: 198000. Train_MSE: 0.007407995406538248. Test_MSE: 0.049141764640808105\n",
      "Epoch: 282 Iteration: 198100. Train_MSE: 0.005435148254036903. Test_MSE: 0.04494618624448776\n",
      "Epoch: 282 Iteration: 198200. Train_MSE: 0.00842722412198782. Test_MSE: 0.04182163253426552\n",
      "Epoch: 282 Iteration: 198300. Train_MSE: 0.012940306216478348. Test_MSE: 0.05122354254126549\n",
      "Epoch: 282 Iteration: 198400. Train_MSE: 0.001139839761890471. Test_MSE: 0.04397450387477875\n",
      "Epoch: 282 Iteration: 198500. Train_MSE: 0.001660908805206418. Test_MSE: 0.05089506879448891\n",
      "Epoch: 282 Iteration: 198600. Train_MSE: 0.004189822822809219. Test_MSE: 0.044956572353839874\n",
      "Epoch: 283 Iteration: 198700. Train_MSE: 0.017070341855287552. Test_MSE: 0.04792585223913193\n",
      "Epoch: 283 Iteration: 198800. Train_MSE: 0.009606296196579933. Test_MSE: 0.045051127672195435\n",
      "Epoch: 283 Iteration: 198900. Train_MSE: 0.002687435131520033. Test_MSE: 0.0417264886200428\n",
      "Epoch: 283 Iteration: 199000. Train_MSE: 0.016821766272187233. Test_MSE: 0.05154232308268547\n",
      "Epoch: 283 Iteration: 199100. Train_MSE: 0.0007580374367535114. Test_MSE: 0.04400875046849251\n",
      "Epoch: 283 Iteration: 199200. Train_MSE: 0.001142127555795014. Test_MSE: 0.05050036683678627\n",
      "Epoch: 283 Iteration: 199300. Train_MSE: 0.01837540604174137. Test_MSE: 0.0455438457429409\n",
      "Epoch: 284 Iteration: 199400. Train_MSE: 0.03236900642514229. Test_MSE: 0.0466369092464447\n",
      "Epoch: 284 Iteration: 199500. Train_MSE: 0.005591026972979307. Test_MSE: 0.04502547159790993\n",
      "Epoch: 284 Iteration: 199600. Train_MSE: 0.0062833814881742. Test_MSE: 0.04171518236398697\n",
      "Epoch: 284 Iteration: 199700. Train_MSE: 0.013361593708395958. Test_MSE: 0.05154632031917572\n",
      "Epoch: 284 Iteration: 199800. Train_MSE: 0.001273107249289751. Test_MSE: 0.04411735758185387\n",
      "Epoch: 284 Iteration: 199900. Train_MSE: 0.001915366854518652. Test_MSE: 0.0501989983022213\n",
      "Epoch: 284 Iteration: 200000. Train_MSE: 0.005746111273765564. Test_MSE: 0.045815229415893555\n",
      "Epoch: 285 Iteration: 200100. Train_MSE: 0.03253748267889023. Test_MSE: 0.044752087444067\n",
      "Epoch: 285 Iteration: 200200. Train_MSE: 0.00507747707888484. Test_MSE: 0.044998351484537125\n",
      "Epoch: 285 Iteration: 200300. Train_MSE: 0.0017856087069958448. Test_MSE: 0.04166249558329582\n",
      "Epoch: 285 Iteration: 200400. Train_MSE: 0.01252720970660448. Test_MSE: 0.051026441156864166\n",
      "Epoch: 285 Iteration: 200500. Train_MSE: 0.0018000792479142547. Test_MSE: 0.04424723982810974\n",
      "Epoch: 285 Iteration: 200600. Train_MSE: 0.0016275550005957484. Test_MSE: 0.04789047688245773\n",
      "Epoch: 285 Iteration: 200700. Train_MSE: 0.004296683240681887. Test_MSE: 0.045760564506053925\n",
      "Epoch: 286 Iteration: 200800. Train_MSE: 0.05249688774347305. Test_MSE: 0.044192660599946976\n",
      "Epoch: 286 Iteration: 200900. Train_MSE: 0.009431485086679459. Test_MSE: 0.04501310735940933\n",
      "Epoch: 286 Iteration: 201000. Train_MSE: 0.0019879078026860952. Test_MSE: 0.04184482619166374\n",
      "Epoch: 286 Iteration: 201100. Train_MSE: 0.018507767468690872. Test_MSE: 0.050269246101379395\n",
      "Epoch: 286 Iteration: 201200. Train_MSE: 0.0017846659757196903. Test_MSE: 0.04459377005696297\n",
      "Epoch: 286 Iteration: 201300. Train_MSE: 0.004050449468195438. Test_MSE: 0.047392260283231735\n",
      "Epoch: 286 Iteration: 201400. Train_MSE: 0.005436948034912348. Test_MSE: 0.04694619029760361\n",
      "Epoch: 287 Iteration: 201500. Train_MSE: 0.03054696135222912. Test_MSE: 0.04298459365963936\n",
      "Epoch: 287 Iteration: 201600. Train_MSE: 0.007925907149910927. Test_MSE: 0.045017059892416\n",
      "Epoch: 287 Iteration: 201700. Train_MSE: 0.0013859036844223738. Test_MSE: 0.04229282960295677\n",
      "Epoch: 287 Iteration: 201800. Train_MSE: 0.009067374281585217. Test_MSE: 0.04950954020023346\n",
      "Epoch: 287 Iteration: 201900. Train_MSE: 0.00297585129737854. Test_MSE: 0.04487135633826256\n",
      "Epoch: 287 Iteration: 202000. Train_MSE: 0.004664732608944178. Test_MSE: 0.0460083894431591\n",
      "Epoch: 287 Iteration: 202100. Train_MSE: 0.0022391630336642265. Test_MSE: 0.04662005603313446\n",
      "Epoch: 288 Iteration: 202200. Train_MSE: 0.04823751002550125. Test_MSE: 0.04186691716313362\n",
      "Epoch: 288 Iteration: 202300. Train_MSE: 0.01867770031094551. Test_MSE: 0.044619154185056686\n",
      "Epoch: 288 Iteration: 202400. Train_MSE: 0.0022510457783937454. Test_MSE: 0.04226303473114967\n",
      "Epoch: 288 Iteration: 202500. Train_MSE: 0.013670546002686024. Test_MSE: 0.048725053668022156\n",
      "Epoch: 288 Iteration: 202600. Train_MSE: 0.004245988558977842. Test_MSE: 0.045224983245134354\n",
      "Epoch: 288 Iteration: 202700. Train_MSE: 0.004690193105489016. Test_MSE: 0.0446009561419487\n",
      "Epoch: 288 Iteration: 202800. Train_MSE: 0.001750544412061572. Test_MSE: 0.04661067947745323\n",
      "Epoch: 289 Iteration: 202900. Train_MSE: 0.0559736005961895. Test_MSE: 0.04102015867829323\n",
      "Epoch: 289 Iteration: 203000. Train_MSE: 0.021565193310379982. Test_MSE: 0.04458632692694664\n",
      "Epoch: 289 Iteration: 203100. Train_MSE: 0.0020250314846634865. Test_MSE: 0.042364489287137985\n",
      "Epoch: 289 Iteration: 203200. Train_MSE: 0.010542353615164757. Test_MSE: 0.04805759713053703\n",
      "Epoch: 289 Iteration: 203300. Train_MSE: 0.004176007583737373. Test_MSE: 0.04579433053731918\n",
      "Epoch: 289 Iteration: 203400. Train_MSE: 0.006940312217921019. Test_MSE: 0.04354766756296158\n",
      "Epoch: 289 Iteration: 203500. Train_MSE: 0.0003303338307887316. Test_MSE: 0.04636609926819801\n",
      "Epoch: 290 Iteration: 203600. Train_MSE: 0.08720388263463974. Test_MSE: 0.04037494957447052\n",
      "Epoch: 290 Iteration: 203700. Train_MSE: 0.02603171020746231. Test_MSE: 0.04434145987033844\n",
      "Epoch: 290 Iteration: 203800. Train_MSE: 0.012496682815253735. Test_MSE: 0.04240506887435913\n",
      "Epoch: 290 Iteration: 203900. Train_MSE: 0.00833563320338726. Test_MSE: 0.048236340284347534\n",
      "Epoch: 290 Iteration: 204000. Train_MSE: 0.0040507870726287365. Test_MSE: 0.04653146490454674\n",
      "Epoch: 290 Iteration: 204100. Train_MSE: 0.008265238255262375. Test_MSE: 0.0428890734910965\n",
      "Epoch: 290 Iteration: 204200. Train_MSE: 0.00039226721855811775. Test_MSE: 0.04614415764808655\n",
      "Epoch: 291 Iteration: 204300. Train_MSE: 0.05575016140937805. Test_MSE: 0.03968673199415207\n",
      "Epoch: 291 Iteration: 204400. Train_MSE: 0.03878224641084671. Test_MSE: 0.04409387335181236\n",
      "Epoch: 291 Iteration: 204500. Train_MSE: 0.011701308190822601. Test_MSE: 0.04262391850352287\n",
      "Epoch: 291 Iteration: 204600. Train_MSE: 0.00794616062194109. Test_MSE: 0.048381879925727844\n",
      "Epoch: 291 Iteration: 204700. Train_MSE: 0.007052169647067785. Test_MSE: 0.04648269712924957\n",
      "Epoch: 291 Iteration: 204800. Train_MSE: 0.007906279526650906. Test_MSE: 0.04258209094405174\n",
      "Epoch: 291 Iteration: 204900. Train_MSE: 0.0006011903751641512. Test_MSE: 0.04624715447425842\n",
      "Epoch: 292 Iteration: 205000. Train_MSE: 0.04810052737593651. Test_MSE: 0.04006796330213547\n",
      "Epoch: 292 Iteration: 205100. Train_MSE: 0.05464392527937889. Test_MSE: 0.04365569353103638\n",
      "Epoch: 292 Iteration: 205200. Train_MSE: 0.0033949578646570444. Test_MSE: 0.042610347270965576\n",
      "Epoch: 292 Iteration: 205300. Train_MSE: 0.0085015669465065. Test_MSE: 0.04791431128978729\n",
      "Epoch: 292 Iteration: 205400. Train_MSE: 0.010134484618902206. Test_MSE: 0.04621557146310806\n",
      "Epoch: 292 Iteration: 205500. Train_MSE: 0.011177556589245796. Test_MSE: 0.04224532097578049\n",
      "Epoch: 292 Iteration: 205600. Train_MSE: 0.0005718047032132745. Test_MSE: 0.04610982537269592\n",
      "Epoch: 293 Iteration: 205700. Train_MSE: 0.04768075793981552. Test_MSE: 0.040377844125032425\n",
      "Epoch: 293 Iteration: 205800. Train_MSE: 0.025858838111162186. Test_MSE: 0.04296577721834183\n",
      "Epoch: 293 Iteration: 205900. Train_MSE: 0.01744813844561577. Test_MSE: 0.0426260381937027\n",
      "Epoch: 293 Iteration: 206000. Train_MSE: 0.005735559388995171. Test_MSE: 0.04728249832987785\n",
      "Epoch: 293 Iteration: 206100. Train_MSE: 0.016270454972982407. Test_MSE: 0.046385399997234344\n",
      "Epoch: 293 Iteration: 206200. Train_MSE: 0.014079484157264233. Test_MSE: 0.04263867065310478\n",
      "Epoch: 293 Iteration: 206300. Train_MSE: 0.0005461634718813002. Test_MSE: 0.04605085402727127\n",
      "Epoch: 294 Iteration: 206400. Train_MSE: 0.04863440990447998. Test_MSE: 0.04107222333550453\n",
      "Epoch: 294 Iteration: 206500. Train_MSE: 0.0310913547873497. Test_MSE: 0.04222691059112549\n",
      "Epoch: 294 Iteration: 206600. Train_MSE: 0.02844947762787342. Test_MSE: 0.04217798635363579\n",
      "Epoch: 294 Iteration: 206700. Train_MSE: 0.006589892320334911. Test_MSE: 0.04680737480521202\n",
      "Epoch: 294 Iteration: 206800. Train_MSE: 0.011365183629095554. Test_MSE: 0.046360816806554794\n",
      "Epoch: 294 Iteration: 206900. Train_MSE: 0.005252200178802013. Test_MSE: 0.04269973188638687\n",
      "Epoch: 294 Iteration: 207000. Train_MSE: 0.0010491682915017009. Test_MSE: 0.04662588611245155\n",
      "Epoch: 295 Iteration: 207100. Train_MSE: 0.0698355883359909. Test_MSE: 0.04311249405145645\n",
      "Epoch: 295 Iteration: 207200. Train_MSE: 0.05110691115260124. Test_MSE: 0.0417044423520565\n",
      "Epoch: 295 Iteration: 207300. Train_MSE: 0.01958843693137169. Test_MSE: 0.04187045618891716\n",
      "Epoch: 295 Iteration: 207400. Train_MSE: 0.00402934430167079. Test_MSE: 0.046321455389261246\n",
      "Epoch: 295 Iteration: 207500. Train_MSE: 0.008730506524443626. Test_MSE: 0.046075381338596344\n",
      "Epoch: 295 Iteration: 207600. Train_MSE: 0.003779260441660881. Test_MSE: 0.0425201952457428\n",
      "Epoch: 295 Iteration: 207700. Train_MSE: 0.0008752429275773466. Test_MSE: 0.046376340091228485\n",
      "Epoch: 296 Iteration: 207800. Train_MSE: 0.04787082597613335. Test_MSE: 0.044766299426555634\n",
      "Epoch: 296 Iteration: 207900. Train_MSE: 0.04616904258728027. Test_MSE: 0.04132891073822975\n",
      "Epoch: 296 Iteration: 208000. Train_MSE: 0.020887233316898346. Test_MSE: 0.04163525998592377\n",
      "Epoch: 296 Iteration: 208100. Train_MSE: 0.0051722158677875996. Test_MSE: 0.04540600627660751\n",
      "Epoch: 296 Iteration: 208200. Train_MSE: 0.013229139149188995. Test_MSE: 0.04506843909621239\n",
      "Epoch: 296 Iteration: 208300. Train_MSE: 0.0029465577099472284. Test_MSE: 0.04340937361121178\n",
      "Epoch: 296 Iteration: 208400. Train_MSE: 0.0009670936851762235. Test_MSE: 0.04646015167236328\n",
      "Epoch: 297 Iteration: 208500. Train_MSE: 0.12775583565235138. Test_MSE: 0.04560069739818573\n",
      "Epoch: 297 Iteration: 208600. Train_MSE: 0.044850483536720276. Test_MSE: 0.04132556915283203\n",
      "Epoch: 297 Iteration: 208700. Train_MSE: 0.0297181885689497. Test_MSE: 0.041657768189907074\n",
      "Epoch: 297 Iteration: 208800. Train_MSE: 0.003208564594388008. Test_MSE: 0.045194800943136215\n",
      "Epoch: 297 Iteration: 208900. Train_MSE: 0.010615183040499687. Test_MSE: 0.04441240802407265\n",
      "Epoch: 297 Iteration: 209000. Train_MSE: 0.0008747514802962542. Test_MSE: 0.04327642172574997\n",
      "Epoch: 297 Iteration: 209100. Train_MSE: 0.0012592693092301488. Test_MSE: 0.04632120952010155\n",
      "Epoch: 298 Iteration: 209200. Train_MSE: 0.06465884298086166. Test_MSE: 0.045784808695316315\n",
      "Epoch: 298 Iteration: 209300. Train_MSE: 0.04596550762653351. Test_MSE: 0.04177924245595932\n",
      "Epoch: 298 Iteration: 209400. Train_MSE: 0.03634952753782272. Test_MSE: 0.04112718626856804\n",
      "Epoch: 298 Iteration: 209500. Train_MSE: 0.003751950804144144. Test_MSE: 0.04467940330505371\n",
      "Epoch: 298 Iteration: 209600. Train_MSE: 0.015082167461514473. Test_MSE: 0.04481399431824684\n",
      "Epoch: 298 Iteration: 209700. Train_MSE: 0.000993442488834262. Test_MSE: 0.0435125008225441\n",
      "Epoch: 298 Iteration: 209800. Train_MSE: 0.0015673680463805795. Test_MSE: 0.04651602730154991\n",
      "Epoch: 299 Iteration: 209900. Train_MSE: 0.05922388657927513. Test_MSE: 0.04567346349358559\n",
      "Epoch: 299 Iteration: 210000. Train_MSE: 0.07224398851394653. Test_MSE: 0.04258924722671509\n",
      "Epoch: 299 Iteration: 210100. Train_MSE: 0.036101117730140686. Test_MSE: 0.040365613996982574\n",
      "Epoch: 299 Iteration: 210200. Train_MSE: 0.0008852695464156568. Test_MSE: 0.04407215490937233\n",
      "Epoch: 299 Iteration: 210300. Train_MSE: 0.014141563326120377. Test_MSE: 0.04551319405436516\n",
      "Epoch: 299 Iteration: 210400. Train_MSE: 0.0006436545518226922. Test_MSE: 0.043095361441373825\n",
      "Epoch: 299 Iteration: 210500. Train_MSE: 0.0031174439936876297. Test_MSE: 0.046687278896570206\n",
      "Epoch: 299 Iteration: 210600. Train_MSE: 0.0053130025044083595. Test_MSE: 0.04548041522502899\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "seq_dim = 1\n",
    "\n",
    "n_iter = 0\n",
    "num_samples = len(X_train)\n",
    "test_samples = len(X_test)\n",
    "batch_size = 100\n",
    "num_epochs = 300\n",
    "feat_dim = X_train.shape[1]\n",
    "\n",
    "X_train = X_train.type(torch.FloatTensor)\n",
    "y_train = y_train.type(torch.FloatTensor)\n",
    "X_test = X_test.type(torch.FloatTensor)\n",
    "y_test = y_test.type(torch.FloatTensor)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, int(num_samples/batch_size -1)):\n",
    "        \n",
    "        \n",
    "        features = Variable(X_train[i*batch_size:(i+1)*batch_size, :]).view(-1, seq_dim, feat_dim)\n",
    "        Kt_value = Variable(y_train[i*batch_size:(i+1)*batch_size])\n",
    "        \n",
    "        #print(\"Kt_value={}\".format(Kt_value))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(features)\n",
    "        #print(\"outputs ={}\".format(outputs))\n",
    "        \n",
    "        loss = criterion(outputs, Kt_value)\n",
    "\n",
    "        train_loss.append(loss.data)\n",
    "        train_iter.append(n_iter)\n",
    "\n",
    "        #print(\"loss = {}\".format(loss))\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        n_iter += 1  \n",
    "            \n",
    "        if n_iter%100 == 0:\n",
    "            for i in range(0,int(test_samples/batch_size -1)):\n",
    "                features = Variable(X_test[i*batch_size:(i+1)*batch_size, :]).view(-1, seq_dim, feat_dim)\n",
    "                Kt_test = Variable(y_test[i*batch_size:(i+1)*batch_size])\n",
    "                \n",
    "                outputs = model(features)\n",
    "                \n",
    "                mse = np.mean(np.abs(Kt_test.data.numpy() - outputs.data.numpy().squeeze()))\n",
    "                \n",
    "                test_iter.append(n_iter)\n",
    "                test_loss.append(mse)\n",
    "                \n",
    "            print('Epoch: {} Iteration: {}. Train_MSE: {}. Test_MSE: {}'.format(epoch, n_iter, loss.data, mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 52])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29ea97fd0>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss,'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2a2cddab0>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(test_loss,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.45945947, 0.32665512, 0.        , ..., 0.81818182, 1.        ,\n",
       "        0.82191781],\n",
       "       [0.44444446, 0.33013919, 0.        , ..., 0.81818182, 1.        ,\n",
       "        0.82191781],\n",
       "       [0.44744741, 0.31533107, 0.        , ..., 0.81818182, 1.        ,\n",
       "        0.82465753],\n",
       "       ...,\n",
       "       [0.22222222, 0.48693391, 0.        , ..., 0.27272727, 1.33333333,\n",
       "        0.3260274 ],\n",
       "       [0.22222222, 0.48954696, 0.        , ..., 0.27272727, 1.33333333,\n",
       "        0.3260274 ],\n",
       "       [0.22222222, 0.48954696, 0.        , ..., 0.27272727, 1.33333333,\n",
       "        0.3260274 ]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array([])\n",
    "\n",
    "for i in range(0, int(num_samples/batch_size -1)):\n",
    "    features = Variable(torch.from_numpy(X_test).type(torch.FloatTensor)[i*batch_size:(i+1)*batch_size, :]).view(-1, seq_dim, feat_dim)\n",
    "\n",
    "    predictions = np.append(predictions, model(features).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = y_train_scaler.inverse_transform(predictions.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2c67e7d60>]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_train_scaler.inverse_transform(y_test))\n",
    "plt.plot(list(preds[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10795, 1)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10795, 1)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  152.992\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"MAE: \",\n",
    "    round(\n",
    "        mean_absolute_error(\n",
    "            y_true=y_train_scaler.inverse_transform(y_test),\n",
    "            y_pred=preds.T,\n",
    "        ),\n",
    "        3,\n",
    "    ),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
